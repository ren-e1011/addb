{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.0'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pla.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie_data = pla.read_chat('./Pitt/*/cookie/*.cha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data = pla.read_chat('./Pitt/*/sentence/*.cha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_data = pla.read_chat('./Pitt/*/recall/*.cha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_fnames = glob.glob(os.getcwd()+'/Pitt/*/sentence/*.cha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_fnames = sorted(sentence_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control, Dementia\n",
    "cookie_fnames = glob.glob(os.getcwd()+'/Pitt/*/cookie/*.cha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie_fnames = sorted(cookie_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_fnames = glob.glob(os.getcwd()+'/Pitt/*/recall/*.cha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_fnames = sorted(recall_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#samples\n",
    "len(sentence_fnames+cookie_fnames+recall_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cookie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for random batching/data grabbing \n",
    "fnames_dict = {i:fname for (i,fname) in enumerate(cookie_fnames+sentence_fnames+recall_fnames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(fnames_dict,'fnames_cookie_sentence_recall_dict.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets (MMSE scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing mmse with group's mean mmse\n",
    "def get_targets(dataset,filenames):\n",
    "    \n",
    "    targets = []\n",
    "    groups = {}\n",
    "    \n",
    "#     for fname in sorted(filenames):\n",
    "    for fname in filenames:\n",
    "        # PAR MMSE\n",
    "#         print(fname)\n",
    "# MOD groupnames to lower -- select few mistyped \n",
    "        target = dataset.headers()[fname]['Participants']['PAR']['education']\n",
    "        group = dataset.headers()[fname]['Participants']['PAR']['group'].lower()\n",
    "        \n",
    "        # to be replaced with group mean\n",
    "        if target is '':\n",
    "            targets.append(group)\n",
    "            \n",
    "        else:\n",
    "            targets.append(int(target))\n",
    "            if group.lower() in groups.keys():\n",
    "                groups[group.lower()].append(int(target))\n",
    "            else:\n",
    "                groups[group.lower()] = [int(target)]\n",
    "                \n",
    "#     print('targets',targets)            \n",
    "#     print('groups',groups)\n",
    "    \n",
    "    for g in groups.keys():\n",
    "        m = np.mean(groups[g])\n",
    "        groups[g] = int(m) if m % 1 > 5 else int(m) + 1\n",
    "    \n",
    "    #TODO replace with tensor\n",
    "    targetseries = pd.Series(targets)\n",
    "    \n",
    "#     print('groups_mean',groups)\n",
    "    \n",
    "    for g in groups.keys():\n",
    "        targetseries[[i for i,x in enumerate(targets) if x==g]] = groups[g]\n",
    "# Uncomment to return dict of group-averages\n",
    "#     return groups\n",
    "    return targetseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie_data_targets = get_targets(cookie_data,cookie_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Control': 30,\n",
       " 'ProbableAD': 19,\n",
       " 'MCI': 28,\n",
       " 'Memory': 30,\n",
       " 'Vascular': 17,\n",
       " 'PossibleAD': 20,\n",
       " 'Probable': 19,\n",
       " 'Other': 24}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_targets(cookie_data,cookie_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(cookie_data_targets,'cookie_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie_target_dict = {i:fname for (i,fname) in enumerate(cookie_data_targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(cookie_target_dict,'cookie_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_data_targets = get_targets(sentence_data,sentence_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ProbableAD': 19,\n",
       " 'MCI': 28,\n",
       " 'Memory': 30,\n",
       " 'Vascular': 17,\n",
       " 'PossibleAD': 21,\n",
       " 'Control': 30,\n",
       " 'Probable': 19,\n",
       " 'Other': 24}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_targets(sentence_data,sentence_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(sentence_data_targets,'sentence_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_target_dict = {i+len(cookie_data):fname for (i,fname) in enumerate(sentence_data_targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(sentence_target_dict,'sentence_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_data_targets = get_targets(recall_data,recall_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(recall_data_targets,'recall_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_target_dict = {i+len(sentence_data)+len(cookie_data):fname for (i,fname) in enumerate(recall_data_targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(recall_target_dict,'recall_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ProbableAD': 19,\n",
       " 'MCI': 28,\n",
       " 'Memory': 30,\n",
       " 'Vascular': 17,\n",
       " 'PossibleAD': 21,\n",
       " 'Probable': 19,\n",
       " 'Other': 24}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_targets(recall_data,recall_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_data_targets) == len(sentence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cookie_data_targets) == len(cookie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recall_data_targets) == len(recall_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renumerate data variables for local data grabbing: vocabset, posset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie_fnames = {i:fname for (i,fname) in enumerate(cookie_fnames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cookie_fnames,'cookie_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving -- \n",
    "#sentence_fnames = {i+len(cookie_data):fname for (i,fname) in enumerate(sentence_fnames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(sentence_fnames,'sentence_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_fnames = {i:fname for (i,fname) in enumerate(sentence_fnames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving -- \n",
    "#recall_fnames = {i+len(cookie_data)+len(sentence_data):fname for (i,fname) in enumerate(recall_fnames)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(recall_fnames,'recall_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_fnames = {i:fname for (i,fname) in enumerate(recall_fnames)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load addb vocab glove word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = './PretrainedWordEmb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './PretrainedWordEmb//addb.vocab.glove.42B.300_words.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-1bf86a173a92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maddbvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{glove_path}/addb.vocab.glove.42B.300_words.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './PretrainedWordEmb//addb.vocab.glove.42B.300_words.pkl'"
     ]
    }
   ],
   "source": [
    "addbvocab = pickle.load(open(f'{glove_path}/addb.vocab.glove.42B.300_words.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addbvocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabset = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corpus,data in [(cookie_fnames,cookie_data),(sentence_fnames,sentence_data),(recall_fnames,recall_data)]: \n",
    "    for i in range(len(corpus)):\n",
    "        tokens = set([tokenraw for sent in data.tagged_sents(participant='PAR',by_files=True)[corpus[i]] for (tokenraw,pos,tokenstem,dependency) in sent])\n",
    "        vocabset.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(vocabset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db Vocab as gloVe emb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(addbvocab)) == sorted(list(vocabset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD MOR: POS + GRAMMATICAL CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "posset = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corpus,data in [(cookie_fnames,cookie_data),(sentence_fnames,sentence_data),(recall_fnames,recall_data)]: \n",
    "    for i in range(len(corpus)):\n",
    "        pos = set([pos for sent in data.tagged_sents(participant='PAR',by_files=True)[corpus[i]] for (tokenraw,pos,tokenstem,dependency) in sent])\n",
    "        posset.update(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to concat to embedding tensor \n",
    "pos_dict = {pos:i for (i,pos) in enumerate(posset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'OVER#V': 1,\n",
       " '+..?': 2,\n",
       " 'DIS#N': 3,\n",
       " 'MID#N': 4,\n",
       " 'PRO:DEM': 5,\n",
       " 'PRO:OBJ': 6,\n",
       " 'NEO': 7,\n",
       " 'PRO:INT': 8,\n",
       " 'DET:ART': 9,\n",
       " 'PREP': 10,\n",
       " 'N:GERUND': 11,\n",
       " 'DET:DEM': 12,\n",
       " 'QN': 13,\n",
       " 'PRO:REFL': 14,\n",
       " 'RE#V': 15,\n",
       " '+/.': 16,\n",
       " 'N': 17,\n",
       " 'DET:NUM': 18,\n",
       " '+\"/.': 19,\n",
       " 'GRAND#ADJ': 20,\n",
       " 'V': 21,\n",
       " 'COMP': 22,\n",
       " 'UN#ADJ': 23,\n",
       " '.': 24,\n",
       " 'OVER#N:GERUND': 25,\n",
       " 'MINI#N': 26,\n",
       " 'PRO:EXIST': 27,\n",
       " 'UN#PART': 28,\n",
       " 'CO': 29,\n",
       " 'N:PROP': 30,\n",
       " 'GRAND#N': 31,\n",
       " 'ON': 32,\n",
       " 'N:PT': 33,\n",
       " 'MOD': 34,\n",
       " 'AUX': 35,\n",
       " 'COP': 36,\n",
       " 'N:ADJ': 37,\n",
       " 'OUT#PART': 38,\n",
       " 'UN#ADV': 39,\n",
       " 'PRO:POSS': 40,\n",
       " 'PRE#V': 41,\n",
       " 'PRE#PART': 42,\n",
       " 'META': 43,\n",
       " '+//?': 44,\n",
       " 'UN#N': 45,\n",
       " 'UP#PART': 46,\n",
       " 'BEG': 47,\n",
       " 'INF': 48,\n",
       " 'OVER#PART': 49,\n",
       " 'DET:POSS': 50,\n",
       " 'DIS#V': 51,\n",
       " '+//.': 52,\n",
       " 'PRO:REL': 53,\n",
       " 'UP#V': 54,\n",
       " '+/?': 55,\n",
       " 'POST': 56,\n",
       " '+\".': 57,\n",
       " 'ADV:TEM': 58,\n",
       " 'CONJ': 59,\n",
       " 'END': 60,\n",
       " 'IN#ADJ': 61,\n",
       " '!': 62,\n",
       " 'CM': 63,\n",
       " 'ADJ': 64,\n",
       " 'PRO:PER': 65,\n",
       " 'PRO:INDEF': 66,\n",
       " '+.': 67,\n",
       " 'PRO:SUB': 68,\n",
       " 'N:LET': 69,\n",
       " 'NEG': 70,\n",
       " '+...': 71,\n",
       " 'PART': 72,\n",
       " '?': 73,\n",
       " 'ADV': 74,\n",
       " 'COORD': 75}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(pos_dict,'pos_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pos_dict,'pos_cookie_sent_recall_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(posset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VOCAB EMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Blosc/bcolz\n",
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with zipfile.ZipFile('./PretrainedWordEmb/glove.42B.300d.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('./PretrainedWordEmb/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load pretrained glove (common crawl 42B tokens, 1.9M vocab, uncased, 300d vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{glove_path}/glove.42B.300d.txt', 'rb') as f:\n",
    "#     for l in f:\n",
    "#         line = l.decode().split()\n",
    "#         word = line[0]\n",
    "#         break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = []\n",
    "# idx = 0\n",
    "# word2idx = {}\n",
    "# vectors = bcolz.carray(np.zeros(1), rootdir=f'{glove_path}/glove.42B.300.dat', mode='w')\n",
    "\n",
    "# with open(f'{glove_path}/glove.42B.300d.txt', 'rb') as f:\n",
    "#     for l in f:\n",
    "#         line = l.decode().split()\n",
    "#         word = line[0]\n",
    "#         words.append(word)\n",
    "#         word2idx[word] = idx\n",
    "#         idx += 1\n",
    "#         vect = np.array(line[1:]).astype(np.float)\n",
    "#         vectors.append(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors = bcolz.carray(vectors[1:].reshape((-1,300)), rootdir=f'{glove_path}/glove.42B.300.dat', mode='w')\n",
    "# vectors.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(words, open(f'{glove_path}/glove.42B.300_words.pkl', 'wb'))\n",
    "# pickle.dump(word2idx, open(f'{glove_path}/glove.42B.300_idx.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = bcolz.open(f'{glove_path}/glove.42B.300.dat')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pickle.load(open(f'{glove_path}/glove.42B.300_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open(f'{glove_path}/glove.42B.300_idx.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'UNK' in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.append('UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1917494, 300)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNK token -- average of embeddings\n",
    "average_vec = np.mean(vectors, axis=0)\n",
    "# print(average_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.concatenate((vectors,np.reshape(average_vec,(1,300))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1917495"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1917495"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx['UNK'] = len(vectors) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1917495"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "def get_glovembs(sample):\n",
    "    \n",
    "    def handle_contractions(x):\n",
    "        tokenizer = TreebankWordTokenizer()\n",
    "        x = tokenizer.tokenize(x)\n",
    "        x = ' '.join(x)\n",
    "        return x\n",
    "    \n",
    "    # preprocess acc to pretrained embeddings \n",
    "    # lower\n",
    "    # replace _, -\n",
    "    # rm contractions\n",
    "    # rm nonascii chars\n",
    "    \n",
    "    sample = [s for s in sample]\n",
    "    \n",
    "    preprocessample = [handle_contractions(t).split()[0] for t in [token.lower().replace('_','-') for token in sample]]\n",
    "    \n",
    "    \n",
    "    preprocessample = [''.join([i if ord(i) < 128 else '' for i in w]) for w in preprocessample]\n",
    "    \n",
    "    preprocessample = [t.translate(str.maketrans('', '', string.punctuation)) for t in preprocessample]\n",
    "    \n",
    "# uncomment for traceunks = get_glovembs(vocabset)\n",
    "#     return set([word for word in preprocessample if word not in words])\n",
    "    # {w: vectors[word2idx[w]] for w in words}\n",
    "    return {sample[i]: torch.tensor(vectors[word2idx[preprocessample[i]]]) if preprocessample[i] in words else torch.tensor(vectors[word2idx['UNK']]) for i in range(len(sample))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "def get_glovembs(sample):\n",
    "    \n",
    "#     unks = set()\n",
    "    \n",
    "    def handle_contractions(x):\n",
    "        tokenizer = TreebankWordTokenizer()\n",
    "        x = tokenizer.tokenize(x)\n",
    "        x = ' '.join(x)\n",
    "        return x\n",
    "#     def list_tokenize(document):\n",
    "#         sentences = nltk.sent_tokenize(document)\n",
    "#         return [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    \n",
    "    # preprocess acc to pretrained embeddings \n",
    "    # lower\n",
    "    # replace _, -\n",
    "    # rm contractions\n",
    "    # rm nonascii chars\n",
    "    \n",
    "    sample = [s for s in sample]\n",
    "    \n",
    "    wordvecs = []\n",
    "    \n",
    "#     print('sample',sample)\n",
    "    preprocessample = [handle_contractions(t).split()[0] for t in [token.lower().replace('_','-') for token in sample]]\n",
    "#     print('preprocessample',preprocessample)\n",
    "    \n",
    "    \n",
    "    preprocessample = [''.join([i if ord(i) < 128 else '' for i in w]) for w in preprocessample]\n",
    "    \n",
    "    for preprocessedtkn in preprocessample:\n",
    "        wordvecs.extend(preprocessedtkn.split('-'))\n",
    "    preprocessample = wordvecs\n",
    "    \n",
    "        \n",
    "#     for i in range(len(sample)):\n",
    "#         if preprocessample[i] not in words:\n",
    "#             unks.add(preprocessample[i])\n",
    "#     uncomment to indicate which are 'UNK'\n",
    "#     return unks\n",
    "    return {sample[i]: torch.tensor(vectors[word2idx[preprocessample[i]]]) if preprocessample[i] in words else torch.tensor(vectors[word2idx['UNK']]) for i in range(len(sample))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '..',\n",
       " '//',\n",
       " 'alrightie',\n",
       " 'cappdf',\n",
       " 'cookeiejar',\n",
       " 'hmhunh',\n",
       " 'hunhunh',\n",
       " 'nuhhuh',\n",
       " 'sewickly',\n",
       " 'thanksiving',\n",
       " 'unhunh'}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_glovembs(vocabset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "unks = get_glovembs(vocabset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '..',\n",
       " '//',\n",
       " 'alrightie',\n",
       " 'cappdf',\n",
       " 'cookeiejar',\n",
       " 'hmhunh',\n",
       " 'hunhunh',\n",
       " 'nuhhuh',\n",
       " 'sewickly',\n",
       " 'thanksiving',\n",
       " 'unhunh'}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptylist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-307-bb94483d548a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-307-bb94483d548a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    emptylist.extend(u.split('-')) for u in prev_unks\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[emptylist.extend(u.split('-')) for u in prev_unks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'oh',\n",
       " 'god',\n",
       " 'mister',\n",
       " 'miller',\n",
       " 'holy',\n",
       " 'mackerel',\n",
       " 'little',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'god',\n",
       " 'bless',\n",
       " 'you',\n",
       " 'mister',\n",
       " 'martin',\n",
       " 'unhunh',\n",
       " 'hmhunh',\n",
       " 'oh',\n",
       " 'dear',\n",
       " 'oh',\n",
       " 'gosh',\n",
       " 'council',\n",
       " 'care',\n",
       " 'hunhunh',\n",
       " 'i',\n",
       " \"don't\",\n",
       " 'know',\n",
       " 'i',\n",
       " 'mean',\n",
       " '..',\n",
       " 'how',\n",
       " 'come',\n",
       " 'sewickly',\n",
       " 'dave',\n",
       " 'branton',\n",
       " 'joyce',\n",
       " 'kilmer',\n",
       " 'what',\n",
       " 'about',\n",
       " 'how',\n",
       " 'about',\n",
       " '//',\n",
       " 'oh',\n",
       " 'brother',\n",
       " 'the',\n",
       " 'window',\n",
       " 'of',\n",
       " 'the',\n",
       " 'xxx',\n",
       " 'doctor',\n",
       " 'dick',\n",
       " 'oh',\n",
       " 'lord',\n",
       " 'oh',\n",
       " 'gee',\n",
       " 'nuhhuh',\n",
       " 'oh',\n",
       " 'boy',\n",
       " 'thanksiving',\n",
       " 'tazmania',\n",
       " 'dutch',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'cookeiejar',\n",
       " 'my',\n",
       " 'goodness',\n",
       " 'lots',\n",
       " 'of',\n",
       " 'pardon',\n",
       " 'me',\n",
       " 'cappdf',\n",
       " 'alrightie',\n",
       " 'lee',\n",
       " 'a']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emptylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_unks = {'',\n",
    " '..',\n",
    " '//',\n",
    " 'a-lot-of',\n",
    " 'alrightie',\n",
    " 'cappdf',\n",
    " 'cookeiejar',\n",
    " '-care',\n",
    " 'dave-branton',\n",
    " 'doctor-dick',\n",
    " 'god-bless-you',\n",
    " 'hmhunh',\n",
    " 'holy-mackerel',\n",
    " 'how-about',\n",
    " 'how-come',\n",
    " 'hunhunh',\n",
    " \"i-don't-know\",\n",
    " 'i-mean',\n",
    " 'joyce-kilmer',\n",
    " 'lee-a',\n",
    " 'little-red-riding-hood',\n",
    " 'lots-of',\n",
    " 'mister-martin',\n",
    " 'mister-miller',\n",
    " 'my-goodness',\n",
    " 'nuhhuh',\n",
    " 'oh-boy',\n",
    " 'oh-brother',\n",
    " 'oh-dear',\n",
    " 'oh-gee',\n",
    " 'oh-god',\n",
    " 'oh-gosh',\n",
    " 'oh-lord',\n",
    " 'pardon-me',\n",
    " 'sewickly',\n",
    " 'tazmania-dutch',\n",
    " 'thanksiving',\n",
    " 'the-window-of-the-xxx',\n",
    " 'unhunh',\n",
    " 'what-about'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptylist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[''],\n",
       " ['oh', 'god'],\n",
       " ['mister', 'miller'],\n",
       " ['holy', 'mackerel'],\n",
       " ['little', 'red', 'riding', 'hood'],\n",
       " ['god', 'bless', 'you'],\n",
       " ['mister', 'martin'],\n",
       " ['unhunh'],\n",
       " ['hmhunh'],\n",
       " ['oh', 'dear'],\n",
       " ['oh', 'gosh'],\n",
       " ['council', 'care'],\n",
       " ['hunhunh'],\n",
       " ['i', \"don't\", 'know'],\n",
       " ['i', 'mean'],\n",
       " ['..'],\n",
       " ['how', 'come'],\n",
       " ['sewickly'],\n",
       " ['dave', 'branton'],\n",
       " ['joyce', 'kilmer'],\n",
       " ['what', 'about'],\n",
       " ['how', 'about'],\n",
       " ['//'],\n",
       " ['oh', 'brother'],\n",
       " ['the', 'window', 'of', 'the', 'xxx'],\n",
       " ['doctor', 'dick'],\n",
       " ['oh', 'lord'],\n",
       " ['oh', 'gee'],\n",
       " ['nuhhuh'],\n",
       " ['oh', 'boy'],\n",
       " ['thanksiving'],\n",
       " ['tazmania', 'dutch'],\n",
       " ['a', 'lot', 'of'],\n",
       " ['cookeiejar'],\n",
       " ['my', 'goodness'],\n",
       " ['lots', 'of'],\n",
       " ['pardon', 'me'],\n",
       " ['cappdf'],\n",
       " ['alrightie'],\n",
       " ['lee', 'a']]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[u.split('-') for u in prev_unks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '..',\n",
       " '//',\n",
       " 'a-lot-of',\n",
       " 'alrightie',\n",
       " 'cappdf',\n",
       " 'cookeiejar',\n",
       " 'council-care',\n",
       " 'dave-branton',\n",
       " 'doctor-dick',\n",
       " 'god-bless-you',\n",
       " 'hmhunh',\n",
       " 'holy-mackerel',\n",
       " 'how-about',\n",
       " 'how-come',\n",
       " 'hunhunh',\n",
       " \"i-don't-know\",\n",
       " 'i-mean',\n",
       " 'joyce-kilmer',\n",
       " 'lee-a',\n",
       " 'little-red-riding-hood',\n",
       " 'lots-of',\n",
       " 'mister-martin',\n",
       " 'mister-miller',\n",
       " 'my-goodness',\n",
       " 'nuhhuh',\n",
       " 'oh-boy',\n",
       " 'oh-brother',\n",
       " 'oh-dear',\n",
       " 'oh-gee',\n",
       " 'oh-god',\n",
       " 'oh-gosh',\n",
       " 'oh-lord',\n",
       " 'pardon-me',\n",
       " 'sewickly',\n",
       " 'tazmania-dutch',\n",
       " 'thanksiving',\n",
       " 'the-window-of-the-xxx',\n",
       " 'unhunh',\n",
       " 'what-about'}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "addb_vocab_embs = get_glovembs(vocabset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(addb_vocab_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addb_vocab_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addb_vocab_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'UNK'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-325-a36990a4b014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maddb_vocab_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UNK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'UNK'"
     ]
    }
   ],
   "source": [
    "addb_vocab_embs['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.0053e-02, -1.0321e-01, -1.6738e-01,  1.9922e-01,  5.9712e-02,\n",
       "         3.1170e-02, -4.4661e+00,  1.3585e-01,  2.7248e-01, -5.9720e-01,\n",
       "         2.3723e-01,  2.0766e-02, -2.6883e-01, -2.4141e-01, -1.8461e-01,\n",
       "        -6.4325e-02, -1.6662e-01, -2.2890e-01, -2.0721e-01, -3.6173e-02,\n",
       "         4.4040e-01, -6.7288e-02,  1.1337e-01,  3.3058e-01, -9.1099e-02,\n",
       "         5.3504e-03, -3.1603e-01, -8.9506e-02, -2.1208e-01,  8.6033e-02,\n",
       "        -2.3813e-02, -1.7691e-01,  4.6761e-01,  8.7031e-02,  1.6213e-01,\n",
       "         1.2928e-02, -3.2798e-01, -1.4660e-01,  7.0218e-02,  1.3093e-01,\n",
       "        -1.2166e-01, -1.9080e-01,  1.9738e-01, -3.8298e-01,  3.2726e-01,\n",
       "         3.2674e-01,  1.3125e-01, -2.8537e-01, -1.4433e-01, -7.1196e-01,\n",
       "        -5.6059e-02, -5.5130e-01, -1.1745e-01, -2.5487e-01,  1.5711e-01,\n",
       "        -3.5474e-02,  2.8145e-01,  4.1805e-02,  2.2557e-02,  1.4275e-01,\n",
       "         1.6868e-01,  7.0439e-02,  2.1714e-01, -1.0379e-01, -1.9166e-01,\n",
       "         8.6866e-02,  2.3581e-01, -1.0142e-01, -1.8156e-01, -3.7176e-01,\n",
       "        -4.3378e-01,  3.7316e-01,  2.6662e-02, -1.9029e-01, -2.2885e-02,\n",
       "         8.7913e-02,  3.1190e-01,  1.8314e-01,  3.9893e-01,  5.6770e-02,\n",
       "        -5.0011e-02, -6.2437e-01, -2.6447e-01,  1.2176e-01, -2.8891e-02,\n",
       "        -7.3216e-02,  1.4320e-01, -1.4690e-01,  6.5568e-02,  8.8155e-03,\n",
       "         2.9984e-02,  2.1043e-02,  9.4480e-02,  2.0792e-01, -5.4458e-02,\n",
       "        -3.8284e-01, -2.5968e+00,  1.9454e-02,  2.5745e-01, -3.0072e-03,\n",
       "        -3.7470e-01,  4.8475e-01,  1.1770e-01, -9.4247e-02, -1.5802e-01,\n",
       "        -2.9974e-01,  1.6799e-01, -1.2214e-01, -7.9662e-02,  1.0226e-01,\n",
       "        -1.3429e-01, -7.5948e-02, -2.3397e-01,  3.5884e-01, -4.5875e-01,\n",
       "         1.8288e-01,  2.0288e-01, -4.1090e-01, -5.7003e-02, -1.7170e-02,\n",
       "         3.9649e-02, -3.9498e-02,  3.8849e-01,  1.7680e-01, -2.9074e-01,\n",
       "        -7.5912e-01, -3.2020e-02, -1.3636e-01, -1.5638e-01,  2.6928e-01,\n",
       "        -3.7165e-01,  8.5099e-02, -4.4334e-02,  4.6032e-02, -8.4263e-02,\n",
       "        -2.1499e-01,  1.9457e-01,  2.7532e-01, -2.5094e-01,  1.2174e+00,\n",
       "         3.0415e-01,  7.9104e-02,  1.2005e-01, -8.3574e-02, -2.7087e-01,\n",
       "        -3.9297e-01,  1.8803e-01, -2.1614e-01,  2.1247e-01,  7.4458e-02,\n",
       "         1.1613e-01, -2.3060e-01,  1.1011e-01, -4.0006e-01, -1.5879e-01,\n",
       "        -1.0349e-02,  1.6820e-02,  2.2618e-01, -1.2206e-01, -2.2265e-01,\n",
       "         3.9475e-01,  2.1418e-01, -4.3785e-01, -1.8225e-01, -6.1489e-02,\n",
       "         2.6622e-01, -5.6675e-01,  6.8772e-02,  4.7977e-01,  8.0547e-02,\n",
       "        -3.7990e-01, -1.7117e-01, -3.4055e-01, -4.7033e-02, -1.8310e-01,\n",
       "         2.3615e-01, -2.1828e-01,  2.0313e-01, -5.7200e-02, -6.2009e-01,\n",
       "         3.6024e-01,  2.2303e-01,  1.8857e-01, -2.2102e-01, -1.0269e-01,\n",
       "        -1.1502e-01,  6.4475e-02, -1.3260e-01,  1.6924e-02,  1.3182e-01,\n",
       "         1.7320e-02, -3.3401e-01,  2.2549e-01, -2.0727e-01, -1.5184e-01,\n",
       "        -7.8453e-02,  1.9446e-01, -9.9012e-02,  4.4255e-01, -1.5507e-01,\n",
       "        -1.2640e-01,  3.1419e-01, -2.5927e-02,  1.5188e-02, -2.0040e-01,\n",
       "         1.9895e-01,  4.5751e-02, -2.2889e-01,  5.6880e-01,  2.2520e-01,\n",
       "         2.1301e-01, -4.4238e-01,  1.5894e-01, -3.3452e-01,  3.8603e-01,\n",
       "        -6.2494e-02,  1.0513e-01, -1.9081e-01,  2.3325e-01, -7.7303e-02,\n",
       "        -1.2323e-01, -1.9051e-01, -1.2677e-01,  1.1373e-01, -2.2574e+00,\n",
       "         1.2468e-01,  3.8296e-01,  3.9647e-01,  1.9421e-01, -5.1318e-02,\n",
       "        -4.6148e-02,  2.0137e-01,  1.0990e-01,  3.0095e-01, -6.1116e-02,\n",
       "         9.9210e-02,  2.1232e-01, -6.6740e-02, -3.0960e-01, -1.2332e-01,\n",
       "         1.1567e-01,  2.4984e-01, -3.9419e-01,  3.1387e-01,  4.0820e-01,\n",
       "         5.5540e-02, -4.0341e-01, -2.2857e-02, -1.2469e-01,  1.6610e-01,\n",
       "         1.0293e-01,  7.6732e-02,  8.6360e-02,  5.1335e-02,  7.7608e-01,\n",
       "        -9.3510e-02,  2.3398e-01, -1.1899e-01,  2.2351e-01, -1.6646e-01,\n",
       "         2.1964e-01, -1.2569e-01, -1.0574e-01, -2.5597e-01,  1.2385e-01,\n",
       "        -1.7176e-01,  7.3660e-02,  6.4241e-02, -6.8073e-02, -1.9798e-01,\n",
       "         2.1048e-01, -6.2550e-02,  1.2252e-01, -9.9382e-02,  8.1024e-02,\n",
       "         2.1463e-01,  1.0191e-01,  4.3555e-01, -5.1278e-02, -3.0489e-01,\n",
       "         1.6980e-01,  8.8258e-02, -1.6874e-01, -1.8312e-01,  1.8430e-01,\n",
       "         7.0977e-04, -1.9184e-01, -1.0077e-01, -3.1909e-02, -1.9419e-01,\n",
       "         2.7197e-01, -4.3720e-01, -1.7222e-02, -6.6084e-02,  2.6554e-01,\n",
       "        -3.7876e-01, -7.7808e-02,  3.9964e-01,  8.3201e-01, -3.2712e-02],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addb_vocab_embs['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.77110762e-03, -2.38171602e-03,  2.48453616e-02,  3.84871991e-02,\n",
       "       -1.27718938e-01,  3.31646344e-02,  4.86656168e-01, -1.60207891e-01,\n",
       "        1.68529167e-02,  1.63224430e-01, -1.02243697e-01, -5.26176498e-02,\n",
       "        3.46847772e-02, -1.90403945e-02,  3.26858599e-02,  3.54991079e-02,\n",
       "        6.39390293e-02,  3.84283555e-02, -1.16503242e-02, -2.53978575e-03,\n",
       "       -1.54851111e-02, -2.30899176e-02,  1.10525923e-02, -2.86016257e-02,\n",
       "       -2.39241718e-02,  5.43962499e-02, -2.72564042e-03,  2.93424213e-02,\n",
       "        3.39359506e-02,  5.73053679e-02,  5.95071778e-02,  1.09199854e-04,\n",
       "       -2.39850050e-02,  2.59529588e-02,  1.05694563e-02,  7.69458290e-03,\n",
       "        1.86652275e-02,  1.77983629e-02, -2.53548389e-02,  2.43759036e-02,\n",
       "        2.54368294e-02, -5.54019334e-02,  2.59849416e-02,  4.13441975e-02,\n",
       "        1.87303416e-02,  3.68259799e-03, -3.21201589e-02,  5.68750757e-02,\n",
       "        4.68697892e-02, -1.33935990e-02, -1.44603463e-03,  4.74672429e-04,\n",
       "        2.68379948e-02,  8.04257735e-06, -2.18948008e-02,  1.83219156e-02,\n",
       "       -3.39346471e-02, -2.66306850e-02,  2.23212386e-02, -1.94754142e-05,\n",
       "        7.30479271e-03,  2.91891943e-02, -2.07341701e-02, -1.14342526e-02,\n",
       "        1.00404227e-02, -2.97088102e-02, -6.27568220e-03, -4.62653886e-02,\n",
       "       -4.01785483e-02,  3.43360887e-02,  7.75729199e-02, -2.97119579e-02,\n",
       "       -1.61555066e-02,  9.81997711e-03,  1.09959206e-02,  7.27834333e-02,\n",
       "       -3.26932356e-02, -3.16679919e-02, -1.85980662e-02,  2.71294022e-02,\n",
       "       -2.08284118e-02,  2.29159121e-01, -3.26001224e-03,  5.90762854e-02,\n",
       "       -3.65571039e-02, -3.19088863e-02, -4.38883460e-02,  1.86008575e-02,\n",
       "       -3.82020500e-03,  2.28310218e-02, -5.79479237e-04,  4.60758459e-02,\n",
       "        5.83652500e-03, -5.57860711e-03, -1.84264244e-02,  1.90696922e-01,\n",
       "        4.54442770e-01,  1.62763339e-02, -3.36225875e-02, -1.64473133e-02,\n",
       "        1.23053757e-02, -7.22361191e-02, -6.45849375e-02, -1.26253468e-02,\n",
       "        1.90587309e-02,  2.32239948e-02, -3.54756578e-02, -2.54456504e-03,\n",
       "        3.76931571e-03,  2.12225100e-02,  5.90359614e-03, -9.48715915e-04,\n",
       "       -1.73244880e-02, -1.59153684e-02,  6.95839599e-02, -5.99729115e-02,\n",
       "       -1.16157052e-01, -9.13497444e-03, -6.29112099e-03, -5.06480270e-02,\n",
       "        4.63160272e-02,  2.80320415e-02, -1.81048932e-02,  6.15529271e-02,\n",
       "       -7.72394559e-03,  2.68893056e-02, -4.04274634e-03,  2.95890387e-02,\n",
       "        1.44753530e-02,  3.08942256e-02, -1.75404121e-02, -2.45371171e-02,\n",
       "        3.01654994e-02,  2.37621137e-02, -7.43010617e-02, -1.70904803e-02,\n",
       "       -2.37747460e-02, -5.49349870e-03, -3.92616127e-02, -2.71933603e-01,\n",
       "       -7.73449005e-03, -2.70511382e-02, -2.13022814e-02, -3.77421298e-03,\n",
       "        2.47498051e-03,  4.49467284e-02, -2.81584745e-02,  2.17868442e-02,\n",
       "       -1.22703600e-01, -1.91991291e-02,  9.02017781e-03,  2.73343587e-02,\n",
       "       -8.67601421e-03,  2.39519202e-02, -3.97425078e-02,  6.32328110e-02,\n",
       "        2.65959717e-02, -2.60106547e-02,  4.12680322e-02,  3.15069673e-02,\n",
       "       -1.73832024e-02,  1.28012840e-02,  4.03177492e-02,  3.00692966e-02,\n",
       "       -4.14899192e-03,  2.71421716e-04, -1.34144745e-03, -1.97032067e-02,\n",
       "       -4.10139589e-02,  8.08664683e-02,  3.88196873e-03,  1.29874651e-02,\n",
       "        2.95845523e-02,  2.17512555e-02,  3.97052874e-02, -6.76439591e-02,\n",
       "        2.89607355e-02,  3.37118624e-02, -5.60413893e-02,  1.46780557e-02,\n",
       "        1.35475817e-02, -4.85808646e-02,  7.82162974e-03,  3.28944609e-02,\n",
       "       -2.86215475e-02,  4.43414751e-02, -5.36211095e-02,  1.87957011e-02,\n",
       "       -1.82017676e-02, -3.39765938e-03, -3.12413547e-02,  4.16291291e-02,\n",
       "       -5.80057705e-02,  2.10018224e-02,  1.42951982e-02,  3.91055608e-02,\n",
       "       -3.81014269e-02, -1.90372487e-02, -3.19134805e-02,  5.73617553e-02,\n",
       "        5.01687363e-02,  2.09082800e-04,  1.37361011e-02, -2.73275728e-02,\n",
       "       -1.68846718e-02, -3.81932100e-02, -1.94893978e-02, -3.34131622e-02,\n",
       "       -6.64952871e-02,  1.73808842e-02, -4.82017718e-02,  2.81172597e-02,\n",
       "        7.86318751e-02,  3.08807584e-02, -2.27833121e-03,  1.41326143e-02,\n",
       "        1.56801616e-02,  4.73774721e-02,  1.49755144e-02,  1.15575185e-02,\n",
       "        4.99614091e-02,  1.93791456e-02,  1.01249449e-02, -2.61276999e-02,\n",
       "        5.14571579e-01, -3.71022793e-02,  4.48672177e-02,  4.00549217e-03,\n",
       "        6.83049122e-03,  2.67905141e-02, -4.30270087e-02, -1.45387436e-02,\n",
       "       -2.42727143e-02,  4.05219157e-03,  1.08208256e-02, -5.01988612e-02,\n",
       "       -1.19188736e-02, -1.51124541e-02,  5.28685385e-02,  5.41534022e-02,\n",
       "        1.86664811e-02, -9.86383330e-03,  7.35627800e-02, -1.06134407e-01,\n",
       "        3.19457609e-03,  2.84830015e-02, -2.65548702e-02,  7.14437106e-02,\n",
       "        3.28689574e-02, -4.29476699e-02,  7.16287049e-03,  2.53985457e-02,\n",
       "        5.94688893e-02, -1.32974624e-02,  1.03833337e-02,  5.04675816e-03,\n",
       "       -1.29671793e-02, -1.78901811e-03, -5.04415269e-02, -5.85285383e-02,\n",
       "       -3.56088732e-02,  1.34219344e-02,  1.37912793e-02, -3.24261944e-03,\n",
       "       -4.95543864e-02,  3.20889100e-03,  4.31969978e-02,  2.68213345e-02,\n",
       "       -2.58762786e-02,  4.59164129e-03, -1.08397825e-02,  3.19686152e-02,\n",
       "        8.16940450e-02, -4.56220196e-02,  1.67329328e-03, -3.19761515e-02,\n",
       "       -4.27843891e-02, -3.48558462e-02, -4.70641807e-02,  2.60851811e-02,\n",
       "       -1.72713540e-01,  3.52618368e-02, -1.08433818e-02, -4.27312883e-02,\n",
       "        2.19364354e-02, -1.48951291e-02, -3.84595062e-03, -2.53876170e-02,\n",
       "        2.31781806e-02,  3.33054528e-02, -4.20659181e-03,  1.23324072e-02,\n",
       "        5.80088647e-02,  2.26852796e-02,  2.05819848e-03,  1.58144669e-02,\n",
       "        1.62143396e-02,  1.01961696e-02, -4.49022512e-02,  1.97468221e-02])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors[word2idx['UNK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.7695e-02,  4.1614e-01, -1.7101e-01,  1.7692e-01, -2.7406e-02,\n",
       "         5.4102e-01, -3.6129e+00,  1.6151e-01,  1.9711e-01,  2.8919e-02,\n",
       "         2.8745e-01, -9.3931e-02,  2.1711e-01, -3.6525e-01,  2.0094e-01,\n",
       "         4.0357e-01,  1.1149e-01, -1.9783e-02, -6.8662e-02,  4.0455e-02,\n",
       "        -1.0114e-01,  6.2720e-02, -2.4347e-01, -2.0251e-01, -4.5643e-01,\n",
       "        -1.6537e-01, -1.4941e-02, -7.6818e-02, -1.8922e-02, -3.7106e-01,\n",
       "         1.6106e-01, -3.7111e-01,  3.8205e-01,  2.5370e-01, -3.9167e-01,\n",
       "        -3.6314e-03, -3.0197e-01, -1.9817e-01, -2.1655e-01,  1.2998e-01,\n",
       "        -1.1480e-01,  3.0046e-01, -7.9314e-01,  1.7068e-01,  2.0446e-01,\n",
       "        -4.5931e-02, -1.9753e-01,  3.2807e-01,  5.5548e-01, -4.4488e-01,\n",
       "        -8.4063e-01, -3.4806e-02, -1.2154e-01, -3.2563e-01,  4.6772e-02,\n",
       "        -6.2888e-02,  5.5237e-01, -8.4866e-02, -9.6028e-02, -1.1892e-01,\n",
       "         3.1771e-01, -5.8550e-02,  3.1959e-01, -4.6279e-01,  5.1349e-01,\n",
       "        -8.2146e-02, -1.3512e-01,  5.3531e-02, -3.8208e-01, -4.1833e-01,\n",
       "        -6.1657e-02,  2.0064e-01, -9.0455e-02,  1.5084e-01, -3.0202e-01,\n",
       "        -4.0329e-01,  3.7133e-01,  3.1638e-02, -1.1160e-01,  2.4170e-01,\n",
       "        -4.9387e-01, -2.2031e-01,  3.7960e-01, -4.5986e-02,  1.0357e-01,\n",
       "         1.4003e-01, -1.0154e-01, -3.4675e-01, -2.8658e-01,  6.5983e-01,\n",
       "        -1.4411e-01, -1.9368e-01,  2.4575e-01, -7.6993e-02, -1.0934e-01,\n",
       "        -4.2768e-02, -1.8456e+00, -2.8545e-01,  7.2854e-01, -6.6174e-02,\n",
       "        -2.5128e-01, -1.4846e-01,  6.3254e-02,  2.8736e-02,  3.5543e-01,\n",
       "         1.6989e-02, -1.9499e-01,  3.2482e-02,  9.5564e-02,  5.8639e-01,\n",
       "        -2.3762e-01,  1.8935e-01, -1.8590e-01,  2.8656e-02,  2.0085e-02,\n",
       "         1.3955e-01,  1.4773e-01,  1.0626e-01, -3.8174e-02, -2.0416e-01,\n",
       "        -8.2518e-02,  2.9651e-01, -6.3937e-02, -2.2353e-01,  6.3388e-02,\n",
       "        -2.6382e-02, -3.3504e-01,  1.5220e-01,  1.8415e-01,  7.3767e-01,\n",
       "        -1.2563e-01,  2.9864e-01, -1.3745e-01, -3.2594e-01, -1.2044e-01,\n",
       "        -4.3157e-01,  6.4578e-01, -3.3792e-02, -1.9826e-01,  7.8966e-01,\n",
       "         2.5423e-01,  2.3918e-01,  4.8837e-01, -8.0837e-02,  7.8629e-03,\n",
       "        -6.8478e-01,  1.7248e-01,  7.5193e-02,  9.4699e-02,  3.6125e-01,\n",
       "        -3.5904e-01,  3.8474e-01, -1.3380e-01,  4.0130e-01,  1.2669e-01,\n",
       "         1.8859e-01, -4.1660e-02,  2.8362e-01, -7.5012e-02,  2.4323e-01,\n",
       "         2.5585e-01,  1.0090e-01,  1.1553e-01, -5.5611e-01,  3.3056e-01,\n",
       "         5.2419e-01,  6.8324e-02,  4.6448e-01,  6.9075e-02, -1.2520e-01,\n",
       "        -1.4330e-01, -2.4757e-01,  1.6746e-01, -7.5622e-01,  2.1216e-01,\n",
       "         1.6144e-01, -2.8452e-01, -8.0855e-03, -2.1397e-01, -3.0391e-01,\n",
       "        -1.5911e-01,  4.2019e-01, -5.5919e-01, -3.0515e-02, -3.6940e-01,\n",
       "        -2.2575e-01,  7.7526e-02,  1.8037e-01,  3.6343e-01,  4.2855e-01,\n",
       "         4.5888e-02,  2.7792e-01,  5.2740e-01, -1.1111e-01, -1.5025e-01,\n",
       "         1.2009e-01,  7.9207e-02, -2.6506e-01,  2.9623e-01, -3.0600e-02,\n",
       "         3.9009e-01,  3.3424e-01, -4.3125e-01, -1.8508e-01, -5.2076e-01,\n",
       "        -1.6136e-01, -1.5845e-01, -2.7887e-01,  7.5152e-01,  2.0119e-01,\n",
       "         3.2341e-01,  4.9306e-02, -6.3844e-02,  1.4384e-01, -2.1880e-01,\n",
       "         2.2695e-01,  6.1874e-01,  5.3254e-01,  1.4728e-01, -2.6153e-01,\n",
       "         2.6855e-01, -4.8916e-01, -3.4154e-01, -3.1716e-01, -1.9547e+00,\n",
       "         4.5308e-01,  5.6225e-02, -6.0259e-02, -8.5050e-02,  2.2200e-01,\n",
       "        -4.8165e-01,  5.0386e-02,  2.8591e-01,  5.0241e-01, -2.0484e-01,\n",
       "         8.6232e-03,  1.2587e-01,  1.3653e-01, -4.4711e-01, -1.4788e-01,\n",
       "        -2.4664e-01, -8.3055e-02, -8.2862e-01,  1.5669e-01, -3.1560e-01,\n",
       "         3.3648e-02,  5.0765e-01,  3.3056e-01, -1.5716e-01, -2.3517e-01,\n",
       "         1.2449e-01,  9.3309e-02, -1.6212e-01, -3.5587e-01,  3.0463e-01,\n",
       "         2.9744e-01,  1.9847e-01,  1.0469e-01, -5.3580e-02, -1.5794e-01,\n",
       "        -4.5976e-01, -2.1984e-01,  3.4505e-03,  2.9027e-02,  6.2270e-02,\n",
       "        -1.7755e-01,  2.1854e-01, -1.3915e-01,  2.3519e-02, -2.9992e-01,\n",
       "        -1.8075e-01,  3.5149e-01, -6.8235e-01, -2.1527e-01, -5.0400e-01,\n",
       "         1.5681e-01,  4.0371e-01,  1.6562e-01,  3.3587e-01, -3.9114e-01,\n",
       "        -4.1541e-01,  5.9359e-01,  4.3457e-02,  1.2720e-01,  3.6175e-01,\n",
       "         2.1335e-01, -3.0120e-01,  5.0625e-02, -3.3768e-01, -5.4410e-02,\n",
       "         1.6656e-01,  7.0567e-02, -3.5305e-01, -2.6111e-01, -6.0375e-02,\n",
       "         1.4895e-01, -9.7141e-02,  7.0041e-01, -3.3353e-01,  6.0551e-02],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addb_vocab_embs['CLITIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.7711e-03, -2.3817e-03,  2.4845e-02,  3.8487e-02, -1.2772e-01,\n",
       "         3.3165e-02,  4.8666e-01, -1.6021e-01,  1.6853e-02,  1.6322e-01,\n",
       "        -1.0224e-01, -5.2618e-02,  3.4685e-02, -1.9040e-02,  3.2686e-02,\n",
       "         3.5499e-02,  6.3939e-02,  3.8428e-02, -1.1650e-02, -2.5398e-03,\n",
       "        -1.5485e-02, -2.3090e-02,  1.1053e-02, -2.8602e-02, -2.3924e-02,\n",
       "         5.4396e-02, -2.7256e-03,  2.9342e-02,  3.3936e-02,  5.7305e-02,\n",
       "         5.9507e-02,  1.0920e-04, -2.3985e-02,  2.5953e-02,  1.0569e-02,\n",
       "         7.6946e-03,  1.8665e-02,  1.7798e-02, -2.5355e-02,  2.4376e-02,\n",
       "         2.5437e-02, -5.5402e-02,  2.5985e-02,  4.1344e-02,  1.8730e-02,\n",
       "         3.6826e-03, -3.2120e-02,  5.6875e-02,  4.6870e-02, -1.3394e-02,\n",
       "        -1.4460e-03,  4.7467e-04,  2.6838e-02,  8.0426e-06, -2.1895e-02,\n",
       "         1.8322e-02, -3.3935e-02, -2.6631e-02,  2.2321e-02, -1.9475e-05,\n",
       "         7.3048e-03,  2.9189e-02, -2.0734e-02, -1.1434e-02,  1.0040e-02,\n",
       "        -2.9709e-02, -6.2757e-03, -4.6265e-02, -4.0179e-02,  3.4336e-02,\n",
       "         7.7573e-02, -2.9712e-02, -1.6156e-02,  9.8200e-03,  1.0996e-02,\n",
       "         7.2783e-02, -3.2693e-02, -3.1668e-02, -1.8598e-02,  2.7129e-02,\n",
       "        -2.0828e-02,  2.2916e-01, -3.2600e-03,  5.9076e-02, -3.6557e-02,\n",
       "        -3.1909e-02, -4.3888e-02,  1.8601e-02, -3.8202e-03,  2.2831e-02,\n",
       "        -5.7948e-04,  4.6076e-02,  5.8365e-03, -5.5786e-03, -1.8426e-02,\n",
       "         1.9070e-01,  4.5444e-01,  1.6276e-02, -3.3623e-02, -1.6447e-02,\n",
       "         1.2305e-02, -7.2236e-02, -6.4585e-02, -1.2625e-02,  1.9059e-02,\n",
       "         2.3224e-02, -3.5476e-02, -2.5446e-03,  3.7693e-03,  2.1223e-02,\n",
       "         5.9036e-03, -9.4872e-04, -1.7324e-02, -1.5915e-02,  6.9584e-02,\n",
       "        -5.9973e-02, -1.1616e-01, -9.1350e-03, -6.2911e-03, -5.0648e-02,\n",
       "         4.6316e-02,  2.8032e-02, -1.8105e-02,  6.1553e-02, -7.7239e-03,\n",
       "         2.6889e-02, -4.0427e-03,  2.9589e-02,  1.4475e-02,  3.0894e-02,\n",
       "        -1.7540e-02, -2.4537e-02,  3.0165e-02,  2.3762e-02, -7.4301e-02,\n",
       "        -1.7090e-02, -2.3775e-02, -5.4935e-03, -3.9262e-02, -2.7193e-01,\n",
       "        -7.7345e-03, -2.7051e-02, -2.1302e-02, -3.7742e-03,  2.4750e-03,\n",
       "         4.4947e-02, -2.8158e-02,  2.1787e-02, -1.2270e-01, -1.9199e-02,\n",
       "         9.0202e-03,  2.7334e-02, -8.6760e-03,  2.3952e-02, -3.9743e-02,\n",
       "         6.3233e-02,  2.6596e-02, -2.6011e-02,  4.1268e-02,  3.1507e-02,\n",
       "        -1.7383e-02,  1.2801e-02,  4.0318e-02,  3.0069e-02, -4.1490e-03,\n",
       "         2.7142e-04, -1.3414e-03, -1.9703e-02, -4.1014e-02,  8.0866e-02,\n",
       "         3.8820e-03,  1.2987e-02,  2.9585e-02,  2.1751e-02,  3.9705e-02,\n",
       "        -6.7644e-02,  2.8961e-02,  3.3712e-02, -5.6041e-02,  1.4678e-02,\n",
       "         1.3548e-02, -4.8581e-02,  7.8216e-03,  3.2894e-02, -2.8622e-02,\n",
       "         4.4341e-02, -5.3621e-02,  1.8796e-02, -1.8202e-02, -3.3977e-03,\n",
       "        -3.1241e-02,  4.1629e-02, -5.8006e-02,  2.1002e-02,  1.4295e-02,\n",
       "         3.9106e-02, -3.8101e-02, -1.9037e-02, -3.1913e-02,  5.7362e-02,\n",
       "         5.0169e-02,  2.0908e-04,  1.3736e-02, -2.7328e-02, -1.6885e-02,\n",
       "        -3.8193e-02, -1.9489e-02, -3.3413e-02, -6.6495e-02,  1.7381e-02,\n",
       "        -4.8202e-02,  2.8117e-02,  7.8632e-02,  3.0881e-02, -2.2783e-03,\n",
       "         1.4133e-02,  1.5680e-02,  4.7377e-02,  1.4976e-02,  1.1558e-02,\n",
       "         4.9961e-02,  1.9379e-02,  1.0125e-02, -2.6128e-02,  5.1457e-01,\n",
       "        -3.7102e-02,  4.4867e-02,  4.0055e-03,  6.8305e-03,  2.6791e-02,\n",
       "        -4.3027e-02, -1.4539e-02, -2.4273e-02,  4.0522e-03,  1.0821e-02,\n",
       "        -5.0199e-02, -1.1919e-02, -1.5112e-02,  5.2869e-02,  5.4153e-02,\n",
       "         1.8666e-02, -9.8638e-03,  7.3563e-02, -1.0613e-01,  3.1946e-03,\n",
       "         2.8483e-02, -2.6555e-02,  7.1444e-02,  3.2869e-02, -4.2948e-02,\n",
       "         7.1629e-03,  2.5399e-02,  5.9469e-02, -1.3297e-02,  1.0383e-02,\n",
       "         5.0468e-03, -1.2967e-02, -1.7890e-03, -5.0442e-02, -5.8529e-02,\n",
       "        -3.5609e-02,  1.3422e-02,  1.3791e-02, -3.2426e-03, -4.9554e-02,\n",
       "         3.2089e-03,  4.3197e-02,  2.6821e-02, -2.5876e-02,  4.5916e-03,\n",
       "        -1.0840e-02,  3.1969e-02,  8.1694e-02, -4.5622e-02,  1.6733e-03,\n",
       "        -3.1976e-02, -4.2784e-02, -3.4856e-02, -4.7064e-02,  2.6085e-02,\n",
       "        -1.7271e-01,  3.5262e-02, -1.0843e-02, -4.2731e-02,  2.1936e-02,\n",
       "        -1.4895e-02, -3.8460e-03, -2.5388e-02,  2.3178e-02,  3.3305e-02,\n",
       "        -4.2066e-03,  1.2332e-02,  5.8009e-02,  2.2685e-02,  2.0582e-03,\n",
       "         1.5814e-02,  1.6214e-02,  1.0196e-02, -4.4902e-02,  1.9747e-02],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(vectors[word2idx['UNK']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace CLITIC emb with UNK token (mistaken for word 'clitic')\n",
    "# mistakenly saved as an np array...overwrote this key with torch.from_numpy(vocab_emb['CLITIC']): saved as addb.vocab.emb.glove.42B.300\n",
    "addb_vocab_embs['CLITIC'] = torch.from_numpy(vectors[word2idx['UNK']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(addb_vocab_embs, open(f'{glove_path}/addb.csr.vocab.glove.42B.300dwords.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "addbvocab = pickle.load(open(f'{glove_path}/addb.csr.vocab.glove.42B.300dwords.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(addbvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addbvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(addbvocab) == list(addb_vocab_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabset_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list generated from preprocessing steps subsumed into get_glovembs()\n",
    "len(unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore CLITIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cookeiejar',\n",
       " \"i-don't-know\",\n",
       " 'cappdf',\n",
       " '//',\n",
       " '',\n",
       " '//',\n",
       " 'alrightie',\n",
       " '..',\n",
       " 'oh-boy',\n",
       " 'hmhunh',\n",
       " 'sewickly',\n",
       " 'tazmania-dutch',\n",
       " 'doctor-dick',\n",
       " 'how-about',\n",
       " 'god-bless-you',\n",
       " '',\n",
       " 'oh-dear',\n",
       " 'how-come',\n",
       " 'i-mean',\n",
       " 'what-about',\n",
       " 'joyce-kilmer',\n",
       " 'the-window-of-the-xxx',\n",
       " 'dave-branton',\n",
       " 'lots-of',\n",
       " 'a-lot-of',\n",
       " 'lee-a']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dl1010",
   "language": "python",
   "name": "dl1010"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
