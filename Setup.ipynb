{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_cookie = torch.load('cookie_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cookie = torch.load('cookie_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_cookie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_sentence = torch.load('sentence_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sentence = torch.load('sentence_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cookie_filenames = torch.load('cookie_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group not listed but control\n",
    "X_cookie_filenames[219]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cookie[219]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cookie_reader.headers()[X_cookie_filenames[219]]['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_cookie_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sent_filenames = torch.load('sentence_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_sent_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(X_cookie_filenames) + len(X_sent_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cookie_reader = pla.read_chat('./Pitt/*/cookie/*.cha')\n",
    "X_sentence_reader = pla.read_chat('./Pitt/*/sentence/*.cha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data -- targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group missing or input error st no mean to replace with and left untouched in target generation\n",
    "\n",
    "replace with closest analog as per means generated from target generation:\n",
    "\n",
    "cookie {'Control': 30, 'ProbableAD': 19, 'MCI': 28, 'Memory': 30, 'Vascular': 17, 'PossibleAD': 20, 'Probable': 19, 'Other': 24}\n",
    "\n",
    "sentence {'ProbableAD': 19, 'MCI': 28, 'Memory': 30, 'Vascular': 17, 'PossibleAD': 21, 'Control': 30, 'Probable': 19, 'Other': 24}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/sentence/236-0.cha\n",
      "674 Dementia\n"
     ]
    }
   ],
   "source": [
    "for sent_k in y_sentence:\n",
    "    if type(y_sentence[sent_k]) == str:\n",
    "        print(X_sent_filenames[sent_k])\n",
    "        print(sent_k,y_sentence[sent_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_674 = X_sentence_retder.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/sentence/236-0.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dementia'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Dementia with Possible mean (as per diagnostic codes in Pitt-data.xlxs and accompanying Pitt-readme.pdf)\n",
    "y_sentence[674] = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha\n",
      "219 \n",
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha\n",
      "511 possibleAD\n"
     ]
    }
   ],
   "source": [
    "for coo_kie in y_cookie:\n",
    "    if type(y_cookie[coo_kie]) == str:\n",
    "        print(X_cookie_filenames[coo_kie])\n",
    "        print(coo_kie,y_cookie[coo_kie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_219 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha']['Participants']['PAR']['education']\n",
    "group_219 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '' with Control mean (as per folder and dx codes in .xlxs)\n",
    "y_cookie[219] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_511 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha']['Participants']['PAR']['education']\n",
    "group_511 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'possibleAD'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace possibleAD with PossibleAD mean\n",
    "y_cookie[511] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm all targets filled now \n",
    "for sent_k in y_sentence:\n",
    "    if type(y_sentence[sent_k]) == str:\n",
    "        print(X_sent_filenames[sent_k])\n",
    "        print(sent_k,y_sentence[sent_k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coo_kie in y_cookie:\n",
    "    if type(y_cookie[coo_kie]) == str:\n",
    "        print(X_cookie_filenames[coo_kie])\n",
    "        print(coo_kie,y_cookie[coo_kie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(y_cookie,'cookie_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(y_sentence,'sentence_target_dict.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Vocab Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = './PretrainedWordEmb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_emb = pickle.load(open(f'{glove_path}/addb.vocab_emb.glove.42B.300.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = torch.load('pos_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(batchsize=1, ix=None):\n",
    "    \n",
    "    minibatch_ix = random.sample(range(num_samples),batchsize) if ix is None else ix \n",
    "    \n",
    "    #index, filename\n",
    "    cookie_files = [(i,X_cookie_filenames[i]) for i in minibatch_ix if i in X_cookie_filenames.keys()]\n",
    "    sent_files = [(i,X_sent_filenames[i] )for i in minibatch_ix if i in X_sent_filenames.keys()]\n",
    "    \n",
    "    embeddings = []\n",
    "    targets = []\n",
    "\n",
    "    for corpus,data,targetdict in [(cookie_files,X_cookie_reader,y_cookie),(sent_files,X_sentence_reader,y_sentence)]: \n",
    "        for file_ix,file in corpus:\n",
    "#             print(file_ix, file)\n",
    "#             print('Words',[tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])\n",
    "#             print('Words_len',len([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance]))\n",
    "            embedding = [(vocab_emb[token],torch.zeros(len(pos_dict),dtype=torch.float64),pos_dict[pos]) for (token,pos) in zip([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance], [pos for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])]\n",
    "            target = targetdict[file_ix]\n",
    "            \n",
    "            for tkn in embedding:\n",
    "\n",
    "                tkn[1][tkn[2]] = 1\n",
    "\n",
    "#                 embeddings.append(torch.cat((tkn[0],tkn[1])))\n",
    "            \n",
    "            embeddings.append([torch.cat((tkn[0],tkn[1])) for tkn in embedding])\n",
    "\n",
    "\n",
    "#             embeddings.append(embedding)\n",
    "            targets.append(target)\n",
    "            \n",
    "#     return embeddings, torch.tensor(targets), minibatch_ix\n",
    "    return embeddings, torch.tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 792)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "e,t,i = get_minibatch(batchsize=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets are [1,30]\n",
    "set([30, 18, 29, 12, 22, 16, 23, 28, 30, 21, 29, 24, 30, 20, 19, 30, 30, 30,\n",
    "        19, 30, 18, 20, 24, 30, 30, 20, 29, 30, 22, 22, 30, 19, 19, 30, 29, 17,\n",
    "        30, 23, 19, 18, 19, 24, 24, 26, 27, 16, 23, 29, 22, 19, 27, 28, 29, 20,\n",
    "        17, 30, 16, 20, 28, 29, 25, 12, 17, 30, 27, 30, 30, 18, 28, 11, 30, 30,\n",
    "        19, 13, 10, 20, 30, 30, 20, 30, 16, 29, 21, 30, 19, 28, 13, 23, 28, 28,\n",
    "        19, 25, 23, 30, 20, 29, 30, 28, 28, 26, 29, 19, 30, 30, 29, 29, 25, 23,\n",
    "        30, 19, 19, 29, 30, 19, 15, 30, 23, 17, 30, 30, 19, 30, 29, 19, 18, 25,\n",
    "        30, 30, 30, 30, 13, 30, 26, 29, 30, 14, 20, 30, 30, 13, 28, 23, 24, 17,\n",
    "        14, 13, 27, 30, 30, 29, 30, 13, 25, 30, 15, 18, 24, 25, 29, 16, 29, 20,\n",
    "        29, 29, 23, 21, 28, 15, 20, 24, 30, 29, 29, 12, 25, 28, 28, 30, 11, 15,\n",
    "        30, 29, 27, 18, 27, 30, 17, 29, 28, 27, 28, 30, 19, 17, 19, 24, 13, 21,\n",
    "        19, 20, 23, 30, 30, 19, 13, 19, 28, 28, 13, 29, 29, 30, 29, 22, 26, 23,\n",
    "        30, 14, 19, 26,  8, 19, 19, 28, 30, 15, 11, 16, 28, 17, 21, 30, 19, 15,\n",
    "        29, 30, 26, 30, 18, 29, 29, 30, 30, 30, 18, 20, 30, 26, 29, 12, 19, 26,\n",
    "        25, 30, 30, 30, 19, 26, 15, 19, 17, 30, 30, 16, 30, 30, 30, 11, 24, 29,\n",
    "        26, 23, 19, 23, 18, 15, 30, 26, 12, 17, 13, 29, 22, 23, 30, 28, 28, 30,\n",
    "        29, 29, 16, 18, 20, 30, 30, 30, 22, 30, 29, 25, 30, 30, 30, 24, 23, 20,\n",
    "        10, 29, 30, 24, 15, 27, 27, 28, 30, 27, 27, 22, 19, 30, 17, 19, 18, 30,\n",
    "        30, 30, 29, 26, 29, 28, 18, 30, 10, 19, 30, 30, 13, 27, 29, 30, 24, 30,\n",
    "        29, 17, 19,  7, 12, 29, 30, 20, 23, 30, 30, 11, 30, 28, 30, 25, 12, 30,\n",
    "        30, 10, 20, 30, 30, 26, 15, 30, 19, 29, 30, 18, 30, 17, 28, 30, 30, 28,\n",
    "        10, 29, 28, 28, 30, 30, 30, 29,  3, 18, 30, 12, 27, 30, 19, 28, 20, 30,\n",
    "        30, 30, 30, 30, 27, 29, 19, 15, 27, 17, 28, 13, 14, 28, 30, 30, 27, 30,\n",
    "        26, 29, 30, 30, 30, 30, 27, 30, 25, 29, 16, 28, 30, 29, 17, 18, 15, 30,\n",
    "        28, 25, 28, 28, 30, 19, 23, 19, 23, 30, 14, 30, 22, 20, 30, 30, 27, 30,\n",
    "        30, 21, 10, 30, 30, 28, 18, 13, 29, 29, 29, 17, 30, 17, 19, 26, 30, 28,\n",
    "        30, 19, 27, 30, 30, 20, 27, 10, 21,  5, 30, 17, 17, 24, 20, 29, 23, 28,\n",
    "        29, 25, 28, 30, 20, 30, 30, 29, 20, 28, 28, 30, 15, 30, 30, 20, 20, 18,\n",
    "        19, 20, 23, 10, 21, 20, 30, 30, 17,  8, 30, 27, 13, 30, 30, 14, 23, 28,\n",
    "        30, 30, 22, 28, 24, 25,  3, 30, 19, 29, 30, 28, 27, 20, 29, 25, 20, 30,\n",
    "        12, 28, 22,  1, 24, 17, 30, 24, 30, 20, 30, 29, 19, 24, 28, 16, 21, 19,\n",
    "        25, 11, 20, 29, 27, 20, 27, 23, 16, 30, 16, 18, 20, 15, 20,  8, 23, 20,\n",
    "        19, 20, 20, 10, 18, 23, 16, 28, 15, 12, 21, 19, 28, 28, 27, 22, 18, 18,\n",
    "        19, 19, 30, 24, 19, 19, 21, 25, 25, 26, 19, 17, 23, 24, 26, 19, 17, 29,\n",
    "        18, 21, 19, 29, 18, 10, 17, 20, 20, 30, 20, 19, 19, 22, 23, 19, 27, 26,\n",
    "        21, 19, 10, 18, 25, 19, 17, 23, 28, 19, 26, 20, 18, 20, 23, 29, 19, 16,\n",
    "        17, 27, 17, 19, 28, 17, 23, 27, 15, 19, 18, 13, 10, 17, 13, 19, 28, 17,\n",
    "         7, 28, 13, 20, 19, 23, 11, 19, 20, 25, 17,  8, 30, 25, 28, 28, 20, 10,\n",
    "        17, 19, 24, 17, 24, 15, 22, 29, 26, 13, 12, 12, 27, 27, 23, 25, 24, 25,\n",
    "        28, 11, 21, 28, 23, 26, 24, 14, 19, 25, 19, 19, 19, 14, 28, 27, 23, 13,\n",
    "        29, 22, 22, 20, 25, 12, 24, 13, 29, 27, 18, 20, 28, 23, 29, 15, 26, 15,\n",
    "        24, 18, 13, 11, 17, 11, 19, 20, 17, 26, 20, 18, 23, 17, 15, 22, 12, 13,\n",
    "        21, 18, 14, 19, 19, 13, 19, 19, 30, 20, 29,  7, 15, 28, 28, 29, 30, 23,\n",
    "        25, 25, 23, 27, 19, 21, 19, 23, 20, 19, 19, 19, 28, 14, 18, 19, 19, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_arr = np.array(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_mask = np.array([type(target) == str for target in t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([788, 504, 695])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_arr[str_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/sentence/704-0.cha\n",
      "23\n",
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/sentence/291-2.cha\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for str_target in [788,695]:\n",
    "    print(X_sent_filenames[str_target])\n",
    "    print(y_sentence[str_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(emb) for emb in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29, 24, 29, 30, 17, 26, 30, 20, 23, 30])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{371}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all words same len of emb size 371 \n",
    "set([len(emb[i]) for emb in e for i in range(len(emb))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq -- with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 layer rnn.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "EMBEDDING_SIZE = 371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, emb_size=371, hidden_size=HIDDEN_SIZE):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        \n",
    "        \n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.gru = nn.GRU(input_size=self.emb_size, hidden_size=self.hidden_size,num_layers=2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # confirm dims here...\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "        \n",
    "        embedded = torch.cat(input).view(len(input), 1, -1)\n",
    "        \n",
    "        output = embedded\n",
    "        \n",
    "#         output, hidden = self.gru(self.emb_size, self.hidden_size)\n",
    "        output, hidden = self.gru(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_minibatch(batchsize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(len(x[0])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hidden = encoder.initHidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 1, 371])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([inp.float() for inp in x[0]]).view(len([inp.float() for inp in x[0]]),1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod .float() in get_embeddings\n",
    "# TODO batch right -- or to train on sequences of difference lengths \n",
    "out = encoder([inp.float() for inp in x[0]],_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 1, 128])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 1, 371])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cat(x[0]).view(len(x[0]), 1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 371])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cat(x[0]).view(len(x[0]), 1, -1)[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max([len(emb) for emb in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "#     def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "    def __init__(self, hidden_size=HIDDEN_SIZE, output_size=1, dropout_p=0.1, max_length=MAX_LENGTH):    \n",
    "    \n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        \n",
    "        #fc\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "#         embedded = torch.cat(input).view(len(input), 1, -1)\n",
    "        embedded = input\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        # unnecessary...predicting one value\n",
    "#         output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = AttnDecoderRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_hidden = decoder.initHidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0060, -0.0245, -0.0464,  ...,  0.0695,  0.0342, -0.0551]],\n",
       "\n",
       "        [[ 0.0537, -0.0173, -0.1303,  ...,  0.0952,  0.0043, -0.0770]],\n",
       "\n",
       "        [[ 0.0549,  0.0048, -0.1962,  ...,  0.0754, -0.0186, -0.1096]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1965,  0.0106, -0.3525,  ...,  0.2107, -0.0763, -0.1470]],\n",
       "\n",
       "        [[ 0.1858, -0.0295, -0.2714,  ...,  0.1975, -0.0800, -0.1494]],\n",
       "\n",
       "        [[ 0.1433, -0.0282, -0.2725,  ...,  0.1491, -0.0575, -0.1883]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0060, -0.0245, -0.0464,  ...,  0.0695,  0.0342, -0.0551]],\n",
       "\n",
       "        [[ 0.0537, -0.0173, -0.1303,  ...,  0.0952,  0.0043, -0.0770]],\n",
       "\n",
       "        [[ 0.0549,  0.0048, -0.1962,  ...,  0.0754, -0.0186, -0.1096]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1965,  0.0106, -0.3525,  ...,  0.2107, -0.0763, -0.1470]],\n",
       "\n",
       "        [[ 0.1858, -0.0295, -0.2714,  ...,  0.1975, -0.0800, -0.1494]],\n",
       "\n",
       "        [[ 0.1433, -0.0282, -0.2725,  ...,  0.1491, -0.0575, -0.1883]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].to(device).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].to(device).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5723e-01,  1.5999e-01, -1.5316e-01,  1.7675e-01, -2.5812e-01,\n",
       "           4.7489e-01,  2.1191e-01, -4.6458e-02, -1.0214e-01,  2.5158e-01,\n",
       "           3.6603e-01,  2.6250e-02, -4.6524e-02, -2.0161e-01, -2.7700e-01,\n",
       "          -5.7927e-02,  1.9463e-01,  1.3949e-01, -2.8001e-01, -2.0826e-01,\n",
       "           6.8004e-01, -1.4004e-01,  1.0250e-01,  2.1201e-01,  3.5271e-01,\n",
       "          -1.4978e-01, -3.3812e-01, -3.2099e-02, -2.5270e-01, -3.1943e-01,\n",
       "           7.4798e-02,  6.0758e-01, -5.9771e-01, -1.0965e-01,  1.8242e-01,\n",
       "           1.0807e-01,  1.1915e-01,  5.6361e-01,  3.9456e-01,  7.9710e-03,\n",
       "          -4.7770e-01,  1.7498e-01, -5.0252e-01,  4.2966e-02,  1.0658e-01,\n",
       "          -9.2730e-02,  9.1547e-02,  7.7902e-03, -3.4490e-01,  3.5609e-01,\n",
       "           2.9160e-01,  3.4331e-01, -9.6344e-02,  3.8138e-01, -2.2851e-01,\n",
       "          -2.5756e-01,  3.5514e-01,  2.0115e-01,  1.1860e-01,  1.0311e-02,\n",
       "           2.0202e-01, -4.0456e-01,  6.0682e-02, -2.0456e-01, -2.1061e-02,\n",
       "          -3.1327e-01,  2.1679e-01, -3.2717e-01, -1.2956e-01, -8.9622e-02,\n",
       "           1.2163e-01, -1.3952e-01,  1.7823e-01, -1.9067e-01, -3.4779e-01,\n",
       "          -4.0128e-01, -3.8428e-01, -3.1446e-01, -3.2945e-01,  4.0243e-02,\n",
       "           1.6010e-01, -4.8730e-02,  3.4257e-03,  2.2410e-01, -1.5628e-01,\n",
       "           3.9718e-02, -3.4121e-01,  5.3389e-02, -2.1122e-01,  1.9786e-01,\n",
       "          -1.0168e-03,  6.6406e-02, -1.1113e-01,  1.3474e-03, -4.3887e-01,\n",
       "           3.0406e-01,  8.0052e-02,  4.7087e-01, -4.8392e-01, -1.4829e-01,\n",
       "          -1.4777e-01,  5.6186e-01, -1.2479e-01,  2.8241e-01,  1.4732e-01,\n",
       "          -3.0798e-01,  3.8584e-01, -8.4204e-02, -3.5891e-01, -5.6632e-02,\n",
       "           1.7505e-01, -1.9294e-01, -3.2657e-01, -4.1122e-02, -1.2814e-01,\n",
       "           6.0926e-02,  2.5229e-01, -8.9133e-04,  2.1926e-01, -2.6708e-01,\n",
       "          -1.3156e-01,  1.8749e-01,  1.1674e-02,  1.6047e-01,  2.8104e-01,\n",
       "          -1.8112e-03, -2.6398e-01,  1.5889e-01]],\n",
       "\n",
       "        [[ 1.4330e-01, -2.8160e-02, -2.7253e-01, -2.1159e-01, -9.1865e-02,\n",
       "           2.3016e-01, -1.9326e-01,  5.3869e-02,  6.9442e-02,  2.9996e-02,\n",
       "          -1.5446e-01, -2.0936e-02,  1.6643e-01,  1.5336e-02,  1.1667e-03,\n",
       "           1.7989e-01, -1.8992e-02,  2.1255e-01, -3.1563e-04, -1.4813e-02,\n",
       "          -2.8875e-02, -7.8578e-02, -3.3935e-02, -1.3566e-01,  7.6635e-02,\n",
       "           1.6937e-01, -2.1261e-01,  1.6421e-02, -8.6880e-02,  1.6153e-01,\n",
       "          -1.4032e-01, -2.8072e-01,  1.2293e-01,  8.0072e-02, -6.6193e-02,\n",
       "          -1.7853e-01, -2.9315e-03, -2.2318e-01, -3.0703e-01, -2.2590e-01,\n",
       "          -4.3205e-03, -2.9151e-01, -8.4244e-02, -1.0588e-01,  1.1057e-01,\n",
       "           2.0269e-01,  9.5587e-02, -2.4270e-01,  1.1075e-03, -3.3889e-01,\n",
       "           2.7359e-01, -1.1423e-01, -3.2622e-02, -3.8472e-03,  1.1763e-01,\n",
       "           1.4291e-01,  7.4120e-02, -1.3591e-01, -5.0060e-02, -1.3046e-01,\n",
       "           1.0717e-01, -2.6232e-01,  1.8451e-01,  1.7628e-01,  3.3406e-02,\n",
       "          -7.5508e-02,  2.8791e-01, -5.7693e-02,  2.4251e-01,  1.6290e-01,\n",
       "          -2.5316e-01, -3.0844e-01, -2.8067e-01,  1.8865e-01, -3.6030e-02,\n",
       "           1.2996e-01,  1.0960e-01, -2.0996e-01,  1.6640e-01, -2.6638e-02,\n",
       "          -1.8704e-01, -9.0023e-02,  1.6692e-01,  4.0083e-01, -4.5856e-02,\n",
       "           8.2002e-02,  2.0011e-01, -1.8588e-01,  2.8147e-02,  1.0997e-02,\n",
       "           8.3186e-02,  1.9039e-01, -2.9955e-02, -6.0836e-02, -5.1880e-02,\n",
       "          -7.3341e-03,  2.2181e-01,  2.4170e-01,  9.9305e-02, -2.1031e-01,\n",
       "          -1.3666e-01, -6.6282e-02, -6.4331e-02, -1.0186e-01,  2.3764e-01,\n",
       "           1.3060e-01, -2.6888e-03, -1.6341e-01,  1.7106e-01,  1.2780e-01,\n",
       "          -6.5506e-02, -1.7860e-01, -1.3370e-01, -1.6844e-01, -3.2597e-01,\n",
       "          -1.0978e-01, -5.9921e-02,  2.5602e-01, -1.5473e-01, -1.6048e-01,\n",
       "          -6.9892e-02, -2.8789e-01,  2.9608e-01, -1.2418e-01, -2.9651e-02,\n",
       "           1.4907e-01, -5.7482e-02, -1.8831e-01]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5723e-01,  1.5999e-01, -1.5316e-01,  1.7675e-01, -2.5812e-01,\n",
       "           4.7489e-01,  2.1191e-01, -4.6458e-02, -1.0214e-01,  2.5158e-01,\n",
       "           3.6603e-01,  2.6250e-02, -4.6524e-02, -2.0161e-01, -2.7700e-01,\n",
       "          -5.7927e-02,  1.9463e-01,  1.3949e-01, -2.8001e-01, -2.0826e-01,\n",
       "           6.8004e-01, -1.4004e-01,  1.0250e-01,  2.1201e-01,  3.5271e-01,\n",
       "          -1.4978e-01, -3.3812e-01, -3.2099e-02, -2.5270e-01, -3.1943e-01,\n",
       "           7.4798e-02,  6.0758e-01, -5.9771e-01, -1.0965e-01,  1.8242e-01,\n",
       "           1.0807e-01,  1.1915e-01,  5.6361e-01,  3.9456e-01,  7.9710e-03,\n",
       "          -4.7770e-01,  1.7498e-01, -5.0252e-01,  4.2966e-02,  1.0658e-01,\n",
       "          -9.2730e-02,  9.1547e-02,  7.7902e-03, -3.4490e-01,  3.5609e-01,\n",
       "           2.9160e-01,  3.4331e-01, -9.6344e-02,  3.8138e-01, -2.2851e-01,\n",
       "          -2.5756e-01,  3.5514e-01,  2.0115e-01,  1.1860e-01,  1.0311e-02,\n",
       "           2.0202e-01, -4.0456e-01,  6.0682e-02, -2.0456e-01, -2.1061e-02,\n",
       "          -3.1327e-01,  2.1679e-01, -3.2717e-01, -1.2956e-01, -8.9622e-02,\n",
       "           1.2163e-01, -1.3952e-01,  1.7823e-01, -1.9067e-01, -3.4779e-01,\n",
       "          -4.0128e-01, -3.8428e-01, -3.1446e-01, -3.2945e-01,  4.0243e-02,\n",
       "           1.6010e-01, -4.8730e-02,  3.4257e-03,  2.2410e-01, -1.5628e-01,\n",
       "           3.9718e-02, -3.4121e-01,  5.3389e-02, -2.1122e-01,  1.9786e-01,\n",
       "          -1.0168e-03,  6.6406e-02, -1.1113e-01,  1.3474e-03, -4.3887e-01,\n",
       "           3.0406e-01,  8.0052e-02,  4.7087e-01, -4.8392e-01, -1.4829e-01,\n",
       "          -1.4777e-01,  5.6186e-01, -1.2479e-01,  2.8241e-01,  1.4732e-01,\n",
       "          -3.0798e-01,  3.8584e-01, -8.4204e-02, -3.5891e-01, -5.6632e-02,\n",
       "           1.7505e-01, -1.9294e-01, -3.2657e-01, -4.1122e-02, -1.2814e-01,\n",
       "           6.0926e-02,  2.5229e-01, -8.9133e-04,  2.1926e-01, -2.6708e-01,\n",
       "          -1.3156e-01,  1.8749e-01,  1.1674e-02,  1.6047e-01,  2.8104e-01,\n",
       "          -1.8112e-03, -2.6398e-01,  1.5889e-01]],\n",
       "\n",
       "        [[ 1.4330e-01, -2.8160e-02, -2.7253e-01, -2.1159e-01, -9.1865e-02,\n",
       "           2.3016e-01, -1.9326e-01,  5.3869e-02,  6.9442e-02,  2.9996e-02,\n",
       "          -1.5446e-01, -2.0936e-02,  1.6643e-01,  1.5336e-02,  1.1667e-03,\n",
       "           1.7989e-01, -1.8992e-02,  2.1255e-01, -3.1563e-04, -1.4813e-02,\n",
       "          -2.8875e-02, -7.8578e-02, -3.3935e-02, -1.3566e-01,  7.6635e-02,\n",
       "           1.6937e-01, -2.1261e-01,  1.6421e-02, -8.6880e-02,  1.6153e-01,\n",
       "          -1.4032e-01, -2.8072e-01,  1.2293e-01,  8.0072e-02, -6.6193e-02,\n",
       "          -1.7853e-01, -2.9315e-03, -2.2318e-01, -3.0703e-01, -2.2590e-01,\n",
       "          -4.3205e-03, -2.9151e-01, -8.4244e-02, -1.0588e-01,  1.1057e-01,\n",
       "           2.0269e-01,  9.5587e-02, -2.4270e-01,  1.1075e-03, -3.3889e-01,\n",
       "           2.7359e-01, -1.1423e-01, -3.2622e-02, -3.8472e-03,  1.1763e-01,\n",
       "           1.4291e-01,  7.4120e-02, -1.3591e-01, -5.0060e-02, -1.3046e-01,\n",
       "           1.0717e-01, -2.6232e-01,  1.8451e-01,  1.7628e-01,  3.3406e-02,\n",
       "          -7.5508e-02,  2.8791e-01, -5.7693e-02,  2.4251e-01,  1.6290e-01,\n",
       "          -2.5316e-01, -3.0844e-01, -2.8067e-01,  1.8865e-01, -3.6030e-02,\n",
       "           1.2996e-01,  1.0960e-01, -2.0996e-01,  1.6640e-01, -2.6638e-02,\n",
       "          -1.8704e-01, -9.0023e-02,  1.6692e-01,  4.0083e-01, -4.5856e-02,\n",
       "           8.2002e-02,  2.0011e-01, -1.8588e-01,  2.8147e-02,  1.0997e-02,\n",
       "           8.3186e-02,  1.9039e-01, -2.9955e-02, -6.0836e-02, -5.1880e-02,\n",
       "          -7.3341e-03,  2.2181e-01,  2.4170e-01,  9.9305e-02, -2.1031e-01,\n",
       "          -1.3666e-01, -6.6282e-02, -6.4331e-02, -1.0186e-01,  2.3764e-01,\n",
       "           1.3060e-01, -2.6888e-03, -1.6341e-01,  1.7106e-01,  1.2780e-01,\n",
       "          -6.5506e-02, -1.7860e-01, -1.3370e-01, -1.6844e-01, -3.2597e-01,\n",
       "          -1.0978e-01, -5.9921e-02,  2.5602e-01, -1.5473e-01, -1.6048e-01,\n",
       "          -6.9892e-02, -2.8789e-01,  2.9608e-01, -1.2418e-01, -2.9651e-02,\n",
       "           1.4907e-01, -5.7482e-02, -1.8831e-01]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/renee/opt/anaconda3/envs/dl1010/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "out1tup = (torch.tensor(out[1][0]),torch.tensor(out[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1572,  0.1600, -0.1532,  0.1767, -0.2581,  0.4749,  0.2119, -0.0465,\n",
       "         -0.1021,  0.2516,  0.3660,  0.0262, -0.0465, -0.2016, -0.2770, -0.0579,\n",
       "          0.1946,  0.1395, -0.2800, -0.2083,  0.6800, -0.1400,  0.1025,  0.2120,\n",
       "          0.3527, -0.1498, -0.3381, -0.0321, -0.2527, -0.3194,  0.0748,  0.6076,\n",
       "         -0.5977, -0.1096,  0.1824,  0.1081,  0.1191,  0.5636,  0.3946,  0.0080,\n",
       "         -0.4777,  0.1750, -0.5025,  0.0430,  0.1066, -0.0927,  0.0915,  0.0078,\n",
       "         -0.3449,  0.3561,  0.2916,  0.3433, -0.0963,  0.3814, -0.2285, -0.2576,\n",
       "          0.3551,  0.2011,  0.1186,  0.0103,  0.2020, -0.4046,  0.0607, -0.2046,\n",
       "         -0.0211, -0.3133,  0.2168, -0.3272, -0.1296, -0.0896,  0.1216, -0.1395,\n",
       "          0.1782, -0.1907, -0.3478, -0.4013, -0.3843, -0.3145, -0.3294,  0.0402,\n",
       "          0.1601, -0.0487,  0.0034,  0.2241, -0.1563,  0.0397, -0.3412,  0.0534,\n",
       "         -0.2112,  0.1979, -0.0010,  0.0664, -0.1111,  0.0013, -0.4389,  0.3041,\n",
       "          0.0801,  0.4709, -0.4839, -0.1483, -0.1478,  0.5619, -0.1248,  0.2824,\n",
       "          0.1473, -0.3080,  0.3858, -0.0842, -0.3589, -0.0566,  0.1751, -0.1929,\n",
       "         -0.3266, -0.0411, -0.1281,  0.0609,  0.2523, -0.0009,  0.2193, -0.2671,\n",
       "         -0.1316,  0.1875,  0.0117,  0.1605,  0.2810, -0.0018, -0.2640,  0.1589]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1tup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4330e-01, -2.8160e-02, -2.7253e-01, -2.1159e-01, -9.1865e-02,\n",
       "          2.3016e-01, -1.9326e-01,  5.3869e-02,  6.9442e-02,  2.9996e-02,\n",
       "         -1.5446e-01, -2.0936e-02,  1.6643e-01,  1.5336e-02,  1.1667e-03,\n",
       "          1.7989e-01, -1.8992e-02,  2.1255e-01, -3.1563e-04, -1.4813e-02,\n",
       "         -2.8875e-02, -7.8578e-02, -3.3935e-02, -1.3566e-01,  7.6635e-02,\n",
       "          1.6937e-01, -2.1261e-01,  1.6421e-02, -8.6880e-02,  1.6153e-01,\n",
       "         -1.4032e-01, -2.8072e-01,  1.2293e-01,  8.0072e-02, -6.6193e-02,\n",
       "         -1.7853e-01, -2.9315e-03, -2.2318e-01, -3.0703e-01, -2.2590e-01,\n",
       "         -4.3205e-03, -2.9151e-01, -8.4244e-02, -1.0588e-01,  1.1057e-01,\n",
       "          2.0269e-01,  9.5587e-02, -2.4270e-01,  1.1075e-03, -3.3889e-01,\n",
       "          2.7359e-01, -1.1423e-01, -3.2622e-02, -3.8472e-03,  1.1763e-01,\n",
       "          1.4291e-01,  7.4120e-02, -1.3591e-01, -5.0060e-02, -1.3046e-01,\n",
       "          1.0717e-01, -2.6232e-01,  1.8451e-01,  1.7628e-01,  3.3406e-02,\n",
       "         -7.5508e-02,  2.8791e-01, -5.7693e-02,  2.4251e-01,  1.6290e-01,\n",
       "         -2.5316e-01, -3.0844e-01, -2.8067e-01,  1.8865e-01, -3.6030e-02,\n",
       "          1.2996e-01,  1.0960e-01, -2.0996e-01,  1.6640e-01, -2.6638e-02,\n",
       "         -1.8704e-01, -9.0023e-02,  1.6692e-01,  4.0083e-01, -4.5856e-02,\n",
       "          8.2002e-02,  2.0011e-01, -1.8588e-01,  2.8147e-02,  1.0997e-02,\n",
       "          8.3186e-02,  1.9039e-01, -2.9955e-02, -6.0836e-02, -5.1880e-02,\n",
       "         -7.3341e-03,  2.2181e-01,  2.4170e-01,  9.9305e-02, -2.1031e-01,\n",
       "         -1.3666e-01, -6.6282e-02, -6.4331e-02, -1.0186e-01,  2.3764e-01,\n",
       "          1.3060e-01, -2.6888e-03, -1.6341e-01,  1.7106e-01,  1.2780e-01,\n",
       "         -6.5506e-02, -1.7860e-01, -1.3370e-01, -1.6844e-01, -3.2597e-01,\n",
       "         -1.0978e-01, -5.9921e-02,  2.5602e-01, -1.5473e-01, -1.6048e-01,\n",
       "         -6.9892e-02, -2.8789e-01,  2.9608e-01, -1.2418e-01, -2.9651e-02,\n",
       "          1.4907e-01, -5.7482e-02, -1.8831e-01]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1tup[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional tensor, but got 4-dimensional tensor for argument #2 'batch2' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-317-33fb6466c9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/dl1010/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-315-c776823a3610>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n\u001b[1;32m     30\u001b[0m         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n\u001b[0;32m---> 31\u001b[0;31m                                  encoder_outputs.unsqueeze(0))\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_applied\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional tensor, but got 4-dimensional tensor for argument #2 'batch2' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "decoder(out[0],out[1],out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 1, 128])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cat(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-312-8789e98f1c70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cat(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "torch.cat(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dl1010",
   "language": "python",
   "name": "dl1010"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
