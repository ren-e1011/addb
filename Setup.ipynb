{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_cookie = torch.load('cookie_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cookie = torch.load('cookie_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_cookie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_sentence = torch.load('sentence_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sentence = torch.load('sentence_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cookie_filenames = torch.load('cookie_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_cookie_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sent_filenames = torch.load('sentence_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_sent_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(X_cookie_filenames) + len(X_sent_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cookie_reader = pla.read_chat('./Pitt/*/cookie/*.cha')\n",
    "X_sentence_reader = pla.read_chat('./Pitt/*/sentence/*.cha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data -- targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group missing or input error st no mean to replace with and left untouched in target generation\n",
    "\n",
    "replace with closest analog as per means generated from target generation:\n",
    "\n",
    "cookie {'Control': 30, 'ProbableAD': 19, 'MCI': 28, 'Memory': 30, 'Vascular': 17, 'PossibleAD': 20, 'Probable': 19, 'Other': 24}\n",
    "\n",
    "sentence {'ProbableAD': 19, 'MCI': 28, 'Memory': 30, 'Vascular': 17, 'PossibleAD': 21, 'Control': 30, 'Probable': 19, 'Other': 24}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent_k in y_sentence:\n",
    "    if type(y_sentence[sent_k]) == str:\n",
    "        print(X_sent_filenames[sent_k])\n",
    "        print(sent_k,y_sentence[sent_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_674 = X_sentence_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/sentence/236-0.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dementia'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Dementia with Possible mean (as per diagnostic codes in Pitt-data.xlxs and accompanying Pitt-readme.pdf)\n",
    "y_sentence[674] = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha\n",
      "219 \n",
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha\n",
      "511 possibleAD\n"
     ]
    }
   ],
   "source": [
    "for coo_kie in y_cookie:\n",
    "    if type(y_cookie[coo_kie]) == str:\n",
    "        print(X_cookie_filenames[coo_kie])\n",
    "        print(coo_kie,y_cookie[coo_kie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_219 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha']['Participants']['PAR']['education']\n",
    "group_219 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '' with Control mean (as per folder and dx codes in .xlxs)\n",
    "y_cookie[219] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_511 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha']['Participants']['PAR']['education']\n",
    "group_511 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'possibleAD'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace possibleAD with PossibleAD mean\n",
    "y_cookie[511] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm all targets filled now \n",
    "for sent_k in y_sentence:\n",
    "    if type(y_sentence[sent_k]) == str:\n",
    "        print(X_sent_filenames[sent_k])\n",
    "        print(sent_k,y_sentence[sent_k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coo_kie in y_cookie:\n",
    "    if type(y_cookie[coo_kie]) == str:\n",
    "        print(X_cookie_filenames[coo_kie])\n",
    "        print(coo_kie,y_cookie[coo_kie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(y_cookie,'cookie_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(y_sentence,'sentence_target_dict.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Vocab Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = './PretrainedWordEmb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_emb = pickle.load(open(f'{glove_path}/addb.vocab_emb.glove.42B.300.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = torch.load('pos_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ix = random.sample(range(num_samples),int(.20*num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ix = [i for i in range(num_samples) if i not in valid_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(valid_ix,'valid_ix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(train_ix,'train_ix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ix = torch.load('valid_ix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ix = torch.load('train_ix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(ix=None,valid=False):\n",
    "    \n",
    "    # first should be...all zeros: each index represents greater than .. but you cant have a zero score..\n",
    "    def num_vectorize(t):\n",
    "\n",
    "        v = torch.zeros([29])\n",
    "        v[:t-1] = 1\n",
    "\n",
    "        return v.double()\n",
    "    \n",
    "    ix = random.randint(1,num_samples-1) if ix is None else ix\n",
    "    \n",
    "    #index, filename\n",
    "    if ix in X_cookie_filenames.keys():\n",
    "        _file = (ix,X_cookie_filenames[ix])\n",
    "        _reader = X_cookie_reader\n",
    "        _targetdict = y_cookie\n",
    "        \n",
    "    else:\n",
    "        _file = (ix,X_sent_filenames[ix])\n",
    "        _reader = X_sentence_reader\n",
    "        _targetdict = y_sentence\n",
    "        \n",
    "    file,data,targetdict = (_file,_reader,_targetdict)\n",
    "    \n",
    "    embeddings = []\n",
    "    targets = []\n",
    "\n",
    "    embedding = [(vocab_emb[token],torch.zeros(len(pos_dict),dtype=torch.float64),pos_dict[pos]) for (token,pos) in zip([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file[1]] for (tokensraw,pos,tokenstem,dependency) in utterance], [pos for utterance in data.tagged_sents(participant='PAR',by_files=True)[file[1]] for (tokensraw,pos,tokenstem,dependency) in utterance])]\n",
    "    target = targetdict[ix]\n",
    "\n",
    "    for tkn in embedding:\n",
    "\n",
    "        tkn[1][tkn[2]] = 1\n",
    "#     print(target)   \n",
    "    if valid: return [torch.cat((tkn[0],tkn[1])) for tkn in embedding], torch.tensor(target)\n",
    "    return [torch.cat((tkn[0],tkn[1])) for tkn in embedding], num_vectorize(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "e,t = get_item(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([371])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_minibatch(minib):\n",
    "    \n",
    "    batchsize = len(minib)\n",
    "    \n",
    "    seq_lens = [len(emb) for emb in minib]\n",
    "    max_len = max(seq_lens)\n",
    "    \n",
    "    # input of shape (seq_len, batch, input_size): tensor containing the features of the input sequence\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "#     seq_tensor = torch.zeros((batchsize, max_len, EMBEDDING_SIZE)).double()\n",
    "    seq_tensor = torch.zeros((max_len, batchsize, EMBEDDING_SIZE)).double()\n",
    "    \n",
    "                  \n",
    "    for i, (seq,length) in enumerate( zip(minib,seq_lens) ):\n",
    "        for wi,word in enumerate(seq):\n",
    "#             seq_tensor[i,wi] = word\n",
    "            seq_tensor[wi,i] = word\n",
    "\n",
    "    return seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pade = pad_minibatch(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 5, 371])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pade.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lens_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 371])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pade[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-1fcb6076b270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-141-1fcb6076b270>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "[e[1 for q in range(len(e[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[torch.equal(pade[q,1],e[1][q]) for q in range(len(e[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41, 371])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pade[1,:41].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize_test = len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_lens_test = [len(emb) for emb in e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 41, 132, 41, 66]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lens_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_test = max(seq_lens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_tensor_test = torch.zeros((batchsize_test, max_len_test ,EMBEDDING_SIZE)).double()\n",
    "seq_tensor_test2 = torch.zeros((max_len_test ,batchsize_test, EMBEDDING_SIZE)).double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (seq, length) in enumerate(zip(e,seq_lens_test2)):\n",
    "    iterator, s, l = i, seq, length\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (seq, length) in enumerate(zip(e,seq_lens_test)):\n",
    "    iterator, s, l = i, seq, length\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wi,word in enumerate(s):\n",
    "    seq_tensor_test[i,wi] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 371])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor_test[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-b78541015139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq_tensor_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_lens_test\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "seq_tensor_test[i,:seq_lens_test,] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 132, 371])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't assign a list to a torch.DoubleTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-b5381dae43a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpade\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-95-49574f37e522>\u001b[0m in \u001b[0;36mpad_minibatch\u001b[0;34m(minib)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_lens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mseq_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_lens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mseq_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't assign a list to a torch.DoubleTensor"
     ]
    }
   ],
   "source": [
    "pade = pad_minibatch(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad with zeros -- maybe\n",
    "# end with eos tensor, tag\n",
    "\n",
    "def get_minibatch(batchsize=1, ix=None):\n",
    "    \n",
    "    \n",
    "    def num_vectorize(targets):\n",
    "        vectors = []\n",
    "        for i in targets:\n",
    "            v = torch.zeros([30])\n",
    "            v[:i] = 1\n",
    "            vectors.append(v)\n",
    "        return vectors\n",
    "    \n",
    "    \n",
    "    minibatch_ix = random.sample(range(num_samples),batchsize) if ix is None else ix \n",
    "    \n",
    "    #index, filename\n",
    "    cookie_files = [(i,X_cookie_filenames[i]) for i in minibatch_ix if i in X_cookie_filenames.keys()]\n",
    "    sent_files = [(i,X_sent_filenames[i] )for i in minibatch_ix if i in X_sent_filenames.keys()]\n",
    "    \n",
    "    embeddings = []\n",
    "    targets = []\n",
    "\n",
    "    for corpus,data,targetdict in [(cookie_files,X_cookie_reader,y_cookie),(sent_files,X_sentence_reader,y_sentence)]: \n",
    "        for file_ix,file in corpus:\n",
    "#             print(file_ix, file)\n",
    "#             print('Words',[tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])\n",
    "#             print('Words_len',len([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance]))\n",
    "            embedding = [(vocab_emb[token],torch.zeros(len(pos_dict),dtype=torch.float64),pos_dict[pos]) for (token,pos) in zip([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance], [pos for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])]\n",
    "            target = targetdict[file_ix]\n",
    "            \n",
    "            for tkn in embedding:\n",
    "\n",
    "                tkn[1][tkn[2]] = 1\n",
    "\n",
    "#                 embeddings.append(torch.cat((tkn[0],tkn[1])))\n",
    "            \n",
    "            embeddings.append([torch.cat((tkn[0],tkn[1])) for tkn in embedding])\n",
    "\n",
    "\n",
    "#             embeddings.append(embedding)\n",
    "            targets.append(target)\n",
    "    print(targets)       \n",
    "#     return embeddings, torch.tensor(targets), minibatch_ix\n",
    "#     return embeddings, torch.tensor(targets)\n",
    "    return embeddings, num_vectorize(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 20, 11, 30, 19]\n"
     ]
    }
   ],
   "source": [
    "e,t = get_minibatch(batchsize=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(emb) for emb in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 30, 26, 29, 19, 23, 28, 26, 23, 19, 29, 30, 29, 30, 29, 20, 30, 20, 29, 30, 21, 5, 30, 30, 29, 19, 15, 13, 29, 10, 16, 15, 30, 7, 30, 30, 28, 30, 30, 20, 28, 29, 13, 30, 26, 30, 24, 25, 24, 30, 25, 30, 19, 19, 19, 28, 24, 28, 30, 17, 28, 18, 30, 30, 27, 25, 30, 19, 29, 30, 26, 17, 10, 30, 28, 17, 30, 15, 27, 30, 30, 22, 30, 29, 27, 21, 30, 19, 15, 17, 27, 16, 30, 28, 24, 26, 19, 30, 29, 26, 15, 30, 30, 30, 22, 29, 28, 22, 30, 26, 30, 30, 28, 28, 30, 17, 20, 27, 25, 30, 28, 30, 20, 23, 30, 30, 30, 29, 29, 30, 20, 17, 19, 17, 15, 30, 21, 28, 22, 28, 29, 10, 28, 22, 22, 13, 30, 15, 29, 19, 28, 20, 30, 20, 29, 30, 30, 29, 30, 29, 29, 29, 30, 19, 19, 27, 18, 28, 28, 12, 30, 30, 12, 29, 30, 3, 30, 23, 19, 30, 11, 12, 19, 30, 24, 24, 29, 19, 16, 19, 30, 28, 25, 20, 30, 25, 20, 29, 10, 30, 30, 19, 30, 28, 15, 30, 29, 8, 20, 24, 30, 30, 28, 29, 28, 23, 30, 23, 29, 30, 30, 28, 16, 30, 30, 20, 26, 13, 28, 27, 30, 30, 30, 30, 23, 28, 18, 29, 24, 22, 30, 11, 13, 21, 30, 26, 13, 28, 20, 23, 23, 27, 25, 30, 21, 30, 18, 28, 28, 1, 19, 28, 29, 30, 11, 12, 13, 29, 29, 30, 30, 28, 30, 20, 30, 30, 19, 30, 28, 30, 26, 26, 18, 30, 18, 16, 29, 17, 19, 30, 29, 30, 27, 30, 19, 19, 30, 30, 17, 23, 20, 20, 17, 30, 30, 20, 29, 27, 20, 10, 18, 19, 30, 29, 12, 30, 27, 28, 17, 28, 28, 17, 19, 30, 28, 21, 24, 3, 30, 25, 22, 30, 23, 23, 25, 22, 27, 30, 29, 30, 13, 24, 28, 25, 29, 26, 17, 17, 19, 24, 23, 23, 23, 10, 22, 30, 29, 18, 30, 23, 30, 30, 29, 27, 27, 19, 26, 30, 19, 27, 20, 28, 20, 11, 27, 19, 18, 24, 20, 30, 30, 30, 13, 13, 10, 17, 12, 16, 14, 29, 12, 13, 25, 24, 19, 30, 29, 30, 23, 30, 27, 30, 19, 30, 18, 30, 30, 22, 30, 30, 18, 19, 28, 26, 15, 30, 30, 30, 30, 19, 28, 10, 30, 30, 30, 14, 30, 29, 23, 30, 20, 16, 18, 19, 18, 20, 14, 18, 26, 29, 23, 29, 29, 23, 30, 24, 25, 17, 28, 19, 27, 21, 24, 30, 30, 20, 27, 24, 30, 17, 19, 16, 13, 30, 29, 15, 19, 15, 28, 19, 17, 25, 30, 17, 19, 29, 16, 30, 11, 30, 29, 30, 29, 12, 30, 30, 30, 18, 30, 30, 27, 18, 27, 30, 29, 29, 29, 29, 28, 30, 25, 30, 19, 30, 20, 30, 15, 30, 19, 30, 29, 28, 30, 28, 18, 14, 30, 29, 30, 18, 30, 15, 27, 17, 20, 8, 25, 30, 13, 30, 29, 20, 20, 30, 12, 30, 20, 29, 19, 17, 30, 30, 13, 23, 30, 14, 28, 30, 21, 14, 30, 29, 21, 19, 26, 19, 27, 26, 19, 23, 28, 29, 8, 20, 10, 12, 30, 17, 19, 18, 15, 24, 23, 15, 20, 19, 13, 28, 23, 23, 22, 29, 23, 27, 19, 12, 19, 12, 19, 18, 25, 20, 20, 19, 17, 22, 13, 23, 17, 19, 26, 29, 27, 24, 20, 8, 21, 28, 21, 27, 19, 23, 18, 28, 19, 27, 18, 22, 29, 29, 29, 23, 16, 21, 23, 18, 19, 19, 13, 27, 13, 17, 19, 22, 25, 30, 13, 10, 28, 18, 19, 23, 19, 18, 30, 20, 27, 11, 19, 20, 20, 24, 28, 22, 20, 19, 26, 19, 16, 19, 25, 17, 24, 19, 21, 17, 23, 13, 28, 17, 15, 20, 20, 19, 27, 13, 17, 30, 30, 14, 29, 7, 21, 19, 20, 20, 13, 24, 16, 11, 17, 24, 13, 19, 20, 27, 25, 7, 21, 25, 15, 28, 19, 23, 17, 17, 23, 24, 15, 25, 20, 30, 19, 23, 18, 17, 19, 19, 14, 25, 12, 17, 17, 15, 25, 20, 10, 28, 10, 14, 26, 28, 19, 19, 28, 12, 19, 16, 15, 11, 18, 27, 26, 27, 18, 20, 20, 29, 19, 20, 10, 19, 19, 18, 13, 18, 23, 16, 19, 23, 14, 20, 25, 26, 29, 28, 26, 28, 28, 11, 22, 17, 25, 15, 25, 11, 19, 18, 24, 24, 18, 28, 28, 21, 25, 19, 20, 28, 19, 19, 29, 23]\n"
     ]
    }
   ],
   "source": [
    "e,t = get_minibatch(batchsize=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/simple-trick-to-train-an-ordinal-regression-with-any-classifier-6911183d2a3c\n",
    "# validate -- accuracy \n",
    "def out_to_score_proba(yhat_vector):\n",
    "    # 29-dim sized vector\n",
    "    proba_vector = torch.zeros([30])\n",
    "    # no zero-score\n",
    "    proba_vector[0] = 0. \n",
    "    # probability == 1 , 1-P(y>1)   \n",
    "    proba_vector[1] = 1-yhat_vector[0]\n",
    "    \n",
    "    for i in range(2,len(yhat_vector)):\n",
    "        proba_vector[i] = yhat_vector[i-1] - yhat_vector[i]\n",
    "        \n",
    "    proba_vector[-1] = yhat_vector[-1] \n",
    "    \n",
    "    print(proba_vector)\n",
    "    return torch.argmax(proba_vector)\n",
    "    if vector[0] == 0: return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5018, 0.4925, 0.4860, 0.4743, 0.4726, 0.4820, 0.5407, 0.5166, 0.5175,\n",
       "        0.4928, 0.4907, 0.4837, 0.4799, 0.5198, 0.4877, 0.5155, 0.4944, 0.4801,\n",
       "        0.4650, 0.5054, 0.5059, 0.4941, 0.5003, 0.5235, 0.5104, 0.4391, 0.4852,\n",
       "        0.5216, 0.5149, 0.4370], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006500000000000006"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".4925 - .4860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000e+00,  4.9823e-01,  6.4766e-03,  1.1666e-02,  1.7491e-03,\n",
      "        -9.4169e-03, -5.8660e-02,  2.4029e-02, -8.6583e-04,  2.4695e-02,\n",
      "         2.1389e-03,  6.9371e-03,  3.8517e-03, -3.9920e-02,  3.2102e-02,\n",
      "        -2.7816e-02,  2.1090e-02,  1.4348e-02,  1.5034e-02, -4.0413e-02,\n",
      "        -4.9319e-04,  1.1883e-02, -6.2801e-03, -2.3158e-02,  1.3134e-02,\n",
      "         7.1215e-02, -4.6066e-02, -3.6440e-02,  6.7199e-03,  4.3695e-01],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_to_score_proba(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_to_score_proba(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy measurement\n",
    "# return summation -- doesnt perfectly handle skipped values\n",
    "# np.where(vector)[0][-1] https://stackoverflow.com/questions/38375401/neural-network-ordinal-classification-for-age\n",
    "def out_to_score_summation(vector):\n",
    "    # zeros array \n",
    "    \n",
    "    return vector.sum() + 1\n",
    "    \n",
    "    if len(np.where(vector)[0]) == 0: return 0\n",
    "#     print ([i+2 for i in np.where(vector)])\n",
    "    print(np.where(vector))\n",
    "    candidate = (np.where(vector)[0][-1]) \n",
    "    \n",
    "    # handling intermediate zeros...maybe not optimal\n",
    "    if np.where(vector)[0][-2] < (candidate - 1): candidate = (np.where(vector)[0][-2] + np.where(vector)[0][-1])/2\n",
    "        \n",
    "    return candidate + 1\n",
    "    # alternative\n",
    "    return vector.sum() + 1\n",
    "#     len(np.where(t)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch of all samples:  longest sample length (for padding, if minibatch)\n",
    "max([len(emb) for emb in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{371}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all words same len of emb size 371 \n",
    "set([len(emb[i]) for emb in e for i in range(len(emb))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq -- with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 layer rnn.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "# EMBEDDING_SIZE = 371\n",
    "# with EOS pos\n",
    "EMBEDDING_SIZE = len(vocab_emb['I']) + len(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max([len(emb) for emb in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change if aadd in EOS, pos to 547\n",
    "MAX_LENGTH = 546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "634/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.8125"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ix)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".8125*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9375"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ix)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".9375*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_dict['EOS'] = len(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOS tag\n",
    "# vocab_emb['EOS'] = torch.rand([300],dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size=MAX_LENGTH, emb_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # what is the input size fo self.embedding...? and is self.embedding necessary\n",
    "#         self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "#         self.gru = nn.GRU(input_size=self.emb_size, hidden_size=self.hidden_size,num_layers=2)\n",
    "# batch_first – If True, then the input and output tensors are provided as (batch, seq, feature) https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "        self.gru = nn.GRU(input_size=self.emb_size,hidden_size=self.hidden_size,num_layers=2).double()\n",
    "#         # each output node Oi of our neural network\n",
    "# uses a standard sigmoid function 1\n",
    "# 1+e−zi\n",
    "# , without including\n",
    "# the outputs from other nodes, as shown in Figure 1. Output\n",
    "# node Oi\n",
    "# is used to estimate the probability oi\n",
    "# that a data\n",
    "# point belongs to category i independently, without subjecting\n",
    "# to normalization as traditional neural networks do. Thus,\n",
    "# for a data point x of category k, the target vector is\n",
    "# (1, , 1, .., 1, 0, 0, 0), in which the first k elements is 1 and\n",
    "# others 0\n",
    "# http://orca.st.usm.edu/~zwang/files/rank.pdf A Neural Network Approach to Ordinal Regression\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size*2,30).double()\n",
    "        \n",
    "        self.activation = nn.Sigmoid()\n",
    "#         self.activations_list = [nn.Sigmoid() for i in range(30)]\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # confirm dims here...\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "        \n",
    "        embedded = input.double()\n",
    "#         embedded = torch.cat(input).view(len(input), batch_size, -1).double()\n",
    "        \n",
    "#         output = embedded\n",
    "        \n",
    "#         output, hidden = self.gru(self.emb_size, self.hidden_size)\n",
    "#         output, hidden = self.gru(output)\n",
    "        gru_out, _ = self.gru(embedded,hidden)\n",
    "        \n",
    "        hid_out = torch.cat((_[-2,:,:], _[-1,:,:]), dim = 1)\n",
    "#         print(gru_out.size(),_.size())\n",
    "    \n",
    "#         lstm_out, _ = self.lstm(embedding.view(len(sentence), -1))\n",
    "        out = self.fc(hid_out)\n",
    "        print(out.size())\n",
    "        \n",
    "#         out = torch.tensor([a(o) for (a,o) in zip(self.activations_list,out[0])],requires_grad=True).double()\n",
    "        out - self.activation(out)\n",
    "        \n",
    "        # any further processing -- int? softmax...? \n",
    "#         return out\n",
    "        return out, _\n",
    "\n",
    "    def initHidden(self,batch_size=BATCH_SIZE):\n",
    "        # h_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2\n",
    "        return torch.zeros(2, batch_size, self.hidden_size, device=device).double()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = torch.ones([158,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "test_act = m(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([158, 30])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_act.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
       "        ...,\n",
       "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311,  ..., 0.7311, 0.7311, 0.7311]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder= EncoderRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pack = nn.utils.rnn.pack_padded_sequence(pad_all_valid_x,lengths=valid_x_lens,enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.utils.rnn.PackedSequence"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([158, 30])\n"
     ]
    }
   ],
   "source": [
    "yhatpack, _ = encoder(test_pack,_hid_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([158, 30])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhatpack.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1788, -0.0023,  0.2569, -0.0905,  0.1914, -0.1614,  0.0171,  0.0897,\n",
       "        -0.0817,  0.0992,  0.1001, -0.0084, -0.2938,  0.0060,  0.1528,  0.1018,\n",
       "        -0.2014, -0.1314, -0.0788, -0.0804,  0.0092,  0.0939, -0.0202,  0.1876,\n",
       "        -0.0398,  0.1013,  0.0640,  0.0624, -0.0851,  0.2401],\n",
       "       dtype=torch.float64, grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhatpack[157]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.9193, -0.0470,  0.1773, -0.2006,  0.2671, -0.1626,  0.0558,\n",
      "        -0.1039,  0.1262, -0.2834,  0.1527,  0.2409, -0.3476, -0.0555,  0.1173,\n",
      "         0.2131, -0.1395,  0.0643, -0.0094, -0.1291,  0.0731, -0.0127, -0.0782,\n",
      "         0.1400,  0.0790, -0.1872,  0.1624,  0.0552,  0.1054],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0.0000,  0.8362, -0.2444,  0.3373, -0.2214,  0.2400, -0.0807, -0.0806,\n",
      "         0.0299, -0.0234, -0.0919,  0.1324,  0.2497, -0.2795, -0.0936,  0.0769,\n",
      "         0.2023, -0.0735, -0.0706, -0.0391, -0.0392, -0.0140,  0.0167,  0.0106,\n",
      "         0.0349, -0.0715,  0.0303,  0.0116,  0.1582,  0.2454],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0.0000,  0.8810, -0.2009,  0.3188, -0.2852,  0.3235, -0.1724, -0.0179,\n",
      "         0.0514, -0.0584, -0.0437,  0.0561,  0.3434, -0.3024, -0.1987,  0.0586,\n",
      "         0.1978, -0.0372,  0.0277,  0.0192, -0.1223, -0.0166,  0.1178, -0.1830,\n",
      "         0.0971, -0.0561,  0.0651,  0.0191,  0.1011,  0.0967],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0.0000,  0.8184, -0.2538,  0.3533, -0.1526,  0.1866, -0.1137, -0.0811,\n",
      "         0.0755, -0.0370, -0.0867,  0.0755,  0.4623, -0.3975, -0.1091,  0.1062,\n",
      "         0.2492, -0.1677,  0.0198, -0.0766, -0.0167, -0.1584,  0.1136, -0.0950,\n",
      "         0.1989, -0.1060, -0.1019,  0.0735,  0.1492,  0.2355],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0.0000,  0.8954, -0.2894,  0.2554, -0.1491,  0.2400, -0.1677, -0.1015,\n",
      "         0.1757, -0.1436, -0.0541,  0.0835,  0.4332, -0.3503, -0.1604,  0.1613,\n",
      "         0.1849, -0.1626, -0.0020, -0.0137, -0.0636, -0.0822,  0.1081, -0.1425,\n",
      "         0.2019, -0.1468,  0.0203, -0.0353,  0.2046,  0.1568],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0.0000,  0.8635, -0.2717,  0.3093, -0.1780,  0.2023, -0.1119, -0.1155,\n",
      "         0.1657, -0.0838, -0.1432,  0.1644,  0.4166, -0.3732, -0.2072,  0.1778,\n",
      "         0.2233, -0.1612, -0.0174, -0.0175, -0.0619, -0.0913,  0.0714, -0.1201,\n",
      "         0.2033, -0.0953, -0.0510,  0.0683,  0.1508,  0.1879],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0.0000,  0.8236, -0.1063,  0.1939,  0.0614,  0.0259, -0.1910,  0.0405,\n",
      "        -0.0566,  0.1711, -0.2126, -0.0230,  0.5598, -0.5186, -0.0389,  0.1036,\n",
      "         0.3128, -0.2371,  0.1091, -0.1274,  0.0144, -0.0637,  0.0123, -0.0236,\n",
      "         0.2518, -0.1439, -0.1367,  0.0472,  0.2490,  0.2903],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0.0000,  0.8774, -0.2161,  0.2910, -0.1613,  0.0626,  0.0813, -0.1570,\n",
      "         0.1573, -0.1592,  0.0902, -0.1024,  0.3384, -0.2872,  0.0149,  0.0477,\n",
      "         0.1519, -0.0830, -0.1531,  0.0831, -0.0305, -0.0391, -0.0458,  0.0125,\n",
      "         0.0810, -0.0938, -0.0264,  0.0764,  0.0793,  0.1327],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0.0000,  0.8737, -0.3062,  0.3309, -0.1736,  0.1832, -0.1364, -0.1536,\n",
      "         0.2683, -0.2012,  0.0071,  0.0321,  0.4272, -0.3481, -0.1363,  0.1191,\n",
      "         0.1707, -0.0887, -0.0428,  0.0568, -0.1606, -0.0660,  0.1291, -0.1796,\n",
      "         0.2629, -0.1341, -0.0288, -0.0193,  0.1388,  0.1939],\n",
      "       grad_fn=<CopySlices>)\n",
      "tensor([ 0.0000,  0.8886, -0.1675,  0.3059, -0.1577,  0.2153, -0.1585, -0.1037,\n",
      "         0.1724, -0.1235, -0.0078, -0.0189,  0.4868, -0.3335, -0.2260,  0.1861,\n",
      "         0.2163, -0.1705, -0.1116,  0.1647, -0.1217, -0.1023,  0.0644, -0.1481,\n",
      "         0.1699, -0.0625, -0.0145,  0.1190,  0.0343,  0.2009],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor(1),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(1)]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[out_to_score_proba(y) for y in yhatpack[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0807,  0.0318,  0.0788,  ..., -0.0805, -0.1357,  0.1054],\n",
       "        [ 0.1638, -0.0103,  0.2341,  ...,  0.0406, -0.1176,  0.2454],\n",
       "        [ 0.1190,  0.0086,  0.2095,  ...,  0.0080, -0.0931,  0.0967],\n",
       "        ...,\n",
       "        [ 0.1824,  0.0310,  0.3300,  ...,  0.0736, -0.0700,  0.3013],\n",
       "        [ 0.1498, -0.0104,  0.2432,  ...,  0.0596, -0.0579,  0.2655],\n",
       "        [ 0.1788, -0.0023,  0.2569,  ...,  0.0624, -0.0851,  0.2401]],\n",
       "       dtype=torch.float64, grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhatpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0218, -0.2005,  0.1678,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1922,  0.2855,  0.0126,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        [ 0.0882,  0.4016, -0.0447,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.3946, -0.0134, -0.2329,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1088,  0.0022,  0.2221,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1088,  0.0022,  0.2221,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pack[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_lens = [len(x) for x in all_valid_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 18, 29, 28, 26, 27, 23, 30, 19, 17, 20, 17, 25, 30, 23, 29, 27, 30, 19, 16, 30, 7, 28, 28, 28, 28, 25, 12, 30, 18, 30, 25, 15, 18, 14, 26, 27, 30, 20, 17, 30, 26, 19, 27, 17, 20, 20, 29, 27, 29, 30, 30, 30, 20, 22, 29, 19, 30, 30, 30, 30, 22, 17, 27, 27, 30, 30, 23, 30, 30, 19, 25, 30, 19, 30, 30, 30, 8, 30, 22, 30, 30, 28, 16, 19, 22, 24, 28, 16, 30, 30, 19, 17, 27, 19, 30, 30, 21, 28, 19, 29, 19, 12, 28, 20, 23, 13, 20, 23, 27, 23, 19, 20, 19, 19, 19, 27, 16, 10, 20, 17, 24, 24, 23, 16, 20, 18, 17, 19, 28, 29, 20, 27, 20, 23, 16, 20, 23, 27, 22, 19, 20, 20, 19, 19, 28, 28, 28, 26, 19, 24, 22, 20, 18, 23, 27, 25, 25]\n"
     ]
    }
   ],
   "source": [
    "all_valid_x,all_valid_y = get_minibatch(ix=valid_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hid_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_all_valid_x = pad_minibatch(all_valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([312, 158, 371])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_all_valid_x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hid_valid = encoder.initHidden(batch_size=len(valid_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_valid, valid_hid = encoder(pad_all_valid_x,_hid_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 158, 128])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_hid_valid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 158, 128])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_hid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_valid.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0807,  0.0318,  0.0788,  ..., -0.0805, -0.1357,  0.1054],\n",
       "        [ 0.1638, -0.0103,  0.2341,  ...,  0.0406, -0.1176,  0.2454],\n",
       "        [ 0.1190,  0.0086,  0.2095,  ...,  0.0080, -0.0931,  0.0967],\n",
       "        ...,\n",
       "        [ 0.1824,  0.0310,  0.3300,  ...,  0.0736, -0.0700,  0.3013],\n",
       "        [ 0.1498, -0.0104,  0.2432,  ...,  0.0596, -0.0579,  0.2655],\n",
       "        [ 0.1788, -0.0023,  0.2569,  ...,  0.0624, -0.0851,  0.2401]],\n",
       "       dtype=torch.float64, grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhatpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-7ec915e6f0b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mout_to_score_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myhat_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-266-7ec915e6f0b9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mout_to_score_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myhat_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-66dae78d665c>\u001b[0m in \u001b[0;36mout_to_score_proba\u001b[0;34m(yhat_vector)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mproba_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# probability == 1 , 1-P(y>1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mproba_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0myhat_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "[out_to_score_proba(y) for y in yhat_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yhat_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5087, 0.4875, 0.5120, 0.4910, 0.4997, 0.4945, 0.5163, 0.5021, 0.4805,\n",
       "        0.5039, 0.4823, 0.5038, 0.5086, 0.5047, 0.5043, 0.4801, 0.5084, 0.5078,\n",
       "        0.5105, 0.4916, 0.4864, 0.4858, 0.5025, 0.4963, 0.4971, 0.4851, 0.4880,\n",
       "        0.4966, 0.4863, 0.5173], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 1, 371])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(x).view(len(x),1,-1).double().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The\n",
    "# cost function for a data point x can be relative entropy\n",
    "# or square error between the target vector and the output\n",
    "# vector\n",
    "# loss = nn.BCELoss()\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO minibatch + pad. For starters, stochastic gd.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hidden = encoder.initHidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = pad_minibatch(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([132, 5, 371])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 132, 371])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat, _hid = encoder(embs,_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4916, 0.4928, 0.5082, 0.4901, 0.4774, 0.4977, 0.4997, 0.4825, 0.4995,\n",
       "        0.4957, 0.4839, 0.5076, 0.4890, 0.4779, 0.4804, 0.4845, 0.5070, 0.5043,\n",
       "        0.4711, 0.5178, 0.5031, 0.4908, 0.4881, 0.4853, 0.4942, 0.4968, 0.4961,\n",
       "        0.4831, 0.4917, 0.4878], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat, hid = encoder(x,_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5018, 0.4925, 0.4860, 0.4743, 0.4726, 0.4820, 0.5407, 0.5166, 0.5175,\n",
       "        0.4928, 0.4907, 0.4837, 0.4799, 0.5198, 0.4877, 0.5155, 0.4944, 0.4801,\n",
       "        0.4650, 0.5054, 0.5059, 0.4941, 0.5003, 0.5235, 0.5104, 0.4391, 0.4852,\n",
       "        0.5216, 0.5149, 0.4370], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_to_score_proba(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2627, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 1\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 2\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 3\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 4\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 5\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 6\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 7\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 8\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 9\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "encoder.train()\n",
    "_hidden = encoder.initHidden()\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('Epoch',epoch)\n",
    "    step = 0\n",
    "    \n",
    "    # in future, mix up epochs \n",
    "    for i in train_ix:\n",
    "        \n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x,y = get_item(i)\n",
    "\n",
    "        yhat, _hidden = encoder(x,_hidden)\n",
    "\n",
    "        loss = loss_func(yhat,y)\n",
    "\n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 20 == 0: \n",
    "            print('step',step)\n",
    "            print('loss',loss)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_minibatch(batchsize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 1, 371])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(x[0]).view(len(x[0]),1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to be able to pass any/all into net\n",
    "# encoder = EncoderRNN(len(x[0])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_hidden.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dl1010",
   "language": "python",
   "name": "dl1010"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
