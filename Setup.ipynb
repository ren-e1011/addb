{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_cookie = torch.load('cookie_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cookie = torch.load('cookie_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_cookie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_sentence = torch.load('sentence_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sentence = torch.load('sentence_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_recall = torch.load('recall_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cookie_filenames = torch.load('cookie_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_cookie_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sent_filenames = torch.load('sentence_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_sent_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_recall_filenames = torch.load('recall_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_recall_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = len(X_cookie_filenames) + len(X_sent_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(X_cookie_filenames) + len(X_sent_filenames) + len(X_recall_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cookie_reader = pla.read_chat('./Pitt/*/cookie/*.cha')\n",
    "X_sentence_reader = pla.read_chat('./Pitt/*/sentence/*.cha')\n",
    "X_recall_reader = pla.read_chat('./Pitt/*/recall/*.cha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data -- targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group missing or input error st no mean to replace with and left untouched in target generation\n",
    "\n",
    "replace with closest analog as per means generated from target generation:\n",
    "\n",
    "cookie {'Control': 30, 'ProbableAD': 19, 'MCI': 28, 'Memory': 30, 'Vascular': 17, 'PossibleAD': 20, 'Probable': 19, 'Other': 24}\n",
    "\n",
    "sentence {'ProbableAD': 19, 'MCI': 28, 'Memory': 30, 'Vascular': 17, 'PossibleAD': 21, 'Control': 30, 'Probable': 19, 'Other': 24}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent_k in y_sentence:\n",
    "    if type(y_sentence[sent_k]) == str:\n",
    "        print(X_sent_filenames[sent_k])\n",
    "        print(sent_k,y_sentence[sent_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_674 = X_sentence_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/sentence/236-0.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dementia'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Dementia with Possible mean (as per diagnostic codes in Pitt-data.xlxs and accompanying Pitt-readme.pdf)\n",
    "y_sentence[674] = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha\n",
      "219 \n",
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha\n",
      "511 possibleAD\n"
     ]
    }
   ],
   "source": [
    "for coo_kie in y_cookie:\n",
    "    if type(y_cookie[coo_kie]) == str:\n",
    "        print(X_cookie_filenames[coo_kie])\n",
    "        print(coo_kie,y_cookie[coo_kie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_219 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha']['Participants']['PAR']['education']\n",
    "group_219 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '' with Control mean (as per folder and dx codes in .xlxs)\n",
    "y_cookie[219] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_511 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha']['Participants']['PAR']['education']\n",
    "group_511 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'possibleAD'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace possibleAD with PossibleAD mean\n",
    "y_cookie[511] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm all targets filled now \n",
    "for sent_k in y_sentence:\n",
    "    if type(y_sentence[sent_k]) == str:\n",
    "        print(X_sent_filenames[sent_k])\n",
    "        print(sent_k,y_sentence[sent_k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coo_kie in y_cookie:\n",
    "    if type(y_cookie[coo_kie]) == str:\n",
    "        print(X_cookie_filenames[coo_kie])\n",
    "        print(coo_kie,y_cookie[coo_kie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(y_cookie,'cookie_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(y_sentence,'sentence_target_dict.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Vocab Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = './PretrainedWordEmb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_emb = pickle.load(open(f'{glove_path}/addb.vocab_emb.glove.42B.300.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_emb = pickle.load(open(f'{glove_path}/addb.csr.vocab.glove.42B.300dwords.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2839"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_dict = torch.load('pos_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = torch.load('pos_cookie_sent_recall_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ix = random.sample(range(num_samples),int(.20*num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ix = [i for i in range(num_samples) if i not in valid_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(valid_ix,'valid_ix_csr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(train_ix,'train_ix_csr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ix = torch.load('valid_ix_csr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ix = torch.load('train_ix_csr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group minibatches of similar size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file index: sequence length\n",
    "ix_size_dict = {}\n",
    "minibatch_ix = train_ix\n",
    "    \n",
    "#index, filename\n",
    "cookie_files = [(i,X_cookie_filenames[i]) for i in minibatch_ix if i in X_cookie_filenames.keys()]\n",
    "sent_files = [(i,X_sent_filenames[i] )for i in minibatch_ix if i in X_sent_filenames.keys()]\n",
    "recall_files = [(i,X_recall_filenames[i] )for i in minibatch_ix if i in X_recall_filenames.keys()]\n",
    "\n",
    "for corpus,data,targetdict in [(cookie_files,X_cookie_reader,y_cookie),(sent_files,X_sentence_reader,y_sentence),(recall_files,X_recall_reader,y_recall)]: \n",
    "    for file_ix,file in corpus:\n",
    "#             print(file_ix, file)\n",
    "#             print('Words',[tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])\n",
    "#             print('Words_len',len([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance]))\n",
    "        embedding = [(vocab_emb[token],torch.zeros(len(pos_dict),dtype=torch.float64),pos_dict[pos]) for (token,pos) in zip([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance], [pos for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])]\n",
    "        ix_size_dict[file_ix] = len(embedding)\n",
    "#         target = targetdict[file_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ix_size_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence length: [file indices]\n",
    "size_ix_dict = {}\n",
    "for k,v in ix_size_dict.items():\n",
    "    if v not in size_ix_dict.keys():\n",
    "        size_ix_dict[v] = [k]\n",
    "    else:\n",
    "        size_ix_dict[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of sequence-lengths\n",
    "len_sents = sorted(list(size_ix_dict.keys()),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = len_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-07747f6bed1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatchset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mminibsize\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mbatchset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_ix_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mminibsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlen_sents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "batches = []\n",
    "while len(len_sents) > 0:\n",
    "    minibsize = 0\n",
    "    batchset = []\n",
    "    while minibsize < 25:\n",
    "        batchset.extend(size_ix_dict[len_sents[0]])\n",
    "        minibsize = len(batchset)\n",
    "        len_sents.pop(0)\n",
    "    batches.append(batchset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append final batchset\n",
    "batches.append(batchset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm all train files accounted for \n",
    "sum([1 for blist in batches for bitem in blist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end with eos tensor, tag\n",
    "\n",
    "def get_minibatch(batchsize=1, ix=None,pad=True):\n",
    "    \n",
    "    \n",
    "    def num_vectorize(targets):\n",
    "        vectors = []\n",
    "        for i in targets:\n",
    "            v = torch.zeros([30])\n",
    "            # up until MMSE index...greater than index i \n",
    "            v[:i] = 1\n",
    "            vectors.append(v)\n",
    "        return torch.stack(vectors).double()\n",
    "    \n",
    "    def pad_minibatch(minib):\n",
    "    \n",
    "        batchsize = len(minib)\n",
    "\n",
    "        seq_lens = [len(emb) for emb in minib]\n",
    "        max_len = max(seq_lens)\n",
    "\n",
    "        # input of shape (seq_len, batch, input_size): tensor containing the features of the input sequence\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
    "    #     seq_tensor = torch.zeros((batchsize, max_len, EMBEDDING_SIZE)).double()\n",
    "        seq_tensor = torch.zeros((max_len, batchsize, EMBEDDING_SIZE)).double()\n",
    "\n",
    "\n",
    "        for i, (seq,length) in enumerate( zip(minib,seq_lens) ):\n",
    "            for wi,word in enumerate(seq):\n",
    "    #             seq_tensor[i,wi] = word\n",
    "                seq_tensor[wi,i] = word\n",
    "        # mod to sort at the start?\n",
    "        seq_tensor = nn.utils.rnn.pack_padded_sequence(seq_tensor,lengths=seq_lens,enforce_sorted=False)\n",
    "        return seq_tensor\n",
    "    \n",
    "    \n",
    "    minibatch_ix = random.sample(range(num_samples),batchsize) if ix is None else ix \n",
    "    \n",
    "    #index, filename\n",
    "    cookie_files = [(i,X_cookie_filenames[i]) for i in minibatch_ix if i in X_cookie_filenames.keys()]\n",
    "    sent_files = [(i,X_sent_filenames[i] )for i in minibatch_ix if i in X_sent_filenames.keys()]\n",
    "    recall_files = [(i,X_recall_filenames[i] )for i in minibatch_ix if i in X_recall_filenames.keys()]\n",
    "    \n",
    "    embeddings = []\n",
    "    targets = []\n",
    "\n",
    "    for corpus,data,targetdict in [(cookie_files,X_cookie_reader,y_cookie),(sent_files,X_sentence_reader,y_sentence),(recall_files,X_recall_reader,y_recall)]: \n",
    "        for file_ix,file in corpus:\n",
    "#             print(file_ix, file)\n",
    "#             print('Words',[tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])\n",
    "#             print('Words_len',len([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance]))\n",
    "            embedding = [(vocab_emb[token],torch.zeros(len(pos_dict),dtype=torch.float64),pos_dict[pos]) for (token,pos) in zip([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance], [pos for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])]\n",
    "            target = targetdict[file_ix]\n",
    "            \n",
    "            for tkn in embedding:\n",
    "\n",
    "                tkn[1][tkn[2]] = 1\n",
    "\n",
    "#                 embeddings.append(torch.cat((tkn[0],tkn[1])))\n",
    "#             try:\n",
    "            embeddings.append([torch.cat((tkn[0],tkn[1])) for tkn in embedding])\n",
    "#             except TypeError:\n",
    "#                 print('TypeError at file_ix,file',file_ix,file)\n",
    "\n",
    "\n",
    "#             embeddings.append(embedding)\n",
    "            targets.append(target)\n",
    "#     print(targets)       \n",
    "#     return embeddings, torch.tensor(targets), minibatch_ix\n",
    "#     return embeddings, torch.tensor(targets)\n",
    "    if pad: embeddings = pad_minibatch(embeddings)\n",
    "# return target vals for accuracy \n",
    "    \n",
    "    return embeddings, num_vectorize(targets), torch.tensor(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "e,nvt,t = get_minibatch(ix=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19, 13, 22, 30, 30, 30, 30, 30, 23, 30, 30, 19, 19, 15, 28, 20, 29, 27,\n",
       "        29, 15, 14, 13, 27, 29, 16, 16])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cookie_files = [(i,X_cookie_filenames[i]) for i in _batch if i in X_cookie_filenames.keys()]\n",
    "_sent_files = [(i,X_sent_filenames[i] )for i in _batch if i in X_sent_filenames.keys()]\n",
    "_recall_files = [(i,X_recall_filenames[i] )for i in _batch if i in X_recall_filenames.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19, 13, 22, 30, 30, 30, 30, 30, 23, 30, 30, 19, 19, 15, 28, 20, 29, 27,\n",
       "        29, 15, 14, 13, 27, 29, 16, 16])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "13\n",
      "22\n",
      "30\n",
      "30\n",
      "\n",
      "30\n",
      "30\n",
      "23\n",
      "30\n",
      "30\n",
      "19\n",
      "19\n",
      "15\n",
      "28\n",
      "20\n",
      "29\n",
      "27\n",
      "29\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "for (fileix,fname) in _cookie_files:\n",
    "    print(X_cookie_reader.headers()[fname]['Participants']['PAR']['education']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for (fileix,fname) in _sent_files:\n",
    "    print(X_sentence_reader.headers()[fname]['Participants']['PAR']['education']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "29\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for (fileix,fname) in _recall_files:\n",
    "    print(X_recall_reader.headers()[fname]['Participants']['PAR']['education']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(449,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/350-0.cha'),\n",
       " (290,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/057-2.cha'),\n",
       " (404,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/257-0.cha'),\n",
       " (32,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/042-1.cha'),\n",
       " (153,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/175-1.cha'),\n",
       " (131,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/145-3.cha'),\n",
       " (73,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/105-0.cha'),\n",
       " (238,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/686-0.cha'),\n",
       " (412,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/270-0.cha'),\n",
       " (144,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/166-1.cha'),\n",
       " (197,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/266-2.cha'),\n",
       " (253,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/010-3.cha'),\n",
       " (499,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/539-0.cha'),\n",
       " (450,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/350-1.cha'),\n",
       " (3,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/002-3.cha'),\n",
       " (436,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/334-1.cha'),\n",
       " (111,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/137-0.cha'),\n",
       " (151,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/172-0.cha'),\n",
       " (25,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/028-1.cha'),\n",
       " (483,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/493-0.cha')]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_cookie_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(730,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/sentence/381-1.cha'),\n",
       " (787,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/sentence/703-0.cha')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sent_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(897,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/recall/184-1.cha'),\n",
       " (1038,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/recall/656-0.cha'),\n",
       " (910,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/recall/216-1.cha'),\n",
       " (960,\n",
       "  '/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/recall/337-0.cha')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_recall_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[449,\n",
       " 897,\n",
       " 1038,\n",
       " 290,\n",
       " 404,\n",
       " 730,\n",
       " 32,\n",
       " 153,\n",
       " 131,\n",
       " 73,\n",
       " 238,\n",
       " 412,\n",
       " 787,\n",
       " 910,\n",
       " 144,\n",
       " 197,\n",
       " 960,\n",
       " 253,\n",
       " 499,\n",
       " 450,\n",
       " 3,\n",
       " 436,\n",
       " 111,\n",
       " 151,\n",
       " 25,\n",
       " 483]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/recall/705-0.cha'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_recall_filenames[1050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/016-1.cha'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cookie_filenames[257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 23, 16, 28, 24, 17, '', 10, 18, 30, 30, 29, 27, 15, 19, 18, 18, 17, 25, 23, 19, 12, 25, 19, 29, 13, 20, 17, 23, 13, 17, 23]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-cf12bf7fd9b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-156-5e5b7d8eeac2>\u001b[0m in \u001b[0;36mget_minibatch\u001b[0;34m(batchsize, ix, pad)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# return target vals for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_vectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-156-5e5b7d8eeac2>\u001b[0m in \u001b[0;36mnum_vectorize\u001b[0;34m(targets)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# up until MMSE index...greater than index i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "get_minibatch(ix=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ix for (ix,fget) in get_minibatch(ix=train_ix)] == train_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/simple-trick-to-train-an-ordinal-regression-with-any-classifier-6911183d2a3c\n",
    "# transform proba dist prediction to MMSE target\n",
    "def out_to_score_proba(yhat_vector):\n",
    "    # mod to 31 for ix 0-30\n",
    "    proba_vector = torch.zeros([31])\n",
    "    # no zero-score\n",
    "    proba_vector[0] = 0. \n",
    "# P(MMSE=i) = P(MMSE>i-1) - P(MMSE>i)\n",
    "    for i in range(1,len(yhat_vector)):\n",
    "        proba_vector[i] = yhat_vector[i-1] - yhat_vector[i]\n",
    "        \n",
    "    proba_vector[-1] = yhat_vector[-1] \n",
    "    \n",
    "#     print(proba_vector)\n",
    "    return torch.argmax(proba_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not on y but on targets as mmse scores\n",
    "def accuracy_distansum(yhat_tensor,y_tensor):\n",
    "    return (torch.abs(y_tensor - yhat_tensor).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw accurate prediction count\n",
    "def accuracy(yhat_tensor,y_tensor):\n",
    "#     return torch.stack([ya==yb for (ya,yb) in zip(yhat_tensor,y_tensor)]).sum()\n",
    "    return ((yhat_tensor == y_tensor).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-layer rnn: gru units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "# EMBEDDING_SIZE = 371\n",
    "EMBEDDING_SIZE = len(vocab_emb['I']) + len(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max([len(emb) for emb in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size=MAX_LENGTH, emb_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(input_size=self.emb_size,hidden_size=self.hidden_size,num_layers=2).double()\n",
    "#         # each output node Oi of our neural network\n",
    "# uses a standard sigmoid function 1\n",
    "# 1+e−zi\n",
    "# , without including\n",
    "# the outputs from other nodes, as shown in Figure 1. Output\n",
    "# node Oi\n",
    "# is used to estimate the probability oi\n",
    "# that a data\n",
    "# point belongs to category i independently, without subjecting\n",
    "# to normalization as traditional neural networks do. Thus,\n",
    "# for a data point x of category k, the target vector is\n",
    "# (1, , 1, .., 1, 0, 0, 0), in which the first k elements is 1 and\n",
    "# others 0\n",
    "# http://orca.st.usm.edu/~zwang/files/rank.pdf A Neural Network Approach to Ordinal Regression\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size*2,30).double()\n",
    "        \n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        embedded = input.double()\n",
    "\n",
    "        gru_out, _ = self.gru(embedded,hidden)\n",
    "        \n",
    "        hid_out = torch.cat((_[-2,:,:], _[-1,:,:]), dim = 1)\n",
    "\n",
    "        out = self.fc(hid_out)\n",
    "#         print(out.size())\n",
    "\n",
    "        out - self.activation(out)\n",
    "\n",
    "        return out, _\n",
    "#         return torch.nn.utils.rnn.pad_packed_sequence(out), _\n",
    "\n",
    "    def initHidden(self,batch_size=BATCH_SIZE):\n",
    "        # h_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2\n",
    "        return torch.zeros(2, batch_size, self.hidden_size, device=device).double()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The\n",
    "# cost function for a data point x can be relative entropy\n",
    "# or square error between the target vector and the output\n",
    "# vector\n",
    "# loss = nn.BCELoss()\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.7171, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(319)\n",
      "step_accurate tensor(0)\n",
      "step 2\n",
      "loss tensor(0.1571, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(194)\n",
      "step_accurate tensor(4)\n",
      "step 3\n",
      "loss tensor(0.5262, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(183)\n",
      "step_accurate tensor(0)\n",
      "step 4\n",
      "loss tensor(0.7324, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(547)\n",
      "step_accurate tensor(0)\n",
      "step 5\n",
      "loss tensor(0.3290, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(255)\n",
      "step_accurate tensor(2)\n",
      "step 6\n",
      "loss tensor(0.3216, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(322)\n",
      "step_accurate tensor(1)\n",
      "step 7\n",
      "loss tensor(0.1632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(361)\n",
      "step_accurate tensor(4)\n",
      "step 8\n",
      "loss tensor(0.2552, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(237)\n",
      "step_accurate tensor(1)\n",
      "step 9\n",
      "loss tensor(0.1479, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(181)\n",
      "step_accurate tensor(1)\n",
      "step 10\n",
      "loss tensor(0.1851, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(354)\n",
      "step_accurate tensor(1)\n",
      "step 11\n",
      "loss tensor(0.1752, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(273)\n",
      "step_accurate tensor(4)\n",
      "step 12\n",
      "loss tensor(0.1702, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(202)\n",
      "step_accurate tensor(1)\n",
      "step 13\n",
      "loss tensor(0.1403, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(363)\n",
      "step_accurate tensor(1)\n",
      "step 14\n",
      "loss tensor(0.1591, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(194)\n",
      "step_accurate tensor(0)\n",
      "step 15\n",
      "loss tensor(0.1355, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(266)\n",
      "step_accurate tensor(2)\n",
      "step 16\n",
      "loss tensor(0.1297, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(171)\n",
      "step_accurate tensor(0)\n",
      "step 17\n",
      "loss tensor(0.1667, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(220)\n",
      "step_accurate tensor(1)\n",
      "step 18\n",
      "loss tensor(0.1471, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(154)\n",
      "step_accurate tensor(1)\n",
      "step 19\n",
      "loss tensor(0.1100, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(162)\n",
      "step_accurate tensor(1)\n",
      "step 20\n",
      "loss tensor(0.1260, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(191)\n",
      "step_accurate tensor(4)\n",
      "step 21\n",
      "loss tensor(0.1353, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(182)\n",
      "step_accurate tensor(4)\n",
      "step 22\n",
      "loss tensor(0.1065, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(196)\n",
      "step_accurate tensor(5)\n",
      "step 23\n",
      "loss tensor(0.1340, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(153)\n",
      "step_accurate tensor(4)\n",
      "step 24\n",
      "loss tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(137)\n",
      "step_accurate tensor(2)\n",
      "step 25\n",
      "loss tensor(0.1566, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(239)\n",
      "step_accurate tensor(1)\n",
      "step 26\n",
      "loss tensor(0.1475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(216)\n",
      "step_accurate tensor(4)\n",
      "step 27\n",
      "loss tensor(0.1096, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(181)\n",
      "step_accurate tensor(1)\n",
      "step 28\n",
      "loss tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(153)\n",
      "step_accurate tensor(4)\n",
      "step 29\n",
      "loss tensor(0.1277, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(112)\n",
      "step_accurate tensor(6)\n",
      "step 30\n",
      "loss tensor(0.1254, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(210)\n",
      "step_accurate tensor(1)\n",
      "step 31\n",
      "loss tensor(0.0970, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(184)\n",
      "step_accurate tensor(3)\n",
      "step 32\n",
      "loss tensor(0.2628, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(12)\n",
      "step_accurate tensor(0)\n",
      "Accurate_total tensor(64.)\n",
      "Distance_total tensor(7124.)\n",
      "Epoch_accuracy tensor(0.0758)\n",
      "Epoch_distance_avg tensor(8.4408)\n",
      "Epoch 1\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.1228, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(272)\n",
      "step_accurate tensor(1)\n",
      "step 2\n",
      "loss tensor(0.1490, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(312)\n",
      "step_accurate tensor(1)\n",
      "step 3\n",
      "loss tensor(0.1562, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(388)\n",
      "step_accurate tensor(2)\n",
      "step 4\n",
      "loss tensor(0.1057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(253)\n",
      "step_accurate tensor(3)\n",
      "step 5\n",
      "loss tensor(0.1056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(132)\n",
      "step_accurate tensor(6)\n",
      "step 6\n",
      "loss tensor(0.1098, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(132)\n",
      "step_accurate tensor(0)\n",
      "step 7\n",
      "loss tensor(0.1464, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(89)\n",
      "step_accurate tensor(5)\n",
      "step 8\n",
      "loss tensor(0.1199, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(139)\n",
      "step_accurate tensor(6)\n",
      "step 9\n",
      "loss tensor(0.1313, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(138)\n",
      "step_accurate tensor(3)\n",
      "step 10\n",
      "loss tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(111)\n",
      "step_accurate tensor(6)\n",
      "step 11\n",
      "loss tensor(0.1238, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(183)\n",
      "step_accurate tensor(3)\n",
      "step 12\n",
      "loss tensor(0.1187, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(109)\n",
      "step_accurate tensor(5)\n",
      "step 13\n",
      "loss tensor(0.1139, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(155)\n",
      "step_accurate tensor(6)\n",
      "step 14\n",
      "loss tensor(0.1208, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(190)\n",
      "step_accurate tensor(7)\n",
      "step 15\n",
      "loss tensor(0.0955, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(191)\n",
      "step_accurate tensor(1)\n",
      "step 16\n",
      "loss tensor(0.1211, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(138)\n",
      "step_accurate tensor(1)\n",
      "step 17\n",
      "loss tensor(0.1005, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(157)\n",
      "step_accurate tensor(0)\n",
      "step 18\n",
      "loss tensor(0.1044, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(88)\n",
      "step_accurate tensor(6)\n",
      "step 19\n",
      "loss tensor(0.1224, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(161)\n",
      "step_accurate tensor(6)\n",
      "step 20\n",
      "loss tensor(0.1054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(141)\n",
      "step_accurate tensor(5)\n",
      "step 21\n",
      "loss tensor(0.1196, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(11)\n",
      "step_accurate tensor(0)\n",
      "step 22\n",
      "loss tensor(0.1219, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(241)\n",
      "step_accurate tensor(6)\n",
      "step 23\n",
      "loss tensor(0.0986, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(86)\n",
      "step_accurate tensor(7)\n",
      "step 24\n",
      "loss tensor(0.1370, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(186)\n",
      "step_accurate tensor(5)\n",
      "step 25\n",
      "loss tensor(0.1068, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(177)\n",
      "step_accurate tensor(5)\n",
      "step 26\n",
      "loss tensor(0.1197, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(164)\n",
      "step_accurate tensor(1)\n",
      "step 27\n",
      "loss tensor(0.0963, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(140)\n",
      "step_accurate tensor(3)\n",
      "step 28\n",
      "loss tensor(0.1279, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(205)\n",
      "step_accurate tensor(4)\n",
      "step 29\n",
      "loss tensor(0.0995, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(172)\n",
      "step_accurate tensor(6)\n",
      "step 30\n",
      "loss tensor(0.1195, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(194)\n",
      "step_accurate tensor(1)\n",
      "step 31\n",
      "loss tensor(0.0958, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(143)\n",
      "step_accurate tensor(6)\n",
      "step 32\n",
      "loss tensor(0.0929, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(116)\n",
      "step_accurate tensor(9)\n",
      "Accurate_total tensor(126.)\n",
      "Distance_total tensor(5314.)\n",
      "Epoch_accuracy tensor(0.1493)\n",
      "Epoch_distance_avg tensor(6.2962)\n",
      "Epoch 2\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0954, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(156)\n",
      "step_accurate tensor(10)\n",
      "step 2\n",
      "loss tensor(0.1235, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(158)\n",
      "step_accurate tensor(3)\n",
      "step 3\n",
      "loss tensor(0.0905, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(169)\n",
      "step_accurate tensor(2)\n",
      "step 4\n",
      "loss tensor(0.0940, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(134)\n",
      "step_accurate tensor(6)\n",
      "step 5\n",
      "loss tensor(0.0904, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(118)\n",
      "step_accurate tensor(7)\n",
      "step 6\n",
      "loss tensor(0.0930, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(118)\n",
      "step_accurate tensor(8)\n",
      "step 7\n",
      "loss tensor(0.0851, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(207)\n",
      "step_accurate tensor(5)\n",
      "step 8\n",
      "loss tensor(0.0686, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(133)\n",
      "step_accurate tensor(9)\n",
      "step 9\n",
      "loss tensor(0.4629, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 10\n",
      "loss tensor(0.1035, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(137)\n",
      "step_accurate tensor(7)\n",
      "step 11\n",
      "loss tensor(0.1263, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(109)\n",
      "step_accurate tensor(9)\n",
      "step 12\n",
      "loss tensor(0.1074, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(146)\n",
      "step_accurate tensor(6)\n",
      "step 13\n",
      "loss tensor(0.0923, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(153)\n",
      "step_accurate tensor(4)\n",
      "step 14\n",
      "loss tensor(0.1168, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(101)\n",
      "step_accurate tensor(8)\n",
      "step 15\n",
      "loss tensor(0.1088, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(112)\n",
      "step_accurate tensor(6)\n",
      "step 16\n",
      "loss tensor(0.1372, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(220)\n",
      "step_accurate tensor(6)\n",
      "step 17\n",
      "loss tensor(0.1092, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(186)\n",
      "step_accurate tensor(5)\n",
      "step 18\n",
      "loss tensor(0.1236, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(207)\n",
      "step_accurate tensor(2)\n",
      "step 19\n",
      "loss tensor(0.1114, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(136)\n",
      "step_accurate tensor(3)\n",
      "step 20\n",
      "loss tensor(0.0988, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(135)\n",
      "step_accurate tensor(4)\n",
      "step 21\n",
      "loss tensor(0.1027, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(161)\n",
      "step_accurate tensor(6)\n",
      "step 22\n",
      "loss tensor(0.0810, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(190)\n",
      "step_accurate tensor(2)\n",
      "step 23\n",
      "loss tensor(0.1331, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(173)\n",
      "step_accurate tensor(4)\n",
      "step 24\n",
      "loss tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(166)\n",
      "step_accurate tensor(6)\n",
      "step 25\n",
      "loss tensor(0.0942, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(104)\n",
      "step_accurate tensor(2)\n",
      "step 26\n",
      "loss tensor(0.1108, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(233)\n",
      "step_accurate tensor(4)\n",
      "step 27\n",
      "loss tensor(0.1009, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(169)\n",
      "step_accurate tensor(3)\n",
      "step 28\n",
      "loss tensor(0.1085, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(133)\n",
      "step_accurate tensor(3)\n",
      "step 29\n",
      "loss tensor(0.0980, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(160)\n",
      "step_accurate tensor(3)\n",
      "step 30\n",
      "loss tensor(0.1148, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(127)\n",
      "step_accurate tensor(7)\n",
      "step 31\n",
      "loss tensor(0.0964, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(144)\n",
      "step_accurate tensor(8)\n",
      "step 32\n",
      "loss tensor(0.0884, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(150)\n",
      "step_accurate tensor(3)\n",
      "Accurate_total tensor(162.)\n",
      "Distance_total tensor(4745.)\n",
      "Epoch_accuracy tensor(0.1919)\n",
      "Epoch_distance_avg tensor(5.6220)\n",
      "Epoch 3\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0560, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(99)\n",
      "step_accurate tensor(12)\n",
      "step 2\n",
      "loss tensor(0.1229, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(105)\n",
      "step_accurate tensor(3)\n",
      "step 3\n",
      "loss tensor(0.0749, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(130)\n",
      "step_accurate tensor(4)\n",
      "step 4\n",
      "loss tensor(0.0852, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(162)\n",
      "step_accurate tensor(8)\n",
      "step 5\n",
      "loss tensor(0.0784, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(110)\n",
      "step_accurate tensor(6)\n",
      "step 6\n",
      "loss tensor(0.0827, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(85)\n",
      "step_accurate tensor(8)\n",
      "step 7\n",
      "loss tensor(0.0786, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 8\n",
      "loss tensor(0.0840, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(126)\n",
      "step_accurate tensor(6)\n",
      "step 9\n",
      "loss tensor(0.0919, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(130)\n",
      "step_accurate tensor(6)\n",
      "step 10\n",
      "loss tensor(0.1393, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(163)\n",
      "step_accurate tensor(2)\n",
      "step 11\n",
      "loss tensor(0.0823, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(201)\n",
      "step_accurate tensor(7)\n",
      "step 12\n",
      "loss tensor(0.0781, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(108)\n",
      "step_accurate tensor(5)\n",
      "step 13\n",
      "loss tensor(0.0811, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(120)\n",
      "step_accurate tensor(5)\n",
      "step 14\n",
      "loss tensor(0.0994, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(103)\n",
      "step_accurate tensor(2)\n",
      "step 15\n",
      "loss tensor(0.0957, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(130)\n",
      "step_accurate tensor(5)\n",
      "step 16\n",
      "loss tensor(0.0813, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(159)\n",
      "step_accurate tensor(9)\n",
      "step 17\n",
      "loss tensor(0.0663, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(139)\n",
      "step_accurate tensor(7)\n",
      "step 18\n",
      "loss tensor(0.0833, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(118)\n",
      "step_accurate tensor(10)\n",
      "step 19\n",
      "loss tensor(0.0815, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(107)\n",
      "step_accurate tensor(9)\n",
      "step 20\n",
      "loss tensor(0.0685, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(89)\n",
      "step_accurate tensor(10)\n",
      "step 21\n",
      "loss tensor(0.0667, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(66)\n",
      "step_accurate tensor(10)\n",
      "step 22\n",
      "loss tensor(0.0956, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(143)\n",
      "step_accurate tensor(6)\n",
      "step 23\n",
      "loss tensor(0.0792, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(70)\n",
      "step_accurate tensor(9)\n",
      "step 24\n",
      "loss tensor(0.0554, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(77)\n",
      "step_accurate tensor(4)\n",
      "step 25\n",
      "loss tensor(0.0778, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(115)\n",
      "step_accurate tensor(7)\n",
      "step 26\n",
      "loss tensor(0.0614, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(76)\n",
      "step_accurate tensor(7)\n",
      "step 27\n",
      "loss tensor(0.0948, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(118)\n",
      "step_accurate tensor(5)\n",
      "step 28\n",
      "loss tensor(0.0878, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(88)\n",
      "step_accurate tensor(9)\n",
      "step 29\n",
      "loss tensor(0.0795, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(160)\n",
      "step_accurate tensor(7)\n",
      "step 30\n",
      "loss tensor(0.0926, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(111)\n",
      "step_accurate tensor(5)\n",
      "step 31\n",
      "loss tensor(0.0621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(97)\n",
      "step_accurate tensor(7)\n",
      "step 32\n",
      "loss tensor(0.0807, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(144)\n",
      "step_accurate tensor(5)\n",
      "Accurate_total tensor(206.)\n",
      "Distance_total tensor(3649.)\n",
      "Epoch_accuracy tensor(0.2441)\n",
      "Epoch_distance_avg tensor(4.3235)\n",
      "Epoch 4\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0661, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(133)\n",
      "step_accurate tensor(5)\n",
      "step 2\n",
      "loss tensor(0.0551, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(56)\n",
      "step_accurate tensor(12)\n",
      "step 3\n",
      "loss tensor(0.0847, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(156)\n",
      "step_accurate tensor(4)\n",
      "step 4\n",
      "loss tensor(0.0497, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(83)\n",
      "step_accurate tensor(16)\n",
      "step 5\n",
      "loss tensor(0.0436, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(55)\n",
      "step_accurate tensor(11)\n",
      "step 6\n",
      "loss tensor(0.0617, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(89)\n",
      "step_accurate tensor(10)\n",
      "step 7\n",
      "loss tensor(0.0654, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(100)\n",
      "step_accurate tensor(6)\n",
      "step 8\n",
      "loss tensor(0.0469, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(43)\n",
      "step_accurate tensor(10)\n",
      "step 9\n",
      "loss tensor(0.0543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(108)\n",
      "step_accurate tensor(8)\n",
      "step 10\n",
      "loss tensor(0.0497, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(93)\n",
      "step_accurate tensor(14)\n",
      "step 11\n",
      "loss tensor(0.0746, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(110)\n",
      "step_accurate tensor(7)\n",
      "step 12\n",
      "loss tensor(0.0403, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(72)\n",
      "step_accurate tensor(14)\n",
      "step 13\n",
      "loss tensor(0.0654, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(67)\n",
      "step_accurate tensor(11)\n",
      "step 14\n",
      "loss tensor(0.0500, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(48)\n",
      "step_accurate tensor(13)\n",
      "step 15\n",
      "loss tensor(0.0439, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(58)\n",
      "step_accurate tensor(10)\n",
      "step 16\n",
      "loss tensor(0.0764, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(103)\n",
      "step_accurate tensor(5)\n",
      "step 17\n",
      "loss tensor(0.0402, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(58)\n",
      "step_accurate tensor(12)\n",
      "step 18\n",
      "loss tensor(0.0684, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(100)\n",
      "step_accurate tensor(9)\n",
      "step 19\n",
      "loss tensor(0.0682, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(116)\n",
      "step_accurate tensor(9)\n",
      "step 20\n",
      "loss tensor(0.0597, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(100)\n",
      "step_accurate tensor(9)\n",
      "step 21\n",
      "loss tensor(0.0646, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(125)\n",
      "step_accurate tensor(7)\n",
      "step 22\n",
      "loss tensor(0.0511, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(64)\n",
      "step_accurate tensor(8)\n",
      "step 23\n",
      "loss tensor(0.0728, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(57)\n",
      "step_accurate tensor(12)\n",
      "step 24\n",
      "loss tensor(0.0413, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 25\n",
      "loss tensor(0.0801, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(132)\n",
      "step_accurate tensor(8)\n",
      "step 26\n",
      "loss tensor(0.0534, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(61)\n",
      "step_accurate tensor(10)\n",
      "step 27\n",
      "loss tensor(0.0460, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(92)\n",
      "step_accurate tensor(9)\n",
      "step 28\n",
      "loss tensor(0.0576, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(102)\n",
      "step_accurate tensor(8)\n",
      "step 29\n",
      "loss tensor(0.0681, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(44)\n",
      "step_accurate tensor(12)\n",
      "step 30\n",
      "loss tensor(0.0881, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(187)\n",
      "step_accurate tensor(3)\n",
      "step 31\n",
      "loss tensor(0.0736, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(91)\n",
      "step_accurate tensor(7)\n",
      "step 32\n",
      "loss tensor(0.0646, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(95)\n",
      "step_accurate tensor(5)\n",
      "Accurate_total tensor(285.)\n",
      "Distance_total tensor(2798.)\n",
      "Epoch_accuracy tensor(0.3377)\n",
      "Epoch_distance_avg tensor(3.3152)\n",
      "Saving..\n",
      "Epoch 5\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0764, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(96)\n",
      "step_accurate tensor(6)\n",
      "step 2\n",
      "loss tensor(0.0504, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(39)\n",
      "step_accurate tensor(17)\n",
      "step 3\n",
      "loss tensor(0.0365, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(41)\n",
      "step_accurate tensor(11)\n",
      "step 4\n",
      "loss tensor(0.0553, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(31)\n",
      "step_accurate tensor(18)\n",
      "step 5\n",
      "loss tensor(0.0524, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(62)\n",
      "step_accurate tensor(9)\n",
      "step 6\n",
      "loss tensor(0.0372, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(55)\n",
      "step_accurate tensor(16)\n",
      "step 7\n",
      "loss tensor(0.0417, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(38)\n",
      "step_accurate tensor(14)\n",
      "step 8\n",
      "loss tensor(0.0554, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(90)\n",
      "step_accurate tensor(15)\n",
      "step 9\n",
      "loss tensor(0.0431, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(64)\n",
      "step_accurate tensor(13)\n",
      "step 10\n",
      "loss tensor(0.0598, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(106)\n",
      "step_accurate tensor(11)\n",
      "step 11\n",
      "loss tensor(0.0474, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(54)\n",
      "step_accurate tensor(10)\n",
      "step 12\n",
      "loss tensor(0.0487, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(45)\n",
      "step_accurate tensor(15)\n",
      "step 13\n",
      "loss tensor(0.0386, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(41)\n",
      "step_accurate tensor(14)\n",
      "step 14\n",
      "loss tensor(0.0546, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(89)\n",
      "step_accurate tensor(10)\n",
      "step 15\n",
      "loss tensor(0.0400, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(49)\n",
      "step_accurate tensor(15)\n",
      "step 16\n",
      "loss tensor(0.0600, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(139)\n",
      "step_accurate tensor(7)\n",
      "step 17\n",
      "loss tensor(0.0829, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 18\n",
      "loss tensor(0.0691, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(82)\n",
      "step_accurate tensor(9)\n",
      "step 19\n",
      "loss tensor(0.0433, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(52)\n",
      "step_accurate tensor(9)\n",
      "step 20\n",
      "loss tensor(0.0535, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(50)\n",
      "step_accurate tensor(11)\n",
      "step 21\n",
      "loss tensor(0.0706, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(75)\n",
      "step_accurate tensor(14)\n",
      "step 22\n",
      "loss tensor(0.0511, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(64)\n",
      "step_accurate tensor(14)\n",
      "step 23\n",
      "loss tensor(0.0480, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(84)\n",
      "step_accurate tensor(9)\n",
      "step 24\n",
      "loss tensor(0.0454, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(66)\n",
      "step_accurate tensor(11)\n",
      "step 25\n",
      "loss tensor(0.0683, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(87)\n",
      "step_accurate tensor(10)\n",
      "step 26\n",
      "loss tensor(0.0612, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(88)\n",
      "step_accurate tensor(7)\n",
      "step 27\n",
      "loss tensor(0.0608, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(104)\n",
      "step_accurate tensor(8)\n",
      "step 28\n",
      "loss tensor(0.0607, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(99)\n",
      "step_accurate tensor(8)\n",
      "step 29\n",
      "loss tensor(0.0633, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(70)\n",
      "step_accurate tensor(9)\n",
      "step 30\n",
      "loss tensor(0.0463, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(67)\n",
      "step_accurate tensor(12)\n",
      "step 31\n",
      "loss tensor(0.0637, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(122)\n",
      "step_accurate tensor(11)\n",
      "step 32\n",
      "loss tensor(0.0747, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(128)\n",
      "step_accurate tensor(7)\n",
      "Accurate_total tensor(351.)\n",
      "Distance_total tensor(2277.)\n",
      "Epoch_accuracy tensor(0.4159)\n",
      "Epoch_distance_avg tensor(2.6979)\n",
      "Saving..\n",
      "Epoch 6\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0385, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(53)\n",
      "step_accurate tensor(15)\n",
      "step 2\n",
      "loss tensor(0.0441, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(93)\n",
      "step_accurate tensor(12)\n",
      "step 3\n",
      "loss tensor(0.0412, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(35)\n",
      "step_accurate tensor(12)\n",
      "step 4\n",
      "loss tensor(0.0695, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(113)\n",
      "step_accurate tensor(10)\n",
      "step 5\n",
      "loss tensor(0.0441, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(66)\n",
      "step_accurate tensor(14)\n",
      "step 6\n",
      "loss tensor(0.0387, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(35)\n",
      "step_accurate tensor(13)\n",
      "step 7\n",
      "loss tensor(0.0352, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(91)\n",
      "step_accurate tensor(14)\n",
      "step 8\n",
      "loss tensor(0.0650, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(99)\n",
      "step_accurate tensor(7)\n",
      "step 9\n",
      "loss tensor(0.2126, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(7)\n",
      "step_accurate tensor(0)\n",
      "step 10\n",
      "loss tensor(0.0363, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(33)\n",
      "step_accurate tensor(19)\n",
      "step 11\n",
      "loss tensor(0.0748, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(124)\n",
      "step_accurate tensor(8)\n",
      "step 12\n",
      "loss tensor(0.0547, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(74)\n",
      "step_accurate tensor(14)\n",
      "step 13\n",
      "loss tensor(0.0449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(111)\n",
      "step_accurate tensor(12)\n",
      "step 14\n",
      "loss tensor(0.0663, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(62)\n",
      "step_accurate tensor(9)\n",
      "step 15\n",
      "loss tensor(0.0748, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(75)\n",
      "step_accurate tensor(12)\n",
      "step 16\n",
      "loss tensor(0.0438, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(41)\n",
      "step_accurate tensor(15)\n",
      "step 17\n",
      "loss tensor(0.0618, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(111)\n",
      "step_accurate tensor(9)\n",
      "step 18\n",
      "loss tensor(0.0554, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(103)\n",
      "step_accurate tensor(10)\n",
      "step 19\n",
      "loss tensor(0.0539, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(106)\n",
      "step_accurate tensor(8)\n",
      "step 20\n",
      "loss tensor(0.0513, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(41)\n",
      "step_accurate tensor(16)\n",
      "step 21\n",
      "loss tensor(0.0407, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(49)\n",
      "step_accurate tensor(17)\n",
      "step 22\n",
      "loss tensor(0.0458, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(69)\n",
      "step_accurate tensor(13)\n",
      "step 23\n",
      "loss tensor(0.0533, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(91)\n",
      "step_accurate tensor(12)\n",
      "step 24\n",
      "loss tensor(0.0316, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(61)\n",
      "step_accurate tensor(15)\n",
      "step 25\n",
      "loss tensor(0.0372, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(54)\n",
      "step_accurate tensor(13)\n",
      "step 26\n",
      "loss tensor(0.0466, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(121)\n",
      "step_accurate tensor(10)\n",
      "step 27\n",
      "loss tensor(0.0484, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(69)\n",
      "step_accurate tensor(12)\n",
      "step 28\n",
      "loss tensor(0.0446, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(49)\n",
      "step_accurate tensor(14)\n",
      "step 29\n",
      "loss tensor(0.0593, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(112)\n",
      "step_accurate tensor(9)\n",
      "step 30\n",
      "loss tensor(0.0428, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(54)\n",
      "step_accurate tensor(10)\n",
      "step 31\n",
      "loss tensor(0.0415, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(52)\n",
      "step_accurate tensor(13)\n",
      "step 32\n",
      "loss tensor(0.0404, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(27)\n",
      "step_accurate tensor(14)\n",
      "Accurate_total tensor(381.)\n",
      "Distance_total tensor(2281.)\n",
      "Epoch_accuracy tensor(0.4514)\n",
      "Epoch_distance_avg tensor(2.7026)\n",
      "Saving..\n",
      "Epoch 7\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0324, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(35)\n",
      "step_accurate tensor(19)\n",
      "step 2\n",
      "loss tensor(0.0280, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(11)\n",
      "step_accurate tensor(21)\n",
      "step 3\n",
      "loss tensor(0.0400, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(33)\n",
      "step_accurate tensor(13)\n",
      "step 4\n",
      "loss tensor(0.0482, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(61)\n",
      "step_accurate tensor(19)\n",
      "step 5\n",
      "loss tensor(0.0329, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(12)\n",
      "step_accurate tensor(19)\n",
      "step 6\n",
      "loss tensor(0.0413, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(64)\n",
      "step_accurate tensor(11)\n",
      "step 7\n",
      "loss tensor(0.0393, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(70)\n",
      "step_accurate tensor(16)\n",
      "step 8\n",
      "loss tensor(0.0498, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 9\n",
      "loss tensor(0.0494, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(84)\n",
      "step_accurate tensor(8)\n",
      "step 10\n",
      "loss tensor(0.0296, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(33)\n",
      "step_accurate tensor(17)\n",
      "step 11\n",
      "loss tensor(0.0300, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(41)\n",
      "step_accurate tensor(15)\n",
      "step 12\n",
      "loss tensor(0.0512, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(109)\n",
      "step_accurate tensor(10)\n",
      "step 13\n",
      "loss tensor(0.0346, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(34)\n",
      "step_accurate tensor(15)\n",
      "step 14\n",
      "loss tensor(0.0374, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(49)\n",
      "step_accurate tensor(14)\n",
      "step 15\n",
      "loss tensor(0.0413, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(28)\n",
      "step_accurate tensor(13)\n",
      "step 16\n",
      "loss tensor(0.0363, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(50)\n",
      "step_accurate tensor(14)\n",
      "step 17\n",
      "loss tensor(0.0369, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(56)\n",
      "step_accurate tensor(15)\n",
      "step 18\n",
      "loss tensor(0.0487, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(66)\n",
      "step_accurate tensor(13)\n",
      "step 19\n",
      "loss tensor(0.0420, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(52)\n",
      "step_accurate tensor(11)\n",
      "step 20\n",
      "loss tensor(0.0370, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(51)\n",
      "step_accurate tensor(18)\n",
      "step 21\n",
      "loss tensor(0.0407, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(16)\n",
      "step_accurate tensor(18)\n",
      "step 22\n",
      "loss tensor(0.0325, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(32)\n",
      "step_accurate tensor(11)\n",
      "step 23\n",
      "loss tensor(0.0320, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(82)\n",
      "step_accurate tensor(19)\n",
      "step 24\n",
      "loss tensor(0.0314, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(40)\n",
      "step_accurate tensor(14)\n",
      "step 25\n",
      "loss tensor(0.0492, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(67)\n",
      "step_accurate tensor(15)\n",
      "step 26\n",
      "loss tensor(0.0300, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(20)\n",
      "step_accurate tensor(19)\n",
      "step 27\n",
      "loss tensor(0.0315, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(22)\n",
      "step_accurate tensor(19)\n",
      "step 28\n",
      "loss tensor(0.0250, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(22)\n",
      "step_accurate tensor(16)\n",
      "step 29\n",
      "loss tensor(0.0298, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(18)\n",
      "step_accurate tensor(19)\n",
      "step 30\n",
      "loss tensor(0.0283, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(20)\n",
      "step_accurate tensor(15)\n",
      "step 31\n",
      "loss tensor(0.0267, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(21)\n",
      "step_accurate tensor(15)\n",
      "step 32\n",
      "loss tensor(0.0382, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(50)\n",
      "step_accurate tensor(16)\n",
      "Accurate_total tensor(478.)\n",
      "Distance_total tensor(1349.)\n",
      "Epoch_accuracy tensor(0.5664)\n",
      "Epoch_distance_avg tensor(1.5983)\n",
      "Saving..\n",
      "Epoch 8\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0341, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(43)\n",
      "step_accurate tensor(17)\n",
      "step 2\n",
      "loss tensor(0.0356, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(36)\n",
      "step_accurate tensor(14)\n",
      "step 3\n",
      "loss tensor(0.0257, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(39)\n",
      "step_accurate tensor(20)\n",
      "step 4\n",
      "loss tensor(0.0178, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(19)\n",
      "step_accurate tensor(21)\n",
      "step 5\n",
      "loss tensor(0.0260, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(28)\n",
      "step_accurate tensor(19)\n",
      "step 6\n",
      "loss tensor(0.0249, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(18)\n",
      "step_accurate tensor(18)\n",
      "step 7\n",
      "loss tensor(0.0285, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(11)\n",
      "step_accurate tensor(19)\n",
      "step 8\n",
      "loss tensor(0.0295, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(16)\n",
      "step_accurate tensor(13)\n",
      "step 9\n",
      "loss tensor(0.0287, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(32)\n",
      "step_accurate tensor(19)\n",
      "step 10\n",
      "loss tensor(0.0278, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(8)\n",
      "step_accurate tensor(22)\n",
      "step 11\n",
      "loss tensor(0.0238, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(16)\n",
      "step_accurate tensor(21)\n",
      "step 12\n",
      "loss tensor(0.0242, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(8)\n",
      "step_accurate tensor(19)\n",
      "step 13\n",
      "loss tensor(0.0211, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(12)\n",
      "step_accurate tensor(22)\n",
      "step 14\n",
      "loss tensor(0.0253, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(9)\n",
      "step_accurate tensor(22)\n",
      "step 15\n",
      "loss tensor(0.0332, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(45)\n",
      "step_accurate tensor(13)\n",
      "step 16\n",
      "loss tensor(0.0238, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(24)\n",
      "step_accurate tensor(16)\n",
      "step 17\n",
      "loss tensor(0.0293, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(17)\n",
      "step_accurate tensor(14)\n",
      "step 18\n",
      "loss tensor(0.0349, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(68)\n",
      "step_accurate tensor(10)\n",
      "step 19\n",
      "loss tensor(0.0274, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(19)\n",
      "step_accurate tensor(17)\n",
      "step 20\n",
      "loss tensor(0.0380, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(79)\n",
      "step_accurate tensor(16)\n",
      "step 21\n",
      "loss tensor(0.0231, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(38)\n",
      "step_accurate tensor(17)\n",
      "step 22\n",
      "loss tensor(0.0344, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(18)\n",
      "step_accurate tensor(20)\n",
      "step 23\n",
      "loss tensor(0.0196, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(8)\n",
      "step_accurate tensor(21)\n",
      "step 24\n",
      "loss tensor(0.0243, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(26)\n",
      "step_accurate tensor(16)\n",
      "step 25\n",
      "loss tensor(0.0233, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(18)\n",
      "step_accurate tensor(15)\n",
      "step 26\n",
      "loss tensor(0.0161, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(12)\n",
      "step_accurate tensor(17)\n",
      "step 27\n",
      "loss tensor(0.0424, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(64)\n",
      "step_accurate tensor(11)\n",
      "step 28\n",
      "loss tensor(0.0374, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(33)\n",
      "step_accurate tensor(20)\n",
      "step 29\n",
      "loss tensor(0.0293, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(28)\n",
      "step_accurate tensor(19)\n",
      "step 30\n",
      "loss tensor(0.0266, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(24)\n",
      "step_accurate tensor(16)\n",
      "step 31\n",
      "loss tensor(0.0375, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 32\n",
      "loss tensor(0.0296, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(16)\n",
      "step_accurate tensor(19)\n",
      "Accurate_total tensor(544.)\n",
      "Distance_total tensor(832.)\n",
      "Epoch_accuracy tensor(0.6445)\n",
      "Epoch_distance_avg tensor(0.9858)\n",
      "Saving..\n",
      "Epoch 9\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0246, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(10)\n",
      "step_accurate tensor(22)\n",
      "step 2\n",
      "loss tensor(0.0191, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(10)\n",
      "step_accurate tensor(23)\n",
      "step 3\n",
      "loss tensor(0.0137, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 4\n",
      "loss tensor(0.0206, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 5\n",
      "loss tensor(0.0458, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(9)\n",
      "step_accurate tensor(24)\n",
      "step 6\n",
      "loss tensor(0.0214, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(19)\n",
      "step_accurate tensor(16)\n",
      "step 7\n",
      "loss tensor(0.0269, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(58)\n",
      "step_accurate tensor(16)\n",
      "step 8\n",
      "loss tensor(0.0207, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(10)\n",
      "step_accurate tensor(22)\n",
      "step 9\n",
      "loss tensor(0.0340, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(23)\n",
      "step_accurate tensor(13)\n",
      "step 10\n",
      "loss tensor(0.1249, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 11\n",
      "loss tensor(0.0246, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(16)\n",
      "step_accurate tensor(18)\n",
      "step 12\n",
      "loss tensor(0.0298, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(7)\n",
      "step_accurate tensor(20)\n",
      "step 13\n",
      "loss tensor(0.0228, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(12)\n",
      "step_accurate tensor(21)\n",
      "step 14\n",
      "loss tensor(0.0268, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(32)\n",
      "step_accurate tensor(19)\n",
      "step 15\n",
      "loss tensor(0.0168, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(7)\n",
      "step_accurate tensor(19)\n",
      "step 16\n",
      "loss tensor(0.0316, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(75)\n",
      "step_accurate tensor(18)\n",
      "step 17\n",
      "loss tensor(0.0275, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(20)\n",
      "step_accurate tensor(18)\n",
      "step 18\n",
      "loss tensor(0.0295, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(13)\n",
      "step_accurate tensor(19)\n",
      "step 19\n",
      "loss tensor(0.0228, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(16)\n",
      "step_accurate tensor(22)\n",
      "step 20\n",
      "loss tensor(0.0370, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(21)\n",
      "step_accurate tensor(14)\n",
      "step 21\n",
      "loss tensor(0.0443, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(27)\n",
      "step_accurate tensor(21)\n",
      "step 22\n",
      "loss tensor(0.0339, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(32)\n",
      "step_accurate tensor(22)\n",
      "step 23\n",
      "loss tensor(0.0221, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(12)\n",
      "step_accurate tensor(20)\n",
      "step 24\n",
      "loss tensor(0.0361, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(36)\n",
      "step_accurate tensor(15)\n",
      "step 25\n",
      "loss tensor(0.0241, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(22)\n",
      "step_accurate tensor(19)\n",
      "step 26\n",
      "loss tensor(0.0230, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(21)\n",
      "step 27\n",
      "loss tensor(0.0332, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(64)\n",
      "step_accurate tensor(18)\n",
      "step 28\n",
      "loss tensor(0.0231, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(22)\n",
      "step_accurate tensor(19)\n",
      "step 29\n",
      "loss tensor(0.0283, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(38)\n",
      "step_accurate tensor(17)\n",
      "step 30\n",
      "loss tensor(0.0211, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(15)\n",
      "step_accurate tensor(17)\n",
      "step 31\n",
      "loss tensor(0.0290, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(48)\n",
      "step_accurate tensor(16)\n",
      "step 32\n",
      "loss tensor(0.0206, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(19)\n",
      "step_accurate tensor(17)\n",
      "Accurate_total tensor(594.)\n",
      "Distance_total tensor(702.)\n",
      "Epoch_accuracy tensor(0.7038)\n",
      "Epoch_distance_avg tensor(0.8318)\n",
      "Saving..\n",
      "Epoch 10\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0190, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(24)\n",
      "step 2\n",
      "loss tensor(0.0194, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(21)\n",
      "step 3\n",
      "loss tensor(0.0270, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(17)\n",
      "step_accurate tensor(18)\n",
      "step 4\n",
      "loss tensor(0.0260, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(15)\n",
      "step_accurate tensor(18)\n",
      "step 5\n",
      "loss tensor(0.0304, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(11)\n",
      "step_accurate tensor(18)\n",
      "step 6\n",
      "loss tensor(0.0231, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(26)\n",
      "step_accurate tensor(20)\n",
      "step 7\n",
      "loss tensor(0.0205, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(11)\n",
      "step_accurate tensor(21)\n",
      "step 8\n",
      "loss tensor(0.0446, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(31)\n",
      "step_accurate tensor(19)\n",
      "step 9\n",
      "loss tensor(0.0252, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(15)\n",
      "step_accurate tensor(18)\n",
      "step 10\n",
      "loss tensor(0.0306, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(30)\n",
      "step_accurate tensor(19)\n",
      "step 11\n",
      "loss tensor(0.0221, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(21)\n",
      "step_accurate tensor(23)\n",
      "step 12\n",
      "loss tensor(0.0207, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(7)\n",
      "step_accurate tensor(24)\n",
      "step 13\n",
      "loss tensor(0.0212, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 14\n",
      "loss tensor(0.0209, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 15\n",
      "loss tensor(0.0219, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(13)\n",
      "step_accurate tensor(17)\n",
      "step 16\n",
      "loss tensor(0.0224, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(23)\n",
      "step 17\n",
      "loss tensor(0.0298, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(32)\n",
      "step_accurate tensor(23)\n",
      "step 18\n",
      "loss tensor(0.0214, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(14)\n",
      "step_accurate tensor(19)\n",
      "step 19\n",
      "loss tensor(0.0244, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(23)\n",
      "step 20\n",
      "loss tensor(0.0231, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 21\n",
      "loss tensor(0.0206, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(22)\n",
      "step 22\n",
      "loss tensor(0.0255, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(24)\n",
      "step 23\n",
      "loss tensor(0.0234, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(27)\n",
      "step_accurate tensor(15)\n",
      "step 24\n",
      "loss tensor(0.0251, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(23)\n",
      "step_accurate tensor(23)\n",
      "step 25\n",
      "loss tensor(0.0216, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(9)\n",
      "step_accurate tensor(21)\n",
      "step 26\n",
      "loss tensor(0.0222, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(23)\n",
      "step_accurate tensor(23)\n",
      "step 27\n",
      "loss tensor(0.0153, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 28\n",
      "loss tensor(0.0181, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(20)\n",
      "step 29\n",
      "loss tensor(0.0241, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(9)\n",
      "step_accurate tensor(19)\n",
      "step 30\n",
      "loss tensor(0.0254, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(38)\n",
      "step_accurate tensor(18)\n",
      "step 31\n",
      "loss tensor(0.0210, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(11)\n",
      "step_accurate tensor(21)\n",
      "step 32\n",
      "loss tensor(0.0267, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(18)\n",
      "step_accurate tensor(20)\n",
      "Accurate_total tensor(644.)\n",
      "Distance_total tensor(437.)\n",
      "Epoch_accuracy tensor(0.7630)\n",
      "Epoch_distance_avg tensor(0.5178)\n",
      "Saving..\n",
      "Epoch 11\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0155, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(23)\n",
      "step 2\n",
      "loss tensor(0.0236, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(21)\n",
      "step_accurate tensor(24)\n",
      "step 3\n",
      "loss tensor(0.0163, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(23)\n",
      "step 4\n",
      "loss tensor(0.0123, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 5\n",
      "loss tensor(0.0188, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(28)\n",
      "step 6\n",
      "loss tensor(0.0246, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(22)\n",
      "step 7\n",
      "loss tensor(0.0208, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(23)\n",
      "step 8\n",
      "loss tensor(0.0196, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(23)\n",
      "step 9\n",
      "loss tensor(0.0151, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(26)\n",
      "step 10\n",
      "loss tensor(0.0184, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(15)\n",
      "step_accurate tensor(20)\n",
      "step 11\n",
      "loss tensor(0.0216, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(21)\n",
      "step_accurate tensor(22)\n",
      "step 12\n",
      "loss tensor(0.0128, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(8)\n",
      "step_accurate tensor(22)\n",
      "step 13\n",
      "loss tensor(0.0172, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(24)\n",
      "step 14\n",
      "loss tensor(0.0141, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 15\n",
      "loss tensor(0.0218, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(21)\n",
      "step_accurate tensor(22)\n",
      "step 16\n",
      "loss tensor(0.0169, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(23)\n",
      "step 17\n",
      "loss tensor(0.0156, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(24)\n",
      "step 18\n",
      "loss tensor(0.0239, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(24)\n",
      "step_accurate tensor(17)\n",
      "step 19\n",
      "loss tensor(0.0140, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(32)\n",
      "step_accurate tensor(22)\n",
      "step 20\n",
      "loss tensor(0.0140, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(24)\n",
      "step 21\n",
      "loss tensor(0.0145, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(23)\n",
      "step 22\n",
      "loss tensor(0.0125, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(23)\n",
      "step 23\n",
      "loss tensor(0.0147, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(22)\n",
      "step 24\n",
      "loss tensor(0.0142, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 25\n",
      "loss tensor(0.0215, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(14)\n",
      "step_accurate tensor(25)\n",
      "step 26\n",
      "loss tensor(0.0162, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(7)\n",
      "step_accurate tensor(21)\n",
      "step 27\n",
      "loss tensor(0.0179, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(21)\n",
      "step_accurate tensor(19)\n",
      "step 28\n",
      "loss tensor(0.0181, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(8)\n",
      "step_accurate tensor(20)\n",
      "step 29\n",
      "loss tensor(0.0187, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(22)\n",
      "step_accurate tensor(27)\n",
      "step 30\n",
      "loss tensor(0.0114, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 31\n",
      "loss tensor(0.0195, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(12)\n",
      "step_accurate tensor(22)\n",
      "step 32\n",
      "loss tensor(0.0246, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(30)\n",
      "step_accurate tensor(19)\n",
      "Accurate_total tensor(707.)\n",
      "Distance_total tensor(323.)\n",
      "Epoch_accuracy tensor(0.8377)\n",
      "Epoch_distance_avg tensor(0.3827)\n",
      "Saving..\n",
      "Epoch 12\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0130, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(7)\n",
      "step_accurate tensor(21)\n",
      "step 2\n",
      "loss tensor(0.0162, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(14)\n",
      "step_accurate tensor(26)\n",
      "step 3\n",
      "loss tensor(0.0150, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(21)\n",
      "step 4\n",
      "loss tensor(0.0172, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 5\n",
      "loss tensor(0.0128, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 6\n",
      "loss tensor(0.0153, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 7\n",
      "loss tensor(0.0134, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 8\n",
      "loss tensor(0.0119, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 9\n",
      "loss tensor(0.0165, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(29)\n",
      "step 10\n",
      "loss tensor(0.0154, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(24)\n",
      "step 11\n",
      "loss tensor(0.0124, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(28)\n",
      "step 12\n",
      "loss tensor(0.0118, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(24)\n",
      "step 13\n",
      "loss tensor(0.0125, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 14\n",
      "loss tensor(0.0119, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(21)\n",
      "step 15\n",
      "loss tensor(0.0126, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(25)\n",
      "step 16\n",
      "loss tensor(0.0179, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(22)\n",
      "step 17\n",
      "loss tensor(0.0128, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(24)\n",
      "step 18\n",
      "loss tensor(0.0145, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(26)\n",
      "step 19\n",
      "loss tensor(0.0145, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(25)\n",
      "step 20\n",
      "loss tensor(0.0122, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(32)\n",
      "step 21\n",
      "loss tensor(0.0123, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(7)\n",
      "step_accurate tensor(20)\n",
      "step 22\n",
      "loss tensor(0.0112, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 23\n",
      "loss tensor(0.0099, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(25)\n",
      "step 24\n",
      "loss tensor(0.0204, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(7)\n",
      "step_accurate tensor(23)\n",
      "step 25\n",
      "loss tensor(0.0172, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(21)\n",
      "step 26\n",
      "loss tensor(0.0208, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(24)\n",
      "step_accurate tensor(20)\n",
      "step 27\n",
      "loss tensor(0.0115, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(25)\n",
      "step 28\n",
      "loss tensor(0.0126, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 29\n",
      "loss tensor(0.0156, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(22)\n",
      "step 30\n",
      "loss tensor(0.0119, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(24)\n",
      "step 31\n",
      "loss tensor(0.0211, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(9)\n",
      "step_accurate tensor(27)\n",
      "step 32\n",
      "loss tensor(0.0116, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(25)\n",
      "Accurate_total tensor(749.)\n",
      "Distance_total tensor(146.)\n",
      "Epoch_accuracy tensor(0.8874)\n",
      "Epoch_distance_avg tensor(0.1730)\n",
      "Saving..\n",
      "Epoch 13\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0078, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(24)\n",
      "step 2\n",
      "loss tensor(0.0152, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(29)\n",
      "step 3\n",
      "loss tensor(0.0109, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 4\n",
      "loss tensor(0.0136, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(9)\n",
      "step_accurate tensor(22)\n",
      "step 5\n",
      "loss tensor(0.0118, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 6\n",
      "loss tensor(0.0118, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(27)\n",
      "step 7\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 8\n",
      "loss tensor(0.0127, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(7)\n",
      "step_accurate tensor(28)\n",
      "step 9\n",
      "loss tensor(0.0100, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 10\n",
      "loss tensor(0.0083, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(23)\n",
      "step 11\n",
      "loss tensor(0.0155, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 12\n",
      "loss tensor(0.0093, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(24)\n",
      "step 13\n",
      "loss tensor(0.0100, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(22)\n",
      "step 14\n",
      "loss tensor(0.0120, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(26)\n",
      "step 15\n",
      "loss tensor(0.0151, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(9)\n",
      "step_accurate tensor(27)\n",
      "step 16\n",
      "loss tensor(0.0091, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 17\n",
      "loss tensor(0.0163, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(16)\n",
      "step_accurate tensor(21)\n",
      "step 18\n",
      "loss tensor(0.0090, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(28)\n",
      "step 19\n",
      "loss tensor(0.0097, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 20\n",
      "loss tensor(0.0107, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 21\n",
      "loss tensor(0.0096, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(22)\n",
      "step 22\n",
      "loss tensor(0.0090, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 23\n",
      "loss tensor(0.0113, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(23)\n",
      "step 24\n",
      "loss tensor(0.0077, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 25\n",
      "loss tensor(0.0125, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(29)\n",
      "step 26\n",
      "loss tensor(0.0076, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 27\n",
      "loss tensor(0.0156, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(25)\n",
      "step 28\n",
      "loss tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 29\n",
      "loss tensor(0.0096, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(24)\n",
      "step 30\n",
      "loss tensor(0.0122, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(29)\n",
      "step 31\n",
      "loss tensor(0.0131, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(13)\n",
      "step_accurate tensor(27)\n",
      "step 32\n",
      "loss tensor(0.0121, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "Accurate_total tensor(778.)\n",
      "Distance_total tensor(110.)\n",
      "Epoch_accuracy tensor(0.9218)\n",
      "Epoch_distance_avg tensor(0.1303)\n",
      "Saving..\n",
      "Epoch 14\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0096, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 2\n",
      "loss tensor(0.0064, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 3\n",
      "loss tensor(0.0100, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(29)\n",
      "step 4\n",
      "loss tensor(0.0076, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 5\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 6\n",
      "loss tensor(0.0075, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 7\n",
      "loss tensor(0.0085, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(24)\n",
      "step 8\n",
      "loss tensor(0.0066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 9\n",
      "loss tensor(0.0071, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 10\n",
      "loss tensor(0.0119, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(5)\n",
      "step_accurate tensor(28)\n",
      "step 11\n",
      "loss tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 12\n",
      "loss tensor(0.0132, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(31)\n",
      "step 13\n",
      "loss tensor(0.0085, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 14\n",
      "loss tensor(0.0099, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 15\n",
      "loss tensor(0.0094, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "step 16\n",
      "loss tensor(0.0090, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(23)\n",
      "step 17\n",
      "loss tensor(0.0093, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 18\n",
      "loss tensor(0.0091, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 19\n",
      "loss tensor(0.0081, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 20\n",
      "loss tensor(0.0107, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(25)\n",
      "step 21\n",
      "loss tensor(0.0157, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(17)\n",
      "step_accurate tensor(25)\n",
      "step 22\n",
      "loss tensor(0.0076, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(25)\n",
      "step 23\n",
      "loss tensor(0.0054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 24\n",
      "loss tensor(0.0074, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(23)\n",
      "step 25\n",
      "loss tensor(0.0097, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(25)\n",
      "step 26\n",
      "loss tensor(0.0090, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(31)\n",
      "step 27\n",
      "loss tensor(0.0093, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 28\n",
      "loss tensor(0.0099, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(24)\n",
      "step 29\n",
      "loss tensor(0.0102, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(24)\n",
      "step 30\n",
      "loss tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(26)\n",
      "step 31\n",
      "loss tensor(0.0089, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(31)\n",
      "step 32\n",
      "loss tensor(0.0092, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(30)\n",
      "Accurate_total tensor(804.)\n",
      "Distance_total tensor(68.)\n",
      "Epoch_accuracy tensor(0.9526)\n",
      "Epoch_distance_avg tensor(0.0806)\n",
      "Saving..\n",
      "Epoch 15\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0085, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 2\n",
      "loss tensor(0.0075, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 3\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(25)\n",
      "step 4\n",
      "loss tensor(0.0059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 5\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 6\n",
      "loss tensor(0.0066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(28)\n",
      "step 7\n",
      "loss tensor(0.0077, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(28)\n",
      "step 8\n",
      "loss tensor(0.0074, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 9\n",
      "loss tensor(0.0081, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(25)\n",
      "step 10\n",
      "loss tensor(0.0066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 11\n",
      "loss tensor(0.0048, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 12\n",
      "loss tensor(0.0079, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 13\n",
      "loss tensor(0.0090, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(29)\n",
      "step 14\n",
      "loss tensor(0.0060, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 15\n",
      "loss tensor(0.0067, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 16\n",
      "loss tensor(0.0066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 17\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 18\n",
      "loss tensor(0.0093, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 19\n",
      "loss tensor(0.0066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 20\n",
      "loss tensor(0.0072, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 21\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 22\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 23\n",
      "loss tensor(0.0107, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(27)\n",
      "step 24\n",
      "loss tensor(0.0073, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(32)\n",
      "step 25\n",
      "loss tensor(0.0067, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 26\n",
      "loss tensor(0.0086, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(25)\n",
      "step 27\n",
      "loss tensor(0.0122, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(15)\n",
      "step_accurate tensor(27)\n",
      "step 28\n",
      "loss tensor(0.0092, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(31)\n",
      "step 29\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 30\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(32)\n",
      "step 31\n",
      "loss tensor(0.0146, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 32\n",
      "loss tensor(0.0081, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "Accurate_total tensor(816.)\n",
      "Distance_total tensor(43.)\n",
      "Epoch_accuracy tensor(0.9668)\n",
      "Epoch_distance_avg tensor(0.0509)\n",
      "Saving..\n",
      "Epoch 16\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 2\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 3\n",
      "loss tensor(0.0083, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(29)\n",
      "step 4\n",
      "loss tensor(0.0079, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 5\n",
      "loss tensor(0.0058, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 6\n",
      "loss tensor(0.0084, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 7\n",
      "loss tensor(0.0099, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 8\n",
      "loss tensor(0.0095, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 9\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 10\n",
      "loss tensor(0.0092, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 11\n",
      "loss tensor(0.0068, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 12\n",
      "loss tensor(0.0062, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 13\n",
      "loss tensor(0.0060, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 14\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 15\n",
      "loss tensor(0.0059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 16\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 17\n",
      "loss tensor(0.0081, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 18\n",
      "loss tensor(0.0085, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(31)\n",
      "step 19\n",
      "loss tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 20\n",
      "loss tensor(0.0068, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(27)\n",
      "step 21\n",
      "loss tensor(0.0064, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 22\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(34)\n",
      "step 23\n",
      "loss tensor(0.0087, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(33)\n",
      "step 24\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(25)\n",
      "step 25\n",
      "loss tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(9)\n",
      "step_accurate tensor(28)\n",
      "step 26\n",
      "loss tensor(0.0077, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(29)\n",
      "step 27\n",
      "loss tensor(0.0057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "step 28\n",
      "loss tensor(0.0072, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(6)\n",
      "step_accurate tensor(25)\n",
      "step 29\n",
      "loss tensor(0.0052, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 30\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 31\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(25)\n",
      "step 32\n",
      "loss tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "Accurate_total tensor(829.)\n",
      "Distance_total tensor(31.)\n",
      "Epoch_accuracy tensor(0.9822)\n",
      "Epoch_distance_avg tensor(0.0367)\n",
      "Saving..\n",
      "Epoch 17\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0079, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 2\n",
      "loss tensor(0.0060, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 3\n",
      "loss tensor(0.0049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(25)\n",
      "step 4\n",
      "loss tensor(0.0057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 5\n",
      "loss tensor(0.0059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(32)\n",
      "step 6\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 7\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(30)\n",
      "step 8\n",
      "loss tensor(0.0045, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 9\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 10\n",
      "loss tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 11\n",
      "loss tensor(0.0078, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 12\n",
      "loss tensor(0.0076, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(29)\n",
      "step 13\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(33)\n",
      "step 14\n",
      "loss tensor(0.0064, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(27)\n",
      "step 15\n",
      "loss tensor(0.0074, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(30)\n",
      "step 16\n",
      "loss tensor(0.0052, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 17\n",
      "loss tensor(0.0058, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 18\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 19\n",
      "loss tensor(0.0044, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 20\n",
      "loss tensor(0.0067, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(23)\n",
      "step 21\n",
      "loss tensor(0.0047, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 22\n",
      "loss tensor(0.0057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 23\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 24\n",
      "loss tensor(0.0049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 25\n",
      "loss tensor(0.0065, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(31)\n",
      "step 26\n",
      "loss tensor(0.0062, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 27\n",
      "loss tensor(0.0054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 28\n",
      "loss tensor(0.0052, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 29\n",
      "loss tensor(0.0047, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 30\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 31\n",
      "loss tensor(0.0059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 32\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "Accurate_total tensor(828.)\n",
      "Distance_total tensor(25.)\n",
      "Epoch_accuracy tensor(0.9810)\n",
      "Epoch_distance_avg tensor(0.0296)\n",
      "Saving..\n",
      "Epoch 18\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0034, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 2\n",
      "loss tensor(0.0032, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 3\n",
      "loss tensor(0.0061, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 4\n",
      "loss tensor(0.0034, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "step 5\n",
      "loss tensor(0.0038, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 6\n",
      "loss tensor(0.0052, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 7\n",
      "loss tensor(0.0042, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 8\n",
      "loss tensor(0.0083, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 9\n",
      "loss tensor(0.0066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 10\n",
      "loss tensor(0.0046, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 11\n",
      "loss tensor(0.0041, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 12\n",
      "loss tensor(0.0047, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(25)\n",
      "step 13\n",
      "loss tensor(0.0043, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 14\n",
      "loss tensor(0.0064, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(33)\n",
      "step 15\n",
      "loss tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(23)\n",
      "step 16\n",
      "loss tensor(0.0037, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 17\n",
      "loss tensor(0.0064, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(33)\n",
      "step 18\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(28)\n",
      "step 19\n",
      "loss tensor(0.0054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 20\n",
      "loss tensor(0.0044, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 21\n",
      "loss tensor(0.0042, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 22\n",
      "loss tensor(0.0087, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(28)\n",
      "step 23\n",
      "loss tensor(0.0084, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 24\n",
      "loss tensor(0.0078, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 25\n",
      "loss tensor(0.0047, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 26\n",
      "loss tensor(0.0091, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 27\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 28\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 29\n",
      "loss tensor(0.0075, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(32)\n",
      "step 30\n",
      "loss tensor(0.0076, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(4)\n",
      "step_accurate tensor(29)\n",
      "step 31\n",
      "loss tensor(0.0084, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 32\n",
      "loss tensor(0.0078, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "Accurate_total tensor(832.)\n",
      "Distance_total tensor(16.)\n",
      "Epoch_accuracy tensor(0.9858)\n",
      "Epoch_distance_avg tensor(0.0190)\n",
      "Saving..\n",
      "Epoch 19\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0038, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 2\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 3\n",
      "loss tensor(0.0060, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 4\n",
      "loss tensor(0.0106, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 5\n",
      "loss tensor(0.0077, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 6\n",
      "loss tensor(0.0075, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 7\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 8\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "step 9\n",
      "loss tensor(0.0040, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 10\n",
      "loss tensor(0.0048, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 11\n",
      "loss tensor(0.0092, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(32)\n",
      "step 12\n",
      "loss tensor(0.0089, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(29)\n",
      "step 13\n",
      "loss tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 14\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(30)\n",
      "step 15\n",
      "loss tensor(0.0041, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 16\n",
      "loss tensor(0.0054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 17\n",
      "loss tensor(0.0072, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(27)\n",
      "step 18\n",
      "loss tensor(0.0046, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 19\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 20\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 21\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 22\n",
      "loss tensor(0.0107, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 23\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(34)\n",
      "step 24\n",
      "loss tensor(0.0043, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 25\n",
      "loss tensor(0.0061, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(23)\n",
      "step 26\n",
      "loss tensor(0.0089, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 27\n",
      "loss tensor(0.0094, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 28\n",
      "loss tensor(0.0065, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(33)\n",
      "step 29\n",
      "loss tensor(0.0045, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 30\n",
      "loss tensor(0.0058, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 31\n",
      "loss tensor(0.0041, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 32\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "Accurate_total tensor(838.)\n",
      "Distance_total tensor(11.)\n",
      "Epoch_accuracy tensor(0.9929)\n",
      "Epoch_distance_avg tensor(0.0130)\n",
      "Saving..\n",
      "Epoch 20\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 2\n",
      "loss tensor(0.0040, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 3\n",
      "loss tensor(0.0044, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 4\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 5\n",
      "loss tensor(0.0045, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 6\n",
      "loss tensor(0.0031, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 7\n",
      "loss tensor(0.0103, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 8\n",
      "loss tensor(0.0072, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(30)\n",
      "step 9\n",
      "loss tensor(0.0049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(26)\n",
      "step 10\n",
      "loss tensor(0.0049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 11\n",
      "loss tensor(0.0105, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 12\n",
      "loss tensor(0.0111, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 13\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 14\n",
      "loss tensor(0.0061, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(34)\n",
      "step 15\n",
      "loss tensor(0.0145, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 16\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 17\n",
      "loss tensor(0.0059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 18\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 19\n",
      "loss tensor(0.0061, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 20\n",
      "loss tensor(0.0046, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 21\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 22\n",
      "loss tensor(0.0078, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(33)\n",
      "step 23\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(32)\n",
      "step 24\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 25\n",
      "loss tensor(0.0103, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(29)\n",
      "step 26\n",
      "loss tensor(0.0130, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 27\n",
      "loss tensor(0.0061, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 28\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "step 29\n",
      "loss tensor(0.0108, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(28)\n",
      "step 30\n",
      "loss tensor(0.0059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 31\n",
      "loss tensor(0.0164, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 32\n",
      "loss tensor(0.0076, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(28)\n",
      "Accurate_total tensor(837.)\n",
      "Distance_total tensor(8.)\n",
      "Epoch_accuracy tensor(0.9917)\n",
      "Epoch_distance_avg tensor(0.0095)\n",
      "Saving..\n",
      "Epoch 21\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 2\n",
      "loss tensor(0.0066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 3\n",
      "loss tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 4\n",
      "loss tensor(0.0073, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 5\n",
      "loss tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 6\n",
      "loss tensor(0.0078, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 7\n",
      "loss tensor(0.0072, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(34)\n",
      "step 8\n",
      "loss tensor(0.0047, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "step 9\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 10\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 11\n",
      "loss tensor(0.0054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 12\n",
      "loss tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(32)\n",
      "step 13\n",
      "loss tensor(0.0064, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(30)\n",
      "step 14\n",
      "loss tensor(0.0191, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 15\n",
      "loss tensor(0.0078, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 16\n",
      "loss tensor(0.0065, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 17\n",
      "loss tensor(0.0071, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(32)\n",
      "step 18\n",
      "loss tensor(0.0061, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 19\n",
      "loss tensor(0.0054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 20\n",
      "loss tensor(0.0065, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(27)\n",
      "step 21\n",
      "loss tensor(0.0064, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 22\n",
      "loss tensor(0.0085, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 23\n",
      "loss tensor(0.0079, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(30)\n",
      "step 24\n",
      "loss tensor(0.0073, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 25\n",
      "loss tensor(0.0052, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 26\n",
      "loss tensor(0.0065, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 27\n",
      "loss tensor(0.0059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 28\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 29\n",
      "loss tensor(0.0049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 30\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 31\n",
      "loss tensor(0.0048, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 32\n",
      "loss tensor(0.0049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "Accurate_total tensor(839.)\n",
      "Distance_total tensor(8.)\n",
      "Epoch_accuracy tensor(0.9941)\n",
      "Epoch_distance_avg tensor(0.0095)\n",
      "Saving..\n",
      "Epoch 22\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0064, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(30)\n",
      "step 2\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 3\n",
      "loss tensor(0.0046, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 4\n",
      "loss tensor(0.0054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 5\n",
      "loss tensor(0.0049, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 6\n",
      "loss tensor(0.0065, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(32)\n",
      "step 7\n",
      "loss tensor(0.0036, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 8\n",
      "loss tensor(0.0045, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 9\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 10\n",
      "loss tensor(0.0060, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(29)\n",
      "step 11\n",
      "loss tensor(0.0046, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 12\n",
      "loss tensor(0.0052, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(33)\n",
      "step 13\n",
      "loss tensor(0.0058, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 14\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 15\n",
      "loss tensor(0.0214, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 16\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 17\n",
      "loss tensor(0.0098, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 18\n",
      "loss tensor(0.0060, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "step 19\n",
      "loss tensor(0.0081, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 20\n",
      "loss tensor(0.0072, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 21\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 22\n",
      "loss tensor(0.0068, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 23\n",
      "loss tensor(0.0083, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 24\n",
      "loss tensor(0.0052, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 25\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 26\n",
      "loss tensor(0.0099, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 27\n",
      "loss tensor(0.0057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(34)\n",
      "step 28\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 29\n",
      "loss tensor(0.0077, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 30\n",
      "loss tensor(0.0054, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 31\n",
      "loss tensor(0.0074, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(27)\n",
      "step 32\n",
      "loss tensor(0.0074, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "Accurate_total tensor(839.)\n",
      "Distance_total tensor(9.)\n",
      "Epoch_accuracy tensor(0.9941)\n",
      "Epoch_distance_avg tensor(0.0107)\n",
      "Saving..\n",
      "Epoch 23\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 2\n",
      "loss tensor(0.0066, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 3\n",
      "loss tensor(0.0046, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 4\n",
      "loss tensor(0.0040, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 5\n",
      "loss tensor(0.0041, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 6\n",
      "loss tensor(0.0057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 7\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 8\n",
      "loss tensor(0.0077, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(30)\n",
      "step 9\n",
      "loss tensor(0.0184, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 10\n",
      "loss tensor(0.0073, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 11\n",
      "loss tensor(0.0072, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(34)\n",
      "step 12\n",
      "loss tensor(0.0083, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 13\n",
      "loss tensor(0.0075, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "step 14\n",
      "loss tensor(0.0047, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 15\n",
      "loss tensor(0.0062, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(34)\n",
      "step 16\n",
      "loss tensor(0.0083, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 17\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(32)\n",
      "step 18\n",
      "loss tensor(0.0089, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 19\n",
      "loss tensor(0.0101, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(28)\n",
      "step 20\n",
      "loss tensor(0.0068, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 21\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 22\n",
      "loss tensor(0.0076, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 23\n",
      "loss tensor(0.0078, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 24\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 25\n",
      "loss tensor(0.0080, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(29)\n",
      "step 26\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 27\n",
      "loss tensor(0.0072, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 28\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 29\n",
      "loss tensor(0.0062, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 30\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 31\n",
      "loss tensor(0.0056, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 32\n",
      "loss tensor(0.0039, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "Accurate_total tensor(842.)\n",
      "Distance_total tensor(5.)\n",
      "Epoch_accuracy tensor(0.9976)\n",
      "Epoch_distance_avg tensor(0.0059)\n",
      "Saving..\n",
      "Epoch 24\n",
      "===========\n",
      "step 1\n",
      "loss tensor(0.0074, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 2\n",
      "loss tensor(0.0048, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 3\n",
      "loss tensor(0.0051, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(24)\n",
      "step 4\n",
      "loss tensor(0.0057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 5\n",
      "loss tensor(0.0042, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 6\n",
      "loss tensor(0.0089, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(33)\n",
      "step 7\n",
      "loss tensor(0.0039, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 8\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(3)\n",
      "step_accurate tensor(30)\n",
      "step 9\n",
      "loss tensor(0.0053, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 10\n",
      "loss tensor(0.0059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 11\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 12\n",
      "loss tensor(0.0040, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 13\n",
      "loss tensor(0.0058, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 14\n",
      "loss tensor(0.0057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(29)\n",
      "step 15\n",
      "loss tensor(0.0070, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 16\n",
      "loss tensor(0.0215, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(1)\n",
      "step 17\n",
      "loss tensor(0.0081, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 18\n",
      "loss tensor(0.0057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 19\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(30)\n",
      "step 20\n",
      "loss tensor(0.0052, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 21\n",
      "loss tensor(0.0069, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 22\n",
      "loss tensor(0.0059, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 23\n",
      "loss tensor(0.0062, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(32)\n",
      "step 24\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 25\n",
      "loss tensor(0.0065, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 26\n",
      "loss tensor(0.0065, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "step 27\n",
      "loss tensor(0.0063, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(1)\n",
      "step_accurate tensor(33)\n",
      "step 28\n",
      "loss tensor(0.0050, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(26)\n",
      "step 29\n",
      "loss tensor(0.0058, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(31)\n",
      "step 30\n",
      "loss tensor(0.0057, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(27)\n",
      "step 31\n",
      "loss tensor(0.0083, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(2)\n",
      "step_accurate tensor(27)\n",
      "step 32\n",
      "loss tensor(0.0055, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step_accuracy_distance tensor(0)\n",
      "step_accurate tensor(25)\n",
      "Accurate_total tensor(839.)\n",
      "Distance_total tensor(8.)\n",
      "Epoch_accuracy tensor(0.9941)\n",
      "Epoch_distance_avg tensor(0.0095)\n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "encoder.train()\n",
    "# _hidden = encoder.initHidden()\n",
    "# Group batches/paddings by relative same-size\n",
    "\n",
    "accuracy_floor = .6\n",
    "distance_floor = 3.6\n",
    "\n",
    "for epoch in range(25):\n",
    "    \n",
    "    # modify for ordering -- benefit here with shuffling at ea epoch\n",
    "#     random.shuffle(train_ix)\n",
    "    random.shuffle(batches)\n",
    "    \n",
    "    print('Epoch',epoch)\n",
    "    print('===========')\n",
    "    step = 0\n",
    "    # mod--\n",
    "    distance = 0.0\n",
    "    accurate = 0.0\n",
    "    \n",
    "    # in future, mix up epochs \n",
    "    for i in range(len(batches)):\n",
    "        batch = batches[i]\n",
    "#     for i in range(19):\n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         x,y,targets = get_minibatch(batchsize=BATCH_SIZE)\n",
    "        x,y,targets = get_minibatch(ix=batch,batchsize=len(batch))\n",
    "#         print('ix',batch,'targets',targets)\n",
    "#         x = pad_minibatch(x)\n",
    "        \n",
    "#         y = torch.stack(y).double()\n",
    "        \n",
    "#         _hidden = encoder.initHidden(batch_size=BATCH_SIZE)\n",
    "        _hidden = encoder.initHidden(batch_size=len(batch))\n",
    "\n",
    "        yhat, _hidden = encoder(x, _hidden)\n",
    "\n",
    "        loss = loss_func(yhat,y)\n",
    "\n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "       \n",
    "        print('step',step)\n",
    "        print('loss',loss)\n",
    "\n",
    "        yhat_tensor = torch.tensor([out_to_score_proba(hat) for hat in yhat])\n",
    "        \n",
    "        _stepdistance = accuracy_distansum(yhat_tensor=yhat_tensor,y_tensor=targets)\n",
    "        distance += _stepdistance\n",
    "        \n",
    "        _stepaccurate = accuracy(yhat_tensor=yhat_tensor,y_tensor=targets)\n",
    "        accurate += _stepaccurate\n",
    "        \n",
    "        \n",
    "        print('step_accuracy_distance',_stepdistance)\n",
    "        print('step_accurate',_stepaccurate)\n",
    "    \n",
    "    print('Accurate_total',accurate)\n",
    "    print('Distance_total',distance)\n",
    "    \n",
    "#     epoch_accuracy = accurate.item()/(len(train_ix))\n",
    "    epoch_accuracy = accurate/(len(train_ix))\n",
    "    # may be a bug in distance..\n",
    "#     epoch_distance_avg = distance.item()/(len(train_ix))\n",
    "    epoch_distance_avg = distance/(len(train_ix))\n",
    "    \n",
    "    print('Epoch_accuracy',epoch_accuracy)\n",
    "    print('Epoch_distance_avg',epoch_distance_avg)\n",
    "    \n",
    "    if epoch_accuracy > accuracy_floor or epoch_distance_avg < distance_floor:\n",
    "        \n",
    "        print('Saving..')\n",
    "        torch.save(encoder.state_dict(),'encoder.csr_accuracy_{:.3f}_avgdistance_{:3f}.pt'.format(epoch_accuracy, epoch_distance_avg))\n",
    "        \n",
    "        if epoch_accuracy > accuracy_floor: accuracy_floor = epoch_accuracy\n",
    "        if epoch_distance_avg > distance_floor: distance_floor = epoch_distance_avg\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sentence[639]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19, 13, 22, 30, 30, 30, 30, 30, 23, 30, 30, 19, 19, 15, 28, 20, 29, 27,\n",
       "        29, 15, 14, 13, 27, 29, 16, 16])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_vectorize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-069f93d416c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_vectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'num_vectorize' is not defined"
     ]
    }
   ],
   "source": [
    "num_vectorize(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder.eval()\n",
    "\n",
    "x_valid,y_valid,targets_valid = get_minibatch(ix=valid_ix)\n",
    "\n",
    "# x_valid = pad_minibatch(x_valid)\n",
    "\n",
    "# y_valid = torch.stack(y_valid).double()\n",
    "\n",
    "_hidden = encoder.initHidden(batch_size=len(valid_ix))\n",
    "\n",
    "yhat_valid, _hidden = encoder(x_valid, _hidden)\n",
    "estimates_csr = torch.tensor([out_to_score_proba(hat) for hat in yhat_valid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17, 30, 19, 30, 30, 30, 28, 21, 20, 29, 30, 30, 27, 15, 20, 30, 30, 29,\n",
       "        16, 23, 30, 29, 30, 29, 27, 17, 20, 28, 23, 20, 30, 30, 30, 24, 19, 30,\n",
       "        30, 29, 30, 30, 23, 28, 26, 27, 20, 30, 20, 19, 30, 23, 28, 23, 19, 28,\n",
       "        30, 30, 30, 17, 20, 29, 20, 28, 21, 22, 29, 30, 17, 20, 21, 30, 19, 11,\n",
       "        20, 30, 23, 28, 20, 23, 17, 20, 23, 29, 30, 28, 19, 21, 27, 20, 28, 20,\n",
       "        30, 29, 19, 19, 23, 20, 30, 30, 16, 30, 30, 29, 30, 21, 20, 28, 30, 17,\n",
       "        23, 23, 29, 23, 28, 20, 15, 28, 15, 17, 25, 28, 23, 23, 25, 20, 23, 29,\n",
       "        19, 17, 20, 27, 12, 30, 19, 23, 28, 18, 20, 23, 20, 17, 17, 15, 28, 20,\n",
       "        23, 26, 28, 20, 28, 27, 19, 19, 25, 28, 29, 20, 24, 19, 29, 21, 10, 19,\n",
       "        18, 19, 23, 24, 27, 20, 28, 30, 28, 20, 13, 20, 23, 28, 19, 11, 23, 19,\n",
       "        19, 19, 20, 17, 19, 30, 19, 13, 20, 13, 30, 30, 19, 19, 20, 19, 21, 17,\n",
       "        20, 30, 19, 20, 20, 21, 29, 17, 20, 23, 18, 19])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimates_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_valid_csr = targets_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 30, 23, 17, 29, 30, 28, 20, 24, 30, 19, 30, 28, 30, 18, 30, 30, 30,\n",
       "         8, 13, 29, 19, 29, 30, 20, 19, 19, 20, 26, 18, 30, 29, 30, 25, 16, 18,\n",
       "        30, 29, 30, 13, 29, 30, 26, 30, 19, 30, 19, 27, 27, 20, 27, 28, 22, 30,\n",
       "        30, 30, 30, 29, 22, 28,  3, 30, 10, 16, 20, 22, 25, 15, 18, 30, 28, 18,\n",
       "        30, 27, 18, 27, 25, 30, 12, 30, 30, 30, 28, 29, 25, 13, 27, 19, 29, 30,\n",
       "        23, 29,  5, 17, 23, 22, 30, 24, 19, 20, 29, 29, 30, 17, 17, 27, 28, 26,\n",
       "        17, 19, 19, 20, 19, 15, 18, 26, 18, 13, 25, 18, 24, 28, 29, 28, 11, 28,\n",
       "        20, 20, 19, 27, 13, 19, 18, 19, 13, 20, 18, 28, 24, 19, 29, 13, 28, 19,\n",
       "        25, 28, 18, 20, 21, 29, 17, 21, 30, 19, 20, 10, 19, 27, 27, 10, 18, 28,\n",
       "        22, 27, 12, 27, 30, 13, 26, 23, 25, 23, 10, 25, 15, 28, 21, 15, 20, 23,\n",
       "        19, 15, 24, 27, 28, 10, 23, 21, 19, 19, 26, 15, 23, 11, 19, 24, 25, 20,\n",
       "        27, 23, 11, 20, 17, 27, 26, 25, 23, 17, 18, 20])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_valid_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1476, dtype=torch.float64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(targets_valid_csr,estimates_csr).double()/len(targets_valid_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   2,   3,   4,   7,   8,   9,  10,  12,  13,  14,  17,  18,\n",
       "         19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  31,  33,\n",
       "         34,  35,  39,  40,  41,  43,  44,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
       "         68,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "         82,  83,  84,  85,  87,  88,  89,  90,  92,  93,  95,  97,  98,\n",
       "         99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "        114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "        128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
       "        143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
       "        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
       "        170, 171, 172, 173, 174, 176, 177, 178, 179, 181, 182, 183, 184,\n",
       "        185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
       "        198, 199, 200, 202, 203, 204, 205, 206, 207, 209]),)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(targets_valid_csr != estimates_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4571, dtype=torch.float64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_distansum(targets_valid_csr,estimates_csr).double()/len(targets_valid_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 18, 29, 28, 26, 27, 23, 30, 19, 17, 20, 17, 25, 30, 23, 29, 27, 30,\n",
       "        19, 16, 30,  7, 28, 28, 28, 28, 25, 12, 30, 18, 30, 25, 15, 18, 14, 26,\n",
       "        27, 30, 20, 17, 30, 26, 19, 27, 17, 20, 20, 29, 27, 29, 30, 30, 30, 20,\n",
       "        22, 29, 19, 30, 30, 30, 30, 22, 17, 27, 27, 30, 30, 23, 30, 30, 19, 25,\n",
       "        30, 19, 30, 30, 30,  8, 30, 22, 30, 30, 28, 16, 19, 22, 24, 28, 16, 30,\n",
       "        30, 19, 17, 27, 19, 30, 30, 21, 28, 19, 29, 19, 12, 28, 20, 23, 13, 20,\n",
       "        23, 27, 23, 19, 20, 19, 19, 19, 27, 16, 10, 20, 17, 24, 24, 23, 16, 20,\n",
       "        18, 17, 19, 28, 29, 20, 27, 20, 23, 16, 20, 23, 27, 22, 19, 20, 20, 19,\n",
       "        19, 28, 28, 28, 26, 19, 24, 22, 20, 18, 23, 27, 25, 25])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 18, 29, 30, 26, 27, 23, 30, 19, 17, 20, 17, 25, 30, 23, 29, 27, 30,\n",
       "        19, 16, 30,  7, 28, 28, 28, 28, 25, 12, 30, 18, 30, 25, 15, 18, 14, 26,\n",
       "        27, 30, 20, 17, 30, 26, 19, 27, 17, 20, 20, 29, 27, 29, 30, 30, 30, 20,\n",
       "        22, 29, 19, 30, 30, 30, 30, 22, 17, 27, 27, 30, 30, 23, 30, 30, 19, 25,\n",
       "        30, 19, 30, 30, 30,  8, 30, 22, 30, 30, 28, 16, 19, 22, 24, 28, 16, 30,\n",
       "        30, 19, 17, 27, 19, 30, 30, 21, 28, 19, 29, 19, 12, 28, 20, 23, 13, 20,\n",
       "        23, 27, 23, 19, 20, 19, 19, 19, 27, 16, 10, 20, 17, 24, 24, 23, 16, 20,\n",
       "        18, 17, 19, 28, 29, 20, 27, 20, 23, 16, 20, 23, 27, 22, 19, 20, 20, 19,\n",
       "        19, 28, 28, 28, 26, 19, 24, 22, 20, 18, 23, 27, 25, 25])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for heatmap visualization\n",
    "# pd.Series(targets_valid).to_csv('targets_valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(estimates).to_csv('estimates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6159, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is WRONG with this metric\n",
    "accuracy_distansum(targets_valid,estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09250569620253164"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14.6159/158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(157)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(targets_valid,estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9936708860759493"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "157/158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3]),)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(targets_valid != estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([634, 30])\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "\n",
    "x_train,y_train,targets_train = get_minibatch(ix=train_ix)\n",
    "\n",
    "# x_valid = pad_minibatch(x_valid)\n",
    "\n",
    "# y_valid = torch.stack(y_valid).double()\n",
    "\n",
    "_hidden = encoder.initHidden(batch_size=len(train_ix))\n",
    "yhat_train, _hidden = encoder(x_train, _hidden)\n",
    "estimates_train = torch.tensor([out_to_score_proba(hat) for hat in yhat_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28, 30, 12, 17, 30, 29, 20, 29, 15, 30, 29, 29, 29, 29, 30, 30, 28,  3,\n",
       "        28, 27, 30, 19, 27, 30, 10, 30, 30, 17, 23, 30, 30, 19, 30, 30, 30, 30,\n",
       "        30, 28, 30, 19, 29, 30, 30, 29, 30, 11, 27, 21, 19, 29, 30, 28, 30, 12,\n",
       "        30, 13, 22, 21, 29, 29, 17, 10, 23, 13, 18, 11, 28, 30, 18,  3, 29, 27,\n",
       "        30, 21, 20, 25, 30, 28, 30, 17, 24, 26, 20, 27, 30, 30, 19, 28, 24, 25,\n",
       "        20, 24, 30, 29, 16, 30, 30, 30, 30, 30, 19, 28, 15, 30, 30, 26, 30, 29,\n",
       "        30, 30, 30, 26, 30, 19, 26, 23, 18, 19, 13, 23, 12, 25, 30, 30, 10, 24,\n",
       "        30, 30, 28, 28, 15, 30, 30, 30, 24, 29, 28, 30, 28, 30, 23, 23, 20, 30,\n",
       "        29,  8, 20, 30, 19, 20, 25, 29, 20, 30, 30, 28, 30, 27, 29, 28, 22, 28,\n",
       "        25, 23, 29, 20, 23, 16, 18, 23, 19, 25, 30, 30, 17, 30, 30, 20, 10, 30,\n",
       "        18, 22, 24, 15, 29, 30, 19, 18, 28, 30, 30, 29, 30, 30, 30, 22, 29, 30,\n",
       "        29, 30, 26, 29, 15, 16, 30, 30, 13, 24, 30, 29, 23, 28, 13, 30, 28, 11,\n",
       "        29, 18, 18, 17, 27, 16, 12, 13, 29, 25, 30, 15, 30, 29, 10, 17, 11, 19,\n",
       "        10, 27, 22, 19, 28, 29, 28, 30, 19, 30, 26, 25, 13, 30, 22, 28, 29, 30,\n",
       "        13, 18, 23, 30, 24, 14, 30, 16, 30, 23, 30, 30, 15, 30, 30, 14, 18, 19,\n",
       "        10, 19, 24, 28, 19, 19, 30, 11, 28, 30, 29, 13, 17, 30, 12, 18, 18, 19,\n",
       "        30, 26, 29, 15, 17, 29, 25, 20, 28, 18, 30, 10, 26, 23, 21, 29, 19, 20,\n",
       "        20, 19, 20, 18, 29, 13, 30, 16, 28, 30, 29, 30, 17, 20, 24, 23, 23, 23,\n",
       "        30, 30, 30, 23, 30, 30, 27, 30, 19, 30, 18, 14, 29, 29, 27, 29, 29, 30,\n",
       "        19, 30, 17, 30, 28, 13, 14, 20, 30, 24, 15, 23, 30, 12, 30, 24, 29, 20,\n",
       "        30, 30, 30, 29, 14, 26, 29, 15, 19, 30, 20, 20, 30, 20, 28, 26, 29, 19,\n",
       "        22, 28, 29, 17, 29, 28, 12, 20, 29, 17,  5, 17, 30, 30, 29, 30, 29, 28,\n",
       "        30, 29, 25, 30, 24, 29, 21, 24, 30, 19, 19, 30, 25, 28, 17, 30,  1, 27,\n",
       "        12, 20, 30, 24, 27, 30, 27, 28, 28, 15, 19, 26, 20, 15, 26, 30, 28, 19,\n",
       "        30, 27, 30, 19, 30, 13, 28, 30, 28, 21, 20, 20, 30, 19, 13, 13, 21, 19,\n",
       "        29, 19, 19, 24, 17, 19, 13, 12, 26, 23, 18, 13, 15, 25, 20, 28, 21, 21,\n",
       "        16, 29, 24, 21, 17,  7, 29, 19, 16, 21, 19, 29, 20,  8, 26, 28, 18, 25,\n",
       "        11, 21, 23, 18, 17, 28, 19, 19, 28,  8, 23, 30, 19, 27, 17, 13, 28, 26,\n",
       "        23, 26, 28, 24, 19, 19, 15, 10, 20, 17, 27, 11, 30, 28, 12, 10, 22, 19,\n",
       "        28, 19, 22, 13, 11, 25, 11, 14, 17, 30, 21, 20, 24, 15, 18, 26, 12, 19,\n",
       "        23, 19, 11, 21, 26, 19, 25, 17,  7, 22, 30, 15, 13, 27, 23, 25, 25, 17,\n",
       "        19, 23, 27, 19, 23, 21, 13, 18, 18, 19, 19, 29, 25, 10, 28, 20, 29, 29,\n",
       "        30, 24, 27, 19, 20, 14, 19, 12, 27, 19, 23, 17, 18, 20, 13, 17, 14, 25,\n",
       "        14, 22, 20, 28, 29, 17, 18, 18, 29, 18, 23, 19, 19, 28, 25, 24, 19, 15,\n",
       "        13, 13, 20, 19, 20, 19, 26, 17, 28, 19, 19, 15, 19, 29, 18, 18, 10, 15,\n",
       "        30, 15, 25, 17])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_train_bugfix = torch.tensor([out_to_score_proba(hat) for hat in yhat_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28, 30, 12, 17, 30, 29, 20, 29, 15, 30, 29, 29, 29, 29, 30, 30, 28,  3,\n",
       "        28, 27, 30, 19, 27, 30, 10, 30, 30, 17, 23, 30, 30, 19, 30, 30, 30, 30,\n",
       "        30, 28, 30, 19, 29, 30, 30, 29, 30, 11, 27, 21, 19, 29, 30, 28, 30, 12,\n",
       "        30, 13, 22, 21, 29, 29, 17, 10, 23, 13, 18, 11, 28, 30, 18,  3, 29, 27,\n",
       "        30, 21, 20, 25, 30, 28, 30, 17, 24, 26, 20, 27, 30, 30, 19, 28, 24, 25,\n",
       "        20, 24, 30, 29, 16, 30, 30, 30, 30, 30, 19, 28, 15, 30, 30, 26, 30, 29,\n",
       "        30, 30, 30, 26, 30, 19, 26, 23, 18, 19, 13, 23, 12, 25, 30, 30, 10, 24,\n",
       "        30, 30, 28, 28, 15, 30, 30, 30, 24, 29, 28, 30, 28, 30, 23, 23, 20, 30,\n",
       "        29,  8, 20, 30, 19, 20, 25, 29, 20, 30, 30, 28, 30, 27, 29, 28, 22, 28,\n",
       "        25, 23, 29, 20, 23, 16, 18, 23, 19, 25, 30, 30, 17, 30, 30, 20, 10, 30,\n",
       "        18, 22, 24, 15, 29, 30, 19, 18, 28, 30, 30, 29, 30, 30, 30, 22, 29, 30,\n",
       "        29, 30, 26, 29, 15, 16, 30, 30, 13, 24, 30, 29, 23, 28, 13, 30, 28, 11,\n",
       "        29, 18, 18, 17, 27, 16, 12, 13, 29, 25, 30, 15, 30, 29, 10, 17, 11, 19,\n",
       "        10, 27, 22, 19, 28, 29, 28, 30, 19, 30, 26, 25, 13, 30, 22, 28, 29, 30,\n",
       "        13, 18, 23, 30, 24, 14, 30, 16, 30, 23, 30, 30, 15, 30, 30, 14, 18, 19,\n",
       "        10, 19, 24, 28, 19, 19, 30, 11, 28, 30, 29, 13, 17, 30, 12, 18, 18, 19,\n",
       "        30, 26, 29, 15, 17, 29, 25, 20, 28, 18, 30, 10, 26, 23, 21, 29, 19, 20,\n",
       "        20, 19, 20, 18, 29, 13, 30, 16, 28, 30, 29, 30, 17, 20, 24, 23, 23, 23,\n",
       "        30, 30, 30, 23, 30, 30, 27, 30, 19, 30, 18, 14, 29, 29, 27, 29, 29, 30,\n",
       "        19, 30, 17, 30, 28, 13, 14, 20, 30, 24, 15, 23, 30, 12, 30, 24, 29, 20,\n",
       "        30, 30, 30, 29, 14, 26, 29, 15, 19, 30, 20, 20, 30, 20, 28, 26, 29, 19,\n",
       "        22, 28, 29, 17, 29, 28, 12, 20, 29, 17,  5, 17, 30, 30, 29, 30, 29, 28,\n",
       "        30, 29, 25, 30, 24, 29, 21, 24, 30, 19, 19, 30, 25, 28, 17, 30,  1, 27,\n",
       "        12, 20, 30, 24, 27, 30, 27, 28, 28, 15, 19, 26, 20, 15, 26, 30, 28, 19,\n",
       "        30, 27, 30, 19, 30, 13, 28, 30, 28, 21, 20, 20, 30, 19, 13, 13, 21, 19,\n",
       "        29, 19, 19, 24, 17, 19, 13, 12, 26, 23, 18, 13, 15, 25, 20, 28, 21, 21,\n",
       "        16, 29, 24, 21, 17,  7, 29, 19, 16, 21, 19, 29, 20,  8, 26, 28, 18, 25,\n",
       "        11, 21, 23, 18, 17, 28, 19, 19, 28,  8, 23, 30, 19, 27, 17, 13, 28, 26,\n",
       "        23, 26, 28, 24, 19, 19, 15, 10, 20, 17, 27, 11, 30, 28, 12, 10, 22, 19,\n",
       "        28, 19, 19, 13, 11, 25, 11, 14, 17, 30, 21, 20, 24, 15, 18, 26, 12, 19,\n",
       "        23, 19, 11, 21, 26, 19, 25, 17,  7, 22, 30, 15, 13, 27, 23, 25, 25, 17,\n",
       "        19, 23, 27, 19, 23, 21, 13, 18, 18, 19, 19, 29, 25, 10, 28, 20, 29, 29,\n",
       "        30, 23, 27, 19, 20, 14, 19, 12, 27, 19, 23, 17, 18, 20, 13, 17, 14, 25,\n",
       "        14, 22, 20, 28, 29, 17, 18, 18, 29, 18, 23, 19, 19, 28, 25, 24, 19, 15,\n",
       "        13, 13, 20, 19, 20, 19, 26, 17, 28, 19, 19, 15, 19, 29, 18, 18, 10, 15,\n",
       "        30, 15, 25, 17])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimates_train_bugfix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(632)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(targets_train,estimates_train_bugfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968454258675079"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "632/len(train_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6159, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_distansum(targets_train,estimates_train_bugfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02305347003154574"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14.6159/len(train_ix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dl1010",
   "language": "python",
   "name": "dl1010"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
