{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylangacq as pla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_cookie = torch.load('cookie_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cookie = torch.load('cookie_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_cookie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_sentence = torch.load('sentence_data_targets.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sentence = torch.load('sentence_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cookie_filenames = torch.load('cookie_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_cookie_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sent_filenames = torch.load('sentence_fnames_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_sent_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(X_cookie_filenames) + len(X_sent_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cookie_reader = pla.read_chat('./Pitt/*/cookie/*.cha')\n",
    "X_sentence_reader = pla.read_chat('./Pitt/*/sentence/*.cha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data -- targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group missing or input error st no mean to replace with and left untouched in target generation\n",
    "\n",
    "replace with closest analog as per means generated from target generation:\n",
    "\n",
    "cookie {'Control': 30, 'ProbableAD': 19, 'MCI': 28, 'Memory': 30, 'Vascular': 17, 'PossibleAD': 20, 'Probable': 19, 'Other': 24}\n",
    "\n",
    "sentence {'ProbableAD': 19, 'MCI': 28, 'Memory': 30, 'Vascular': 17, 'PossibleAD': 21, 'Control': 30, 'Probable': 19, 'Other': 24}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent_k in y_sentence:\n",
    "    if type(y_sentence[sent_k]) == str:\n",
    "        print(X_sent_filenames[sent_k])\n",
    "        print(sent_k,y_sentence[sent_k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_674 = X_sentence_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/sentence/236-0.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dementia'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_674"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Dementia with Possible mean (as per diagnostic codes in Pitt-data.xlxs and accompanying Pitt-readme.pdf)\n",
    "y_sentence[674] = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha\n",
      "219 \n",
      "/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha\n",
      "511 possibleAD\n"
     ]
    }
   ],
   "source": [
    "for coo_kie in y_cookie:\n",
    "    if type(y_cookie[coo_kie]) == str:\n",
    "        print(X_cookie_filenames[coo_kie])\n",
    "        print(coo_kie,y_cookie[coo_kie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_219 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha']['Participants']['PAR']['education']\n",
    "group_219 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Control/cookie/304-1.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '' with Control mean (as per folder and dx codes in .xlxs)\n",
    "y_cookie[219] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_511 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha']['Participants']['PAR']['education']\n",
    "group_511 = X_cookie_reader.headers()['/Users/renee/Documents/WIS_Spr20/DL/FinalProj/Pitt/Dementia/cookie/585-0.cha']['Participants']['PAR']['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'possibleAD'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace possibleAD with PossibleAD mean\n",
    "y_cookie[511] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm all targets filled now \n",
    "for sent_k in y_sentence:\n",
    "    if type(y_sentence[sent_k]) == str:\n",
    "        print(X_sent_filenames[sent_k])\n",
    "        print(sent_k,y_sentence[sent_k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coo_kie in y_cookie:\n",
    "    if type(y_cookie[coo_kie]) == str:\n",
    "        print(X_cookie_filenames[coo_kie])\n",
    "        print(coo_kie,y_cookie[coo_kie])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(y_cookie,'cookie_target_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(y_sentence,'sentence_target_dict.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Vocab Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = './PretrainedWordEmb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_emb = pickle.load(open(f'{glove_path}/addb.vocab_emb.glove.42B.300.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = torch.load('pos_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "792"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_ix = random.sample(range(num_samples),int(.20*num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ix = [i for i in range(num_samples) if i not in valid_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(valid_ix,'valid_ix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(train_ix,'train_ix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ix = torch.load('valid_ix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ix = torch.load('train_ix.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(ix=None):\n",
    "    \n",
    "    # first should be...all zeros: each index represents greater than .. but you cant have a zero score..\n",
    "    def num_vectorize(t):\n",
    "\n",
    "        v = torch.zeros([30])\n",
    "        v[:t] = 1\n",
    "\n",
    "        return v.double()\n",
    "    \n",
    "    ix = random.randint(1,num_samples-1) if ix is None else ix\n",
    "    \n",
    "    #index, filename\n",
    "    if ix in X_cookie_filenames.keys():\n",
    "        _file = (ix,X_cookie_filenames[ix])\n",
    "        _reader = X_cookie_reader\n",
    "        _targetdict = y_cookie\n",
    "        \n",
    "    else:\n",
    "        _file = (ix,X_sent_filenames[ix])\n",
    "        _reader = X_sentence_reader\n",
    "        _targetdict = y_sentence\n",
    "        \n",
    "    file,data,targetdict = (_file,_reader,_targetdict)\n",
    "    \n",
    "    embeddings = []\n",
    "    targets = []\n",
    "\n",
    "    embedding = [(vocab_emb[token],torch.zeros(len(pos_dict),dtype=torch.float64),pos_dict[pos]) for (token,pos) in zip([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file[1]] for (tokensraw,pos,tokenstem,dependency) in utterance], [pos for utterance in data.tagged_sents(participant='PAR',by_files=True)[file[1]] for (tokensraw,pos,tokenstem,dependency) in utterance])]\n",
    "    target = targetdict[ix]\n",
    "\n",
    "    for tkn in embedding:\n",
    "\n",
    "        tkn[1][tkn[2]] = 1\n",
    "#     print(target)   \n",
    "    return [torch.cat((tkn[0],tkn[1])) for tkn in embedding], num_vectorize(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "e,t = get_item(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad with zeros -- maybe\n",
    "# end with eos tensor, tag\n",
    "\n",
    "def get_minibatch(batchsize=1, ix=None):\n",
    "    \n",
    "    \n",
    "    def num_vectorize(targets):\n",
    "        vectors = []\n",
    "        for i in targets:\n",
    "            v = torch.zeros([30])\n",
    "            v[:i] = 1\n",
    "            vectors.append(v)\n",
    "        return vectors\n",
    "    \n",
    "    \n",
    "    minibatch_ix = random.sample(range(num_samples),batchsize) if ix is None else ix \n",
    "    \n",
    "    #index, filename\n",
    "    cookie_files = [(i,X_cookie_filenames[i]) for i in minibatch_ix if i in X_cookie_filenames.keys()]\n",
    "    sent_files = [(i,X_sent_filenames[i] )for i in minibatch_ix if i in X_sent_filenames.keys()]\n",
    "    \n",
    "    embeddings = []\n",
    "    targets = []\n",
    "\n",
    "    for corpus,data,targetdict in [(cookie_files,X_cookie_reader,y_cookie),(sent_files,X_sentence_reader,y_sentence)]: \n",
    "        for file_ix,file in corpus:\n",
    "#             print(file_ix, file)\n",
    "#             print('Words',[tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])\n",
    "#             print('Words_len',len([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance]))\n",
    "            embedding = [(vocab_emb[token],torch.zeros(len(pos_dict),dtype=torch.float64),pos_dict[pos]) for (token,pos) in zip([tokensraw for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance], [pos for utterance in data.tagged_sents(participant='PAR',by_files=True)[file] for (tokensraw,pos,tokenstem,dependency) in utterance])]\n",
    "            target = targetdict[file_ix]\n",
    "            \n",
    "            for tkn in embedding:\n",
    "\n",
    "                tkn[1][tkn[2]] = 1\n",
    "\n",
    "#                 embeddings.append(torch.cat((tkn[0],tkn[1])))\n",
    "            \n",
    "            embeddings.append([torch.cat((tkn[0],tkn[1])) for tkn in embedding])\n",
    "\n",
    "\n",
    "#             embeddings.append(embedding)\n",
    "            targets.append(target)\n",
    "    print(targets)       \n",
    "#     return embeddings, torch.tensor(targets), minibatch_ix\n",
    "#     return embeddings, torch.tensor(targets)\n",
    "    return embeddings, num_vectorize(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 30, 26, 29, 19, 23, 28, 26, 23, 19, 29, 30, 29, 30, 29, 20, 30, 20, 29, 30, 21, 5, 30, 30, 29, 19, 15, 13, 29, 10, 16, 15, 30, 7, 30, 30, 28, 30, 30, 20, 28, 29, 13, 30, 26, 30, 24, 25, 24, 30, 25, 30, 19, 19, 19, 28, 24, 28, 30, 17, 28, 18, 30, 30, 27, 25, 30, 19, 29, 30, 26, 17, 10, 30, 28, 17, 30, 15, 27, 30, 30, 22, 30, 29, 27, 21, 30, 19, 15, 17, 27, 16, 30, 28, 24, 26, 19, 30, 29, 26, 15, 30, 30, 30, 22, 29, 28, 22, 30, 26, 30, 30, 28, 28, 30, 17, 20, 27, 25, 30, 28, 30, 20, 23, 30, 30, 30, 29, 29, 30, 20, 17, 19, 17, 15, 30, 21, 28, 22, 28, 29, 10, 28, 22, 22, 13, 30, 15, 29, 19, 28, 20, 30, 20, 29, 30, 30, 29, 30, 29, 29, 29, 30, 19, 19, 27, 18, 28, 28, 12, 30, 30, 12, 29, 30, 3, 30, 23, 19, 30, 11, 12, 19, 30, 24, 24, 29, 19, 16, 19, 30, 28, 25, 20, 30, 25, 20, 29, 10, 30, 30, 19, 30, 28, 15, 30, 29, 8, 20, 24, 30, 30, 28, 29, 28, 23, 30, 23, 29, 30, 30, 28, 16, 30, 30, 20, 26, 13, 28, 27, 30, 30, 30, 30, 23, 28, 18, 29, 24, 22, 30, 11, 13, 21, 30, 26, 13, 28, 20, 23, 23, 27, 25, 30, 21, 30, 18, 28, 28, 1, 19, 28, 29, 30, 11, 12, 13, 29, 29, 30, 30, 28, 30, 20, 30, 30, 19, 30, 28, 30, 26, 26, 18, 30, 18, 16, 29, 17, 19, 30, 29, 30, 27, 30, 19, 19, 30, 30, 17, 23, 20, 20, 17, 30, 30, 20, 29, 27, 20, 10, 18, 19, 30, 29, 12, 30, 27, 28, 17, 28, 28, 17, 19, 30, 28, 21, 24, 3, 30, 25, 22, 30, 23, 23, 25, 22, 27, 30, 29, 30, 13, 24, 28, 25, 29, 26, 17, 17, 19, 24, 23, 23, 23, 10, 22, 30, 29, 18, 30, 23, 30, 30, 29, 27, 27, 19, 26, 30, 19, 27, 20, 28, 20, 11, 27, 19, 18, 24, 20, 30, 30, 30, 13, 13, 10, 17, 12, 16, 14, 29, 12, 13, 25, 24, 19, 30, 29, 30, 23, 30, 27, 30, 19, 30, 18, 30, 30, 22, 30, 30, 18, 19, 28, 26, 15, 30, 30, 30, 30, 19, 28, 10, 30, 30, 30, 14, 30, 29, 23, 30, 20, 16, 18, 19, 18, 20, 14, 18, 26, 29, 23, 29, 29, 23, 30, 24, 25, 17, 28, 19, 27, 21, 24, 30, 30, 20, 27, 24, 30, 17, 19, 16, 13, 30, 29, 15, 19, 15, 28, 19, 17, 25, 30, 17, 19, 29, 16, 30, 11, 30, 29, 30, 29, 12, 30, 30, 30, 18, 30, 30, 27, 18, 27, 30, 29, 29, 29, 29, 28, 30, 25, 30, 19, 30, 20, 30, 15, 30, 19, 30, 29, 28, 30, 28, 18, 14, 30, 29, 30, 18, 30, 15, 27, 17, 20, 8, 25, 30, 13, 30, 29, 20, 20, 30, 12, 30, 20, 29, 19, 17, 30, 30, 13, 23, 30, 14, 28, 30, 21, 14, 30, 29, 21, 19, 26, 19, 27, 26, 19, 23, 28, 29, 8, 20, 10, 12, 30, 17, 19, 18, 15, 24, 23, 15, 20, 19, 13, 28, 23, 23, 22, 29, 23, 27, 19, 12, 19, 12, 19, 18, 25, 20, 20, 19, 17, 22, 13, 23, 17, 19, 26, 29, 27, 24, 20, 8, 21, 28, 21, 27, 19, 23, 18, 28, 19, 27, 18, 22, 29, 29, 29, 23, 16, 21, 23, 18, 19, 19, 13, 27, 13, 17, 19, 22, 25, 30, 13, 10, 28, 18, 19, 23, 19, 18, 30, 20, 27, 11, 19, 20, 20, 24, 28, 22, 20, 19, 26, 19, 16, 19, 25, 17, 24, 19, 21, 17, 23, 13, 28, 17, 15, 20, 20, 19, 27, 13, 17, 30, 30, 14, 29, 7, 21, 19, 20, 20, 13, 24, 16, 11, 17, 24, 13, 19, 20, 27, 25, 7, 21, 25, 15, 28, 19, 23, 17, 17, 23, 24, 15, 25, 20, 30, 19, 23, 18, 17, 19, 19, 14, 25, 12, 17, 17, 15, 25, 20, 10, 28, 10, 14, 26, 28, 19, 19, 28, 12, 19, 16, 15, 11, 18, 27, 26, 27, 18, 20, 20, 29, 19, 20, 10, 19, 19, 18, 13, 18, 23, 16, 19, 23, 14, 20, 25, 26, 29, 28, 26, 28, 28, 11, 22, 17, 25, 15, 25, 11, 19, 18, 24, 24, 18, 28, 28, 21, 25, 19, 20, 28, 19, 19, 29, 23]\n"
     ]
    }
   ],
   "source": [
    "e,t = get_minibatch(batchsize=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(t)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(torch.zeros([29]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy measurement\n",
    "# return summation -- doesnt perfectly handle skipped values\n",
    "# np.where(vector)[0][-1] https://stackoverflow.com/questions/38375401/neural-network-ordinal-classification-for-age\n",
    "def out_to_score(vector):\n",
    "    # zeros array \n",
    "    \n",
    "    return vector.sum() + 1\n",
    "    \n",
    "    if len(np.where(vector)[0]) == 0: return 0\n",
    "#     print ([i+2 for i in np.where(vector)])\n",
    "    print(np.where(vector))\n",
    "    candidate = (np.where(vector)[0][-1]) \n",
    "    \n",
    "    # handling intermediate zeros...maybe not optimal\n",
    "    if np.where(vector)[0][-2] < (candidate - 1): candidate = (np.where(vector)[0][-2] + np.where(vector)[0][-1])/2\n",
    "        \n",
    "    return candidate + 1\n",
    "    # alternative\n",
    "    return vector.sum() + 1\n",
    "#     len(np.where(t)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch of all samples:  longest sample length (for padding, if minibatch)\n",
    "max([len(emb) for emb in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{371}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all words same len of emb size 371 \n",
    "set([len(emb[i]) for emb in e for i in range(len(emb))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seq2Seq -- with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 layer rnn.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "371"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "# EMBEDDING_SIZE = 371\n",
    "# with EOS pos\n",
    "EMBEDDING_SIZE = len(vocab_emb['I']) + len(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "546"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max([len(emb) for emb in e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change if aadd in EOS, pos to 547\n",
    "MAX_LENGTH = 546"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_dict['EOS'] = len(pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EOS tag\n",
    "# vocab_emb['EOS'] = torch.rand([300],dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size=MAX_LENGTH, emb_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # what is the input size fo self.embedding...? and is self.embedding necessary\n",
    "#         self.embedding = nn.Embedding(input_size, emb_size)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "#         self.gru = nn.GRU(input_size=self.emb_size, hidden_size=self.hidden_size,num_layers=2)\n",
    "        self.gru = nn.GRU(input_size=self.emb_size,hidden_size=self.hidden_size,num_layers=2).double()\n",
    "    \n",
    "#         # each output node Oi of our neural network\n",
    "# uses a standard sigmoid function 1\n",
    "# 1+e−zi\n",
    "# , without including\n",
    "# the outputs from other nodes, as shown in Figure 1. Output\n",
    "# node Oi\n",
    "# is used to estimate the probability oi\n",
    "# that a data\n",
    "# point belongs to category i independently, without subjecting\n",
    "# to normalization as traditional neural networks do. Thus,\n",
    "# for a data point x of category k, the target vector is\n",
    "# (1, , 1, .., 1, 0, 0, 0), in which the first k elements is 1 and\n",
    "# others 0\n",
    "# http://orca.st.usm.edu/~zwang/files/rank.pdf A Neural Network Approach to Ordinal Regression\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size*2,30).double()\n",
    "        self.activations_list = [nn.Sigmoid() for i in range(30)]\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # confirm dims here...\n",
    "#         embedded = self.embedding(input).view(1, 1, -1)\n",
    "        \n",
    "        embedded = torch.cat(input).view(len(input), 1, -1).double()\n",
    "        \n",
    "#         output = embedded\n",
    "        \n",
    "#         output, hidden = self.gru(self.emb_size, self.hidden_size)\n",
    "#         output, hidden = self.gru(output)\n",
    "        gru_out, _ = self.gru(embedded,hidden)\n",
    "        \n",
    "        hid_out = torch.cat((_[-2,:,:], _[-1,:,:]), dim = 1)\n",
    "#         print(gru_out.size(),_.size())\n",
    "    \n",
    "#         lstm_out, _ = self.lstm(embedding.view(len(sentence), -1))\n",
    "        out = self.fc(hid_out)\n",
    "    \n",
    "        out = torch.tensor([a(o) for (a,o) in zip(self.activations_list,out[0])],requires_grad=True).double()\n",
    "        \n",
    "        # any further processing -- int? softmax...? \n",
    "#         return out\n",
    "        return out, _\n",
    "\n",
    "    def initHidden(self):\n",
    "        # h_0 of shape (num_layers * num_directions, batch, hidden_size): tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2\n",
    "        return torch.zeros(2, 1, self.hidden_size, device=device).double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The\n",
    "# cost function for a data point x can be relative entropy\n",
    "# or square error between the target vector and the output\n",
    "# vector\n",
    "# loss = nn.BCELoss()\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO minibatch + pad. For starters, stochastic gd.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hidden = encoder.initHidden()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat, hid = encoder(x,_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2627, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 1\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 2\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 3\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 4\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 5\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 6\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 7\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 8\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "Epoch 9\n",
      "step 20\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 40\n",
      "loss tensor(0.2647, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 60\n",
      "loss tensor(0.2632, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 80\n",
      "loss tensor(0.2630, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 100\n",
      "loss tensor(0.2621, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 120\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 140\n",
      "loss tensor(0.2642, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 160\n",
      "loss tensor(0.2613, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 180\n",
      "loss tensor(0.2605, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 200\n",
      "loss tensor(0.2449, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 220\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 240\n",
      "loss tensor(0.2515, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 260\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 280\n",
      "loss tensor(0.2577, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 300\n",
      "loss tensor(0.2631, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 320\n",
      "loss tensor(0.2570, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 340\n",
      "loss tensor(0.2549, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 360\n",
      "loss tensor(0.2452, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 380\n",
      "loss tensor(0.2543, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 400\n",
      "loss tensor(0.2455, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 420\n",
      "loss tensor(0.2496, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 440\n",
      "loss tensor(0.2555, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 460\n",
      "loss tensor(0.2596, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 480\n",
      "loss tensor(0.2491, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 500\n",
      "loss tensor(0.2604, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 520\n",
      "loss tensor(0.2475, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 540\n",
      "loss tensor(0.2540, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 560\n",
      "loss tensor(0.2518, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 580\n",
      "loss tensor(0.2556, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 600\n",
      "loss tensor(0.2447, dtype=torch.float64, grad_fn=<MseLossBackward>)\n",
      "step 620\n",
      "loss tensor(0.2522, dtype=torch.float64, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "encoder.train()\n",
    "_hidden = encoder.initHidden()\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('Epoch',epoch)\n",
    "    step = 0\n",
    "    \n",
    "    # in future, mix up epochs \n",
    "    for i in train_ix:\n",
    "        \n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x,y = get_item(i)\n",
    "\n",
    "        yhat, _hidden = encoder(x,_hidden)\n",
    "\n",
    "        loss = loss_func(yhat,y)\n",
    "\n",
    "        loss.backward()\n",
    "#         loss.backward(retain_graph=True)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 20 == 0: \n",
    "            print('step',step)\n",
    "            print('loss',loss)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_minibatch(batchsize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 1, 371])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(x[0]).view(len(x[0]),1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to be able to pass any/all into net\n",
    "# encoder = EncoderRNN(len(x[0])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_hidden.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dl1010",
   "language": "python",
   "name": "dl1010"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
